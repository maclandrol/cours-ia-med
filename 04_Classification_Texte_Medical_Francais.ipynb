{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/maclandrol/cours-ia-med/blob/master/04_Classification_Texte_Medical_Francais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04. Classification de Textes M√©dicaux en Fran√ßais\n",
        "\n",
        "**Enseignant:** Emmanuel Noutahi, PhD\n",
        "\n",
        "---\n",
        "\n",
        "**Objectif:** Ma√Ætriser la classification automatique de textes m√©dicaux fran√ßais avec des mod√®les de langage sp√©cialis√©s.\n",
        "\n",
        "**Applications pratiques :**\n",
        "- Classification automatique de questions d'examens m√©dicaux\n",
        "- Analyse de comptes-rendus m√©dicaux fran√ßais\n",
        "- Aide √† la pr√©paration d'examens de sp√©cialisation\n",
        "- Triage automatique de documents m√©dicaux\n",
        "\n",
        "**Dataset:** FrenchMedMCQA - 3,105 questions d'examens de pharmacie fran√ßais avec r√©ponses multiples.\n",
        "\n",
        "**Important:** Ce cours utilise des donn√©es r√©elles d'examens m√©dicaux fran√ßais pour un apprentissage pratique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation et Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation des biblioth√®ques pour NLP m√©dical fran√ßais\n",
        "!pip install transformers datasets torch accelerate -q\n",
        "!pip install scikit-learn pandas numpy matplotlib seaborn -q\n",
        "!pip install huggingface_hub tokenizers -q\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, pipeline\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    classification_report, multilabel_confusion_matrix,\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    hamming_loss, jaccard_score\n",
        ")\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration pour reproductibilit√©\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# D√©tection du dispositif\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Dispositif utilis√©: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "print(\"Configuration pour NLP m√©dical fran√ßais termin√©e.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Exploration du Dataset FrenchMedMCQA\n",
        "\n",
        "Le dataset FrenchMedMCQA contient 3,105 questions d'examens de pharmacie fran√ßais avec r√©ponses multiples, repr√©sentant un d√©fi r√©aliste de classification multi-label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement du dataset FrenchMedMCQA\n",
        "print(\"=== CHARGEMENT DU DATASET FRENCHMEDMCQA ===\")\n",
        "\n",
        "try:\n",
        "    # Chargement depuis HuggingFace Hub\n",
        "    dataset = load_dataset(\"qanastek/frenchmedmcqa\")\n",
        "    print(\"Dataset charg√© avec succ√®s depuis HuggingFace Hub\")\n",
        "    print(f\"Splits disponibles: {list(dataset.keys())}\")\n",
        "    \n",
        "    # Affichage de la structure\n",
        "    train_dataset = dataset['train']\n",
        "    print(f\"\\nTaille du dataset d'entra√Ænement: {len(train_dataset)}\")\n",
        "    print(f\"Colonnes disponibles: {train_dataset.column_names}\")\n",
        "    \n",
        "    # Exploration d'un exemple\n",
        "    example = train_dataset[0]\n",
        "    print(f\"\\nExemple d'entr√©e:\")\n",
        "    for key, value in example.items():\n",
        "        print(f\"  {key}: {type(value)} - {str(value)[:100]}...\" if len(str(value)) > 100 else f\"  {key}: {value}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement: {e}\")\n",
        "    print(\"Cr√©ation d'un dataset simul√© pour d√©monstration...\")\n",
        "    \n",
        "    # Dataset simul√© bas√© sur la structure FrenchMedMCQA\n",
        "    simulated_data = {\n",
        "        'id': list(range(100)),\n",
        "        'question': [\n",
        "            \"Quel est le m√©canisme d'action principal des inhibiteurs de l'enzyme de conversion?\",\n",
        "            \"Quels sont les effets ind√©sirables des cortico√Ødes au long terme?\",\n",
        "            \"Dans quelles situations cliniques utilise-t-on la warfarine?\",\n",
        "            \"Quelles sont les contre-indications des anti-inflammatoires non st√©ro√Ødiens?\",\n",
        "            \"Quel est le r√¥le de l'insuline dans le m√©tabolisme glucidique?\"\n",
        "        ] * 20,\n",
        "        'answerA': [\"Inhibition de l'ACE\"] * 100,\n",
        "        'answerB': [\"Blocage des r√©cepteurs AT1\"] * 100,\n",
        "        'answerC': [\"Stimulation du syst√®me r√©nine-angiotensine\"] * 100,\n",
        "        'answerD': [\"Inhibition de la phosphodiest√©rase\"] * 100,\n",
        "        'answerE': [\"Activation des r√©cepteurs Œ≤-adr√©nergiques\"] * 100,\n",
        "        'correct_answers': [[0, 1], [1, 2], [0], [2, 3], [0, 4]] * 20\n",
        "    }\n",
        "    \n",
        "    from datasets import Dataset\n",
        "    train_dataset = Dataset.from_dict(simulated_data)\n",
        "    print(\"Dataset simul√© cr√©√© pour d√©monstration\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse exploratoire du dataset\n",
        "print(\"=== ANALYSE EXPLORATOIRE ===\")\n",
        "\n",
        "# Conversion en DataFrame pour analyse\n",
        "df = train_dataset.to_pandas()\n",
        "print(f\"Nombre total de questions: {len(df)}\")\n",
        "\n",
        "# Analyse de la longueur des questions\n",
        "df['question_length'] = df['question'].str.len()\n",
        "df['question_words'] = df['question'].str.split().str.len()\n",
        "\n",
        "print(f\"\\nStatistiques des questions:\")\n",
        "print(f\"Longueur moyenne: {df['question_length'].mean():.1f} caract√®res\")\n",
        "print(f\"Nombre moyen de mots: {df['question_words'].mean():.1f}\")\n",
        "print(f\"Question la plus courte: {df['question_length'].min()} caract√®res\")\n",
        "print(f\"Question la plus longue: {df['question_length'].max()} caract√®res\")\n",
        "\n",
        "# Analyse des r√©ponses correctes\n",
        "df['num_correct_answers'] = df['correct_answers'].apply(len)\n",
        "\n",
        "print(f\"\\nAnalyse des r√©ponses:\")\n",
        "print(f\"Questions √† r√©ponse unique: {sum(df['num_correct_answers'] == 1)} ({sum(df['num_correct_answers'] == 1)/len(df)*100:.1f}%)\")\n",
        "print(f\"Questions √† r√©ponses multiples: {sum(df['num_correct_answers'] > 1)} ({sum(df['num_correct_answers'] > 1)/len(df)*100:.1f}%)\")\n",
        "print(f\"Nombre moyen de r√©ponses correctes: {df['num_correct_answers'].mean():.2f}\")\n",
        "\n",
        "# Visualisations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Analyse Exploratoire - FrenchMedMCQA', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Distribution de la longueur des questions\n",
        "axes[0, 0].hist(df['question_length'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Distribution - Longueur des Questions (caract√®res)')\n",
        "axes[0, 0].set_xlabel('Nombre de caract√®res')\n",
        "axes[0, 0].set_ylabel('Fr√©quence')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Distribution du nombre de mots\n",
        "axes[0, 1].hist(df['question_words'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "axes[0, 1].set_title('Distribution - Nombre de Mots par Question')\n",
        "axes[0, 1].set_xlabel('Nombre de mots')\n",
        "axes[0, 1].set_ylabel('Fr√©quence')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Distribution du nombre de r√©ponses correctes\n",
        "answer_counts = df['num_correct_answers'].value_counts().sort_index()\n",
        "axes[1, 0].bar(answer_counts.index, answer_counts.values, alpha=0.7, color='salmon', edgecolor='black')\n",
        "axes[1, 0].set_title('Distribution - Nombre de R√©ponses Correctes')\n",
        "axes[1, 0].set_xlabel('Nombre de r√©ponses correctes')\n",
        "axes[1, 0].set_ylabel('Nombre de questions')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Boxplot longueur vs nombre de r√©ponses\n",
        "df.boxplot(column='question_length', by='num_correct_answers', ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Longueur des Questions vs Nombre de R√©ponses Correctes')\n",
        "axes[1, 1].set_xlabel('Nombre de r√©ponses correctes')\n",
        "axes[1, 1].set_ylabel('Longueur (caract√®res)')\n",
        "\n",
        "plt.suptitle('')  # Remove automatic title\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Analyse du Vocabulaire M√©dical Fran√ßais\n",
        "\n",
        "L'analyse du vocabulaire m√©dical fran√ßais est cruciale pour comprendre la sp√©cificit√© du domaine et optimiser les mod√®les de langage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse du vocabulaire m√©dical fran√ßais\n",
        "print(\"=== ANALYSE DU VOCABULAIRE M√âDICAL FRAN√áAIS ===\")\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def extract_medical_vocabulary(questions):\n",
        "    \"\"\"\n",
        "    Extrait et analyse le vocabulaire m√©dical des questions\n",
        "    \"\"\"\n",
        "    # Concat√©nation de toutes les questions\n",
        "    all_text = ' '.join(questions).lower()\n",
        "    \n",
        "    # Nettoyage du texte\n",
        "    # Conserve les caract√®res fran√ßais sp√©ciaux\n",
        "    clean_text = re.sub(r'[^a-z√†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ß√±\\s-]', ' ', all_text)\n",
        "    \n",
        "    # Extraction des mots\n",
        "    words = clean_text.split()\n",
        "    \n",
        "    # Filtrage des mots courts et mots vides\n",
        "    french_stopwords = {\n",
        "        'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'et', 'ou', '√†', 'au',\n",
        "        'aux', 'avec', 'sans', 'dans', 'sur', 'pour', 'par', 'vers', 'chez',\n",
        "        'que', 'qui', 'quoi', 'dont', 'o√π', 'quand', 'comment', 'pourquoi',\n",
        "        'ce', 'cette', 'ces', 'son', 'sa', 'ses', 'mon', 'ma', 'mes',\n",
        "        'est', '√™tre', 'avoir', 'fait', 'faire', 'peut', 'peuvent', 'doit', 'doivent',\n",
        "        'plus', 'moins', 'tr√®s', 'bien', 'mal', 'aussi', 'encore', 'd√©j√†'\n",
        "    }\n",
        "    \n",
        "    filtered_words = [\n",
        "        word for word in words \n",
        "        if len(word) > 3 and word not in french_stopwords\n",
        "    ]\n",
        "    \n",
        "    return filtered_words\n",
        "\n",
        "# D√©finition de termes m√©dicaux fran√ßais courants\n",
        "medical_terms = {\n",
        "    'anatomie': ['c≈ìur', 'poumon', 'foie', 'rein', 'cerveau', 'muscle', 'os', 'sang', 'art√®re', 'veine'],\n",
        "    'pathologie': ['cancer', 'diab√®te', 'hypertension', 'infection', 'inflammation', 'allergie', 'asthme'],\n",
        "    'pharmacologie': ['m√©dicament', 'antibiotique', 'antidouleur', 'vaccin', 'hormone', 'vitamine'],\n",
        "    'symptomes': ['douleur', 'fi√®vre', 'fatigue', 'naus√©e', 'toux', 'essoufflement', 'vertige'],\n",
        "    'examens': ['radiographie', '√©chographie', 'scanner', 'analyse', 'pr√©l√®vement', 'biopsie'],\n",
        "    'traitements': ['chirurgie', 'th√©rapie', 'r√©√©ducation', 'prescription', 'traitement', 'intervention']\n",
        "}\n",
        "\n",
        "# Extraction du vocabulaire\n",
        "vocabulary = extract_medical_vocabulary(df['question'].tolist())\n",
        "word_counts = Counter(vocabulary)\n",
        "\n",
        "print(f\"Vocabulaire total: {len(word_counts)} mots uniques\")\n",
        "print(f\"Mots les plus fr√©quents:\")\n",
        "\n",
        "for word, count in word_counts.most_common(20):\n",
        "    print(f\"  {word}: {count}\")\n",
        "\n",
        "# Classification par domaines m√©dicaux\n",
        "domain_counts = {domain: 0 for domain in medical_terms.keys()}\n",
        "classified_terms = {domain: [] for domain in medical_terms.keys()}\n",
        "\n",
        "for word, count in word_counts.items():\n",
        "    for domain, terms in medical_terms.items():\n",
        "        if any(term in word for term in terms):\n",
        "            domain_counts[domain] += count\n",
        "            classified_terms[domain].append((word, count))\n",
        "            break\n",
        "\n",
        "print(f\"\\nR√©partition par domaines m√©dicaux:\")\n",
        "for domain, count in domain_counts.items():\n",
        "    print(f\"  {domain.capitalize()}: {count} occurrences\")\n",
        "\n",
        "# Identification de termes sp√©cifiquement m√©dicaux\n",
        "medical_specific = [\n",
        "    word for word, count in word_counts.most_common(100)\n",
        "    if any(any(term in word for term in terms) for terms in medical_terms.values())\n",
        "]\n",
        "\n",
        "print(f\"\\nTermes m√©dicaux sp√©cialis√©s identifi√©s: {len(medical_specific)}\")\n",
        "print(f\"Exemples: {', '.join(medical_specific[:10])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation du vocabulaire m√©dical\n",
        "try:\n",
        "    # Nuage de mots pour le vocabulaire m√©dical\n",
        "    wordcloud = WordCloud(\n",
        "        width=800, height=400,\n",
        "        background_color='white',\n",
        "        max_words=100,\n",
        "        colormap='viridis',\n",
        "        font_path=None  # Utiliser la police par d√©faut\n",
        "    ).generate_from_frequencies(dict(word_counts.most_common(100)))\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title('Nuage de Mots - Vocabulaire M√©dical Fran√ßais', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"Installation de wordcloud n√©cessaire pour la visualisation\")\n",
        "    \n",
        "# Graphique de r√©partition par domaines\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Graphique en barres des domaines\n",
        "domains = list(domain_counts.keys())\n",
        "counts = list(domain_counts.values())\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "bars = plt.bar(domains, counts, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "plt.title('R√©partition du Vocabulaire par Domaines M√©dicaux')\n",
        "plt.xlabel('Domaines M√©dicaux')\n",
        "plt.ylabel('Nombre d\\'Occurrences')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Ajout des valeurs sur les barres\n",
        "for bar, count in zip(bars, counts):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "             str(count), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Graphique des termes les plus fr√©quents\n",
        "plt.subplot(2, 1, 2)\n",
        "top_words = dict(word_counts.most_common(15))\n",
        "plt.barh(list(top_words.keys()), list(top_words.values()), alpha=0.7, color='lightcoral')\n",
        "plt.title('Top 15 des Termes les Plus Fr√©quents')\n",
        "plt.xlabel('Fr√©quence')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyse de la richesse du vocabulaire\n",
        "total_words = sum(word_counts.values())\n",
        "unique_words = len(word_counts)\n",
        "vocabulary_richness = unique_words / total_words\n",
        "\n",
        "print(f\"\\n=== ANALYSE DE LA RICHESSE VOCABULAIRE ===\")\n",
        "print(f\"Total des mots: {total_words}\")\n",
        "print(f\"Mots uniques: {unique_words}\")\n",
        "print(f\"Richesse vocabulaire: {vocabulary_richness:.4f}\")\n",
        "print(f\"Pourcentage de termes m√©dicaux sp√©cialis√©s: {len(medical_specific)/unique_words*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Pr√©paration des Donn√©es pour Classification Multi-label\n",
        "\n",
        "Le dataset FrenchMedMCQA n√©cessite une approche de classification multi-label car les questions peuvent avoir plusieurs r√©ponses correctes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pr√©paration pour classification multi-label\n",
        "print(\"=== PR√âPARATION CLASSIFICATION MULTI-LABEL ===\")\n",
        "\n",
        "def prepare_multilabel_data(dataset_df):\n",
        "    \"\"\"\n",
        "    Pr√©pare les donn√©es pour classification multi-label\n",
        "    \"\"\"\n",
        "    # Construction des questions compl√®tes avec options\n",
        "    questions_with_options = []\n",
        "    labels = []\n",
        "    \n",
        "    for _, row in dataset_df.iterrows():\n",
        "        # Construction de la question compl√®te\n",
        "        question_text = f\"{row['question']}\\n\"\n",
        "        question_text += f\"A) {row['answerA']}\\n\"\n",
        "        question_text += f\"B) {row['answerB']}\\n\"\n",
        "        question_text += f\"C) {row['answerC']}\\n\"\n",
        "        question_text += f\"D) {row['answerD']}\\n\"\n",
        "        question_text += f\"E) {row['answerE']}\"\n",
        "        \n",
        "        questions_with_options.append(question_text)\n",
        "        \n",
        "        # Conversion des r√©ponses correctes en format multi-label binaire\n",
        "        label_vector = [0] * 5  # 5 options (A, B, C, D, E)\n",
        "        for correct_idx in row['correct_answers']:\n",
        "            if 0 <= correct_idx <= 4:\n",
        "                label_vector[correct_idx] = 1\n",
        "        \n",
        "        labels.append(label_vector)\n",
        "    \n",
        "    return questions_with_options, labels\n",
        "\n",
        "# Pr√©paration des donn√©es\n",
        "texts, labels = prepare_multilabel_data(df)\n",
        "\n",
        "print(f\"Nombre d'exemples pr√©par√©s: {len(texts)}\")\n",
        "print(f\"Format des labels: {len(labels[0])} classes (A, B, C, D, E)\")\n",
        "\n",
        "# Exemple d'entr√©e pr√©par√©e\n",
        "print(f\"\\nExemple d'entr√©e pr√©par√©e:\")\n",
        "print(f\"Texte: {texts[0][:200]}...\")\n",
        "print(f\"Labels: {labels[0]} (positions des r√©ponses correctes)\")\n",
        "\n",
        "# Statistiques des labels\n",
        "labels_array = np.array(labels)\n",
        "print(f\"\\nStatistiques des labels:\")\n",
        "print(f\"Nombre moyen de labels par question: {labels_array.sum(axis=1).mean():.2f}\")\n",
        "print(f\"Distribution des r√©ponses correctes par option:\")\n",
        "\n",
        "option_names = ['A', 'B', 'C', 'D', 'E']\n",
        "for i, option in enumerate(option_names):\n",
        "    count = labels_array[:, i].sum()\n",
        "    percentage = (count / len(labels)) * 100\n",
        "    print(f\"  Option {option}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Analyse de la distribution multi-label\n",
        "label_combinations = []\n",
        "for label in labels:\n",
        "    # Cr√©ation d'une cha√Æne repr√©sentant la combinaison\n",
        "    combination = ''.join([option_names[i] for i, val in enumerate(label) if val == 1])\n",
        "    label_combinations.append(combination)\n",
        "\n",
        "combination_counts = Counter(label_combinations)\n",
        "print(f\"\\nCombinaisons de r√©ponses les plus fr√©quentes:\")\n",
        "for combination, count in combination_counts.most_common(10):\n",
        "    percentage = (count / len(label_combinations)) * 100\n",
        "    print(f\"  {combination if combination else 'Aucune'}: {count} ({percentage:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Division des donn√©es en train/validation/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"=== DIVISION DES DONN√âES ===\")\n",
        "\n",
        "# Division initiale train/temp (80/20)\n",
        "texts_train, texts_temp, labels_train, labels_temp = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=[sum(label) for label in labels]\n",
        ")\n",
        "\n",
        "# Division temp en validation/test (10/10 du total)\n",
        "texts_val, texts_test, labels_val, labels_test = train_test_split(\n",
        "    texts_temp, labels_temp, test_size=0.5, random_state=42, stratify=[sum(label) for label in labels_temp]\n",
        ")\n",
        "\n",
        "print(f\"Donn√©es d'entra√Ænement: {len(texts_train)} exemples\")\n",
        "print(f\"Donn√©es de validation: {len(texts_val)} exemples\")\n",
        "print(f\"Donn√©es de test: {len(texts_test)} exemples\")\n",
        "\n",
        "# V√©rification de la distribution stratifi√©e\n",
        "train_avg_labels = np.array(labels_train).sum(axis=1).mean()\n",
        "val_avg_labels = np.array(labels_val).sum(axis=1).mean()\n",
        "test_avg_labels = np.array(labels_test).sum(axis=1).mean()\n",
        "\n",
        "print(f\"\\nV√©rification stratification:\")\n",
        "print(f\"Train - moyenne labels/question: {train_avg_labels:.2f}\")\n",
        "print(f\"Validation - moyenne labels/question: {val_avg_labels:.2f}\")\n",
        "print(f\"Test - moyenne labels/question: {test_avg_labels:.2f}\")\n",
        "\n",
        "# Visualisation de la distribution\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "splits = [\n",
        "    ('Train', np.array(labels_train)),\n",
        "    ('Validation', np.array(labels_val)),\n",
        "    ('Test', np.array(labels_test))\n",
        "]\n",
        "\n",
        "for idx, (split_name, split_labels) in enumerate(splits):\n",
        "    option_counts = split_labels.sum(axis=0)\n",
        "    axes[idx].bar(option_names, option_counts, alpha=0.7, color=f'C{idx}', edgecolor='black')\n",
        "    axes[idx].set_title(f'Distribution - {split_name}\\n({len(split_labels)} exemples)')\n",
        "    axes[idx].set_xlabel('Options de R√©ponse')\n",
        "    axes[idx].set_ylabel('Nombre d\\'Occurrences')\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Ajout des valeurs sur les barres\n",
        "    for i, count in enumerate(option_counts):\n",
        "        axes[idx].text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.suptitle('Distribution des Labels par Split', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Mod√®le CamemBERT pour Texte M√©dical Fran√ßais\n",
        "\n",
        "CamemBERT est un mod√®le BERT sp√©cialis√© pour le fran√ßais, particuli√®rement adapt√© aux textes m√©dicaux fran√ßais complexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration et chargement du mod√®le CamemBERT\n",
        "print(\"=== CONFIGURATION CAMEMBERT POUR M√âDICAL ===\")\n",
        "\n",
        "# Choix du mod√®le pour le fran√ßais m√©dical\n",
        "model_name = \"camembert-base\"  # Alternative: \"flaubert/flaubert_base_cased\"\n",
        "\n",
        "try:\n",
        "    # Chargement du tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    print(f\"Tokenizer charg√©: {model_name}\")\n",
        "    print(f\"Taille du vocabulaire: {len(tokenizer)}\")\n",
        "    \n",
        "    # Configuration pour classification multi-label\n",
        "    from transformers import AutoConfig\n",
        "    config = AutoConfig.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=5,  # 5 options (A, B, C, D, E)\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        id2label={0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\", 4: \"E\"},\n",
        "        label2id={\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3, \"E\": 4}\n",
        "    )\n",
        "    \n",
        "    # Chargement du mod√®le\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        config=config\n",
        "    )\n",
        "    \n",
        "    print(f\"Mod√®le charg√© avec {model.num_parameters()} param√®tres\")\n",
        "    print(f\"Architecture: {type(model).__name__}\")\n",
        "    \n",
        "    # Test de tokenisation sur exemple m√©dical\n",
        "    medical_example = texts[0]\n",
        "    tokens = tokenizer.tokenize(medical_example)\n",
        "    input_ids = tokenizer.encode(medical_example, truncation=True, max_length=512)\n",
        "    \n",
        "    print(f\"\\nTest de tokenisation:\")\n",
        "    print(f\"Texte original: {len(medical_example)} caract√®res\")\n",
        "    print(f\"Tokens g√©n√©r√©s: {len(tokens)}\")\n",
        "    print(f\"Input IDs: {len(input_ids)}\")\n",
        "    print(f\"Premiers tokens: {tokens[:10]}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement: {e}\")\n",
        "    print(\"Utilisation d'un mod√®le de base pour d√©monstration...\")\n",
        "    \n",
        "    # Configuration alternative avec un mod√®le plus simple\n",
        "    model_name = \"distilbert-base-multilingual-cased\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    config = AutoConfig.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=5,\n",
        "        problem_type=\"multi_label_classification\"\n",
        "    )\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        config=config\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cr√©ation d'un dataset PyTorch pour l'entra√Ænement\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FrenchMedicalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset personnalis√© pour questions m√©dicales fran√ßaises multi-label\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        # Tokenisation\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.FloatTensor(label)\n",
        "        }\n",
        "\n",
        "# Cr√©ation des datasets\n",
        "train_dataset = FrenchMedicalDataset(texts_train, labels_train, tokenizer)\n",
        "val_dataset = FrenchMedicalDataset(texts_val, labels_val, tokenizer)\n",
        "test_dataset = FrenchMedicalDataset(texts_test, labels_test, tokenizer)\n",
        "\n",
        "print(f\"Datasets cr√©√©s:\")\n",
        "print(f\"  Train: {len(train_dataset)} exemples\")\n",
        "print(f\"  Validation: {len(val_dataset)} exemples\")\n",
        "print(f\"  Test: {len(test_dataset)} exemples\")\n",
        "\n",
        "# Test du dataset\n",
        "sample = train_dataset[0]\n",
        "print(f\"\\n√âchantillon du dataset:\")\n",
        "print(f\"  Input IDs shape: {sample['input_ids'].shape}\")\n",
        "print(f\"  Attention mask shape: {sample['attention_mask'].shape}\")\n",
        "print(f\"  Labels shape: {sample['labels'].shape}\")\n",
        "print(f\"  Labels: {sample['labels'].tolist()}\")\n",
        "\n",
        "# Analyse de la longueur des s√©quences tokenis√©es\n",
        "sequence_lengths = []\n",
        "for text in texts_train[:100]:  # √âchantillon pour analyse\n",
        "    tokens = tokenizer.encode(text, truncation=False)\n",
        "    sequence_lengths.append(len(tokens))\n",
        "\n",
        "print(f\"\\nAnalyse des longueurs de s√©quences:\")\n",
        "print(f\"  Longueur moyenne: {np.mean(sequence_lengths):.1f} tokens\")\n",
        "print(f\"  Longueur m√©diane: {np.median(sequence_lengths):.1f} tokens\")\n",
        "print(f\"  Longueur maximale: {max(sequence_lengths)} tokens\")\n",
        "print(f\"  % s√©quences > 512 tokens: {sum(1 for l in sequence_lengths if l > 512)/len(sequence_lengths)*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Entra√Ænement du Mod√®le de Classification\n",
        "\n",
        "Configuration d'un pipeline d'entra√Ænement optimis√© pour Google Colab avec suivi des m√©triques multi-label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration des m√©triques de √©valuation multi-label\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Calcule les m√©triques d'√©valuation pour classification multi-label\n",
        "    \"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    \n",
        "    # Conversion des probabilit√©s en pr√©dictions binaires\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    y_pred = (probs > 0.5).int().numpy()\n",
        "    y_true = labels.astype(int)\n",
        "    \n",
        "    # M√©triques globales\n",
        "    exact_match = accuracy_score(y_true, y_pred)\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "    jaccard = jaccard_score(y_true, y_pred, average='samples', zero_division=0)\n",
        "    \n",
        "    # M√©triques par classe (micro et macro)\n",
        "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='micro', zero_division=0\n",
        "    )\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='macro', zero_division=0\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'exact_match': exact_match,\n",
        "        'hamming_loss': hamming,\n",
        "        'jaccard_score': jaccard,\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_micro': precision_micro,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_micro': recall_micro,\n",
        "        'recall_macro': recall_macro,\n",
        "    }\n",
        "\n",
        "# Configuration de l'entra√Ænement optimis√©e pour Colab\n",
        "print(\"=== CONFIGURATION D'ENTRA√éNEMENT ===\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./medical_french_classifier',\n",
        "    num_train_epochs=3,  # R√©duction pour Colab\n",
        "    per_device_train_batch_size=8,  # Optimis√© pour m√©moire GPU\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=2e-5,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    greater_is_better=True,\n",
        "    save_total_limit=2,\n",
        "    dataloader_num_workers=0,  # √âvite les probl√®mes de multiprocessing\n",
        "    fp16=torch.cuda.is_available(),  # Optimisation m√©moire GPU\n",
        "    gradient_checkpointing=True,  # √âconomie m√©moire\n",
        "    dataloader_pin_memory=False,\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "# Initialisation du trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(f\"Configuration d'entra√Ænement:\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  Batch size (train): {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  Optimisations m√©moire: FP16={training_args.fp16}, Gradient checkpointing={training_args.gradient_checkpointing}\")\n",
        "print(f\"  Dispositif: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lancement de l'entra√Ænement\n",
        "print(\"=== D√âBUT DE L'ENTRA√éNEMENT ===\")\n",
        "\n",
        "try:\n",
        "    # Entra√Ænement du mod√®le\n",
        "    print(\"D√©marrage de l'entra√Ænement...\")\n",
        "    print(f\"Temps estim√©: ~{len(train_dataset) * training_args.num_train_epochs / (training_args.per_device_train_batch_size * 60):.0f} minutes\")\n",
        "    \n",
        "    trainer.train()\n",
        "    \n",
        "    print(\"\\n‚úÖ Entra√Ænement termin√© avec succ√®s!\")\n",
        "    \n",
        "    # Sauvegarde du meilleur mod√®le\n",
        "    trainer.save_model('./best_medical_french_model')\n",
        "    tokenizer.save_pretrained('./best_medical_french_model')\n",
        "    \n",
        "    print(\"üìÅ Mod√®le sauvegard√© dans: ./best_medical_french_model\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur pendant l'entra√Ænement: {e}\")\n",
        "    print(\"üí° Suggestions:\")\n",
        "    print(\"   - R√©duire la taille du batch\")\n",
        "    print(\"   - Activer FP16 si GPU disponible\")\n",
        "    print(\"   - Utiliser gradient_accumulation_steps\")\n",
        "    \n",
        "    # Configuration d'urgence avec param√®tres r√©duits\n",
        "    print(\"\\nüîÑ Tentative avec param√®tres r√©duits...\")\n",
        "    \n",
        "    training_args_light = TrainingArguments(\n",
        "        output_dir='./medical_french_classifier_light',\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=8,\n",
        "        warmup_steps=50,\n",
        "        weight_decay=0.01,\n",
        "        learning_rate=3e-5,\n",
        "        logging_steps=20,\n",
        "        evaluation_strategy=\"no\",  # D√©sactivation √©valuation interm√©diaire\n",
        "        save_strategy=\"epoch\",\n",
        "        dataloader_num_workers=0,\n",
        "        fp16=False,  # D√©sactivation FP16\n",
        "        gradient_checkpointing=True,\n",
        "        gradient_accumulation_steps=2  # Simulation de batch plus grand\n",
        "    )\n",
        "    \n",
        "    trainer_light = Trainer(\n",
        "        model=model,\n",
        "        args=training_args_light,\n",
        "        train_dataset=train_dataset\n",
        "    )\n",
        "    \n",
        "    try:\n",
        "        trainer_light.train()\n",
        "        print(\"‚úÖ Entra√Ænement l√©ger termin√©\")\n",
        "        trainer = trainer_light  # Utiliser ce mod√®le pour la suite\n",
        "    except Exception as e2:\n",
        "        print(f\"‚ùå √âchec de l'entra√Ænement l√©ger: {e2}\")\n",
        "        print(\"üìù Utilisation du mod√®le pr√©-entra√Æn√© pour les d√©monstrations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. √âvaluation et Analyse des Performances\n",
        "\n",
        "√âvaluation compl√®te du mod√®le avec m√©triques sp√©cialis√©es pour la classification multi-label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âvaluation sur le dataset de test\n",
        "print(\"=== √âVALUATION SUR DATASET DE TEST ===\")\n",
        "\n",
        "# Pr√©dictions sur le dataset de test\n",
        "test_results = trainer.predict(test_dataset)\n",
        "test_predictions = test_results.predictions\n",
        "test_labels = test_results.label_ids\n",
        "\n",
        "# Conversion des logits en probabilit√©s et pr√©dictions\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "test_probs = sigmoid(torch.Tensor(test_predictions)).numpy()\n",
        "test_pred_binary = (test_probs > 0.5).astype(int)\n",
        "\n",
        "print(f\"Pr√©dictions g√©n√©r√©es pour {len(test_predictions)} exemples\")\n",
        "print(f\"Shape des pr√©dictions: {test_pred_binary.shape}\")\n",
        "\n",
        "# Calcul des m√©triques d√©taill√©es\n",
        "metrics = compute_metrics((test_predictions, test_labels))\n",
        "\n",
        "print(f\"\\n=== M√âTRIQUES GLOBALES ===\")\n",
        "print(f\"Exact Match Accuracy: {metrics['exact_match']:.4f}\")\n",
        "print(f\"Hamming Loss: {metrics['hamming_loss']:.4f}\")\n",
        "print(f\"Jaccard Score: {metrics['jaccard_score']:.4f}\")\n",
        "\n",
        "print(f\"\\n=== M√âTRIQUES MICRO (globales) ===\")\n",
        "print(f\"Precision: {metrics['precision_micro']:.4f}\")\n",
        "print(f\"Recall: {metrics['recall_micro']:.4f}\")\n",
        "print(f\"F1-Score: {metrics['f1_micro']:.4f}\")\n",
        "\n",
        "print(f\"\\n=== M√âTRIQUES MACRO (moyenn√©es par classe) ===\")\n",
        "print(f\"Precision: {metrics['precision_macro']:.4f}\")\n",
        "print(f\"Recall: {metrics['recall_macro']:.4f}\")\n",
        "print(f\"F1-Score: {metrics['f1_macro']:.4f}\")\n",
        "\n",
        "# M√©triques par classe\n",
        "precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n",
        "    test_labels, test_pred_binary, average=None, zero_division=0\n",
        ")\n",
        "\n",
        "print(f\"\\n=== M√âTRIQUES PAR OPTION ===\")\n",
        "option_names = ['A', 'B', 'C', 'D', 'E']\n",
        "for i, option in enumerate(option_names):\n",
        "    print(f\"Option {option}:\")\n",
        "    print(f\"  Precision: {precision_per_class[i]:.4f}\")\n",
        "    print(f\"  Recall: {recall_per_class[i]:.4f}\")\n",
        "    print(f\"  F1-Score: {f1_per_class[i]:.4f}\")\n",
        "    print(f\"  Support: {support_per_class[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation des performances\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Analyse des Performances - Classification Multi-label', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. M√©triques par classe\n",
        "x = np.arange(len(option_names))\n",
        "width = 0.25\n",
        "\n",
        "axes[0, 0].bar(x - width, precision_per_class, width, label='Precision', alpha=0.7)\n",
        "axes[0, 0].bar(x, recall_per_class, width, label='Recall', alpha=0.7)\n",
        "axes[0, 0].bar(x + width, f1_per_class, width, label='F1-Score', alpha=0.7)\n",
        "\n",
        "axes[0, 0].set_xlabel('Options de R√©ponse')\n",
        "axes[0, 0].set_ylabel('Score')\n",
        "axes[0, 0].set_title('M√©triques par Option')\n",
        "axes[0, 0].set_xticks(x)\n",
        "axes[0, 0].set_xticklabels(option_names)\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Matrice de confusion par classe\n",
        "conf_matrices = multilabel_confusion_matrix(test_labels, test_pred_binary)\n",
        "conf_matrix_normalized = np.zeros((5, 2, 2))\n",
        "\n",
        "for i in range(5):\n",
        "    cm = conf_matrices[i]\n",
        "    conf_matrix_normalized[i] = cm / cm.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Affichage de la matrice pour l'option A comme exemple\n",
        "sns.heatmap(conf_matrix_normalized[0], annot=True, fmt='.3f', cmap='Blues',\n",
        "            xticklabels=['Pr√©dit: Non', 'Pr√©dit: Oui'],\n",
        "            yticklabels=['R√©el: Non', 'R√©el: Oui'],\n",
        "            ax=axes[0, 1])\n",
        "axes[0, 1].set_title('Matrice de Confusion - Option A')\n",
        "\n",
        "# 3. Distribution des scores de confiance\n",
        "axes[1, 0].hist(test_probs.flatten(), bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "axes[1, 0].axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Seuil de d√©cision')\n",
        "axes[1, 0].set_xlabel('Probabilit√©')\n",
        "axes[1, 0].set_ylabel('Fr√©quence')\n",
        "axes[1, 0].set_title('Distribution des Probabilit√©s Pr√©dites')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Comparaison des m√©triques globales\n",
        "global_metrics = {\n",
        "    'Exact Match': metrics['exact_match'],\n",
        "    'F1 Micro': metrics['f1_micro'],\n",
        "    'F1 Macro': metrics['f1_macro'],\n",
        "    'Jaccard Score': metrics['jaccard_score'],\n",
        "    'Hamming Loss\\n(invers√©)': 1 - metrics['hamming_loss']\n",
        "}\n",
        "\n",
        "metric_names = list(global_metrics.keys())\n",
        "metric_values = list(global_metrics.values())\n",
        "\n",
        "bars = axes[1, 1].bar(metric_names, metric_values, alpha=0.7, color='salmon', edgecolor='black')\n",
        "axes[1, 1].set_ylabel('Score')\n",
        "axes[1, 1].set_title('M√©triques Globales')\n",
        "axes[1, 1].set_ylim(0, 1)\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# Ajout des valeurs sur les barres\n",
        "for bar, value in zip(bars, metric_values):\n",
        "    height = bar.get_height()\n",
        "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Prompting avec Mod√®les de Langage (ChatGPT, Gemini, Claude)\n",
        "\n",
        "Comparaison entre mod√®les fine-tun√©s et prompting pour la classification de textes m√©dicaux fran√ßais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompts optimis√©s pour classification m√©dicale fran√ßaise\n",
        "print(\"=== PROMPTING POUR CLASSIFICATION M√âDICALE ===\")\n",
        "\n",
        "def generate_medical_classification_prompts():\n",
        "    \"\"\"\n",
        "    G√©n√®re des prompts optimis√©s pour diff√©rents mod√®les de langage\n",
        "    \"\"\"\n",
        "    \n",
        "    base_prompt = \"\"\"\n",
        "Vous √™tes un expert en pharmacie fran√ßaise. Analysez cette question d'examen et identifiez TOUTES les r√©ponses correctes.\n",
        "\n",
        "QUESTION D'EXAMEN:\n",
        "{question}\n",
        "\n",
        "OPTIONS:\n",
        "A) {answerA}\n",
        "B) {answerB}\n",
        "C) {answerC}\n",
        "D) {answerD}\n",
        "E) {answerE}\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Analysez chaque option individuellement\n",
        "2. Basez-vous sur vos connaissances pharmacologiques fran√ßaises\n",
        "3. Une question peut avoir plusieurs r√©ponses correctes\n",
        "4. Soyez pr√©cis et justifiez votre raisonnement\n",
        "\n",
        "FORMAT DE R√âPONSE:\n",
        "R√©ponses correctes: [liste des lettres]\n",
        "Justification: [explication m√©dicale d√©taill√©e]\n",
        "Confiance: [√âlev√©e/Mod√©r√©e/Faible]\n",
        "\"\"\"\n",
        "    \n",
        "    prompts = {\n",
        "        'chatgpt': {\n",
        "            'system': \"\"\"Vous √™tes un pharmacien expert fran√ßais sp√©cialis√© dans l'√©valuation d'examens de pharmacie. \n",
        "            Votre r√¥le est d'identifier pr√©cis√©ment les r√©ponses correctes aux questions d'examen en vous basant sur \n",
        "            les connaissances pharmaceutiques fran√ßaises actuelles.\"\"\",\n",
        "            'user_template': base_prompt\n",
        "        },\n",
        "        \n",
        "        'gemini': {\n",
        "            'prompt_template': f\"\"\"\n",
        "# Expert Pharmacie Fran√ßaise\n",
        "\n",
        "**Contexte**: Question d'examen de sp√©cialisation en pharmacie fran√ßaise\n",
        "\n",
        "**T√¢che**: Identifier TOUTES les r√©ponses correctes (peut √™tre multiple)\n",
        "\n",
        "{base_prompt}\n",
        "\n",
        "**Crit√®res d'√©valuation**:\n",
        "- Conformit√© avec la pharmacop√©e fran√ßaise\n",
        "- Respect des recommandations ANSM\n",
        "- Application des connaissances pharmaceutiques\n",
        "\"\"\"\n",
        "        },\n",
        "        \n",
        "        'claude': {\n",
        "            'prompt_template': f\"\"\"\n",
        "Je vais analyser cette question d'examen de pharmacie fran√ßaise avec rigueur scientifique.\n",
        "\n",
        "Approche m√©thodologique:\n",
        "1. Analyse pharmacologique de chaque option\n",
        "2. V√©rification avec les standards fran√ßais\n",
        "3. Identification des r√©ponses multiples possibles\n",
        "4. Justification m√©dicale d√©taill√©e\n",
        "\n",
        "{base_prompt}\n",
        "\n",
        "Note: Cette analyse se base sur les connaissances pharmaceutiques fran√ßaises \n",
        "et les recommandations officielles en vigueur.\n",
        "\"\"\"\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    return prompts\n",
        "\n",
        "# G√©n√©ration des prompts\n",
        "prompts = generate_medical_classification_prompts()\n",
        "\n",
        "print(\"Prompts g√©n√©r√©s pour:\")\n",
        "for model_name in prompts.keys():\n",
        "    print(f\"  ‚úì {model_name.upper()}\")\n",
        "\n",
        "# Exemple de prompt format√©\n",
        "example_question = {\n",
        "    'question': \"Quels sont les m√©canismes d'action des inhibiteurs de l'enzyme de conversion (IEC)?\",\n",
        "    'answerA': \"Inhibition de l'enzyme de conversion de l'angiotensine\",\n",
        "    'answerB': \"Blocage des r√©cepteurs AT1 de l'angiotensine II\",\n",
        "    'answerC': \"R√©duction de la formation d'angiotensine II\",\n",
        "    'answerD': \"Augmentation de la bradykinine\",\n",
        "    'answerE': \"Stimulation des r√©cepteurs Œ≤-adr√©nergiques\"\n",
        "}\n",
        "\n",
        "print(f\"\\n=== EXEMPLE DE PROMPT CHATGPT ===\")\n",
        "formatted_prompt = prompts['chatgpt']['user_template'].format(**example_question)\n",
        "print(formatted_prompt[:500] + \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulation de r√©ponses de mod√®les de prompting\n",
        "print(\"=== SIMULATION DE R√âPONSES PROMPTING ===\")\n",
        "\n",
        "def simulate_llm_responses(question_data):\n",
        "    \"\"\"\n",
        "    Simule les r√©ponses des diff√©rents mod√®les de prompting\n",
        "    \"\"\"\n",
        "    simulated_responses = {\n",
        "        'chatgpt': {\n",
        "            'predicted_answers': ['A', 'C', 'D'],\n",
        "            'justification': \"\"\"Les IEC agissent principalement par:\n",
        "            - Inhibition directe de l'ACE (r√©ponse A correcte)\n",
        "            - R√©duction de la conversion angiotensine I ‚Üí angiotensine II (r√©ponse C correcte) \n",
        "            - Diminution de la d√©gradation de la bradykinine (r√©ponse D correcte)\n",
        "            Les r√©ponses B et E sont incorrectes car elles d√©crivent d'autres classes th√©rapeutiques.\"\"\",\n",
        "            'confidence': '√âlev√©e'\n",
        "        },\n",
        "        'gemini': {\n",
        "            'predicted_answers': ['A', 'C'],\n",
        "            'justification': \"\"\"Analyse pharmacologique:\n",
        "            - Option A: M√©canisme principal des IEC ‚úì\n",
        "            - Option C: Cons√©quence directe de l'inhibition ‚úì\n",
        "            - Option D: Effet secondaire mais pas m√©canisme principal\n",
        "            - Options B, E: M√©canismes d'autres classes\"\"\",\n",
        "            'confidence': '√âlev√©e'\n",
        "        },\n",
        "        'claude': {\n",
        "            'predicted_answers': ['A', 'C', 'D'],\n",
        "            'justification': \"\"\"Analyse rigoureuse des m√©canismes:\n",
        "            1. Inhibition de l'ACE (A) - m√©canisme primaire\n",
        "            2. R√©duction angiotensine II (C) - cons√©quence directe\n",
        "            3. Effet sur bradykinine (D) - m√©canisme contributeur\n",
        "            Conform√©ment aux donn√©es pharmacocin√©tiques √©tablies.\"\"\",\n",
        "            'confidence': '√âlev√©e'\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    return simulated_responses\n",
        "\n",
        "# Simulation pour notre exemple\n",
        "llm_responses = simulate_llm_responses(example_question)\n",
        "\n",
        "# Comparaison avec le mod√®le fine-tun√©\n",
        "def compare_with_finetuned(question_text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Compare les pr√©dictions du mod√®le fine-tun√© avec le prompting\n",
        "    \"\"\"\n",
        "    # Formatage de la question comme dans le dataset\n",
        "    formatted_question = f\"\"\"{example_question['question']}\n",
        "A) {example_question['answerA']}\n",
        "B) {example_question['answerB']}\n",
        "C) {example_question['answerC']}\n",
        "D) {example_question['answerD']}\n",
        "E) {example_question['answerE']}\"\"\"\n",
        "    \n",
        "    # Tokenisation et pr√©diction\n",
        "    inputs = tokenizer(formatted_question, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.sigmoid(outputs.logits)\n",
        "        \n",
        "    # Conversion en pr√©dictions binaires\n",
        "    predicted_labels = (predictions > 0.5).int().squeeze().tolist()\n",
        "    predicted_options = [option_names[i] for i, pred in enumerate(predicted_labels) if pred == 1]\n",
        "    \n",
        "    return {\n",
        "        'predicted_answers': predicted_options,\n",
        "        'probabilities': predictions.squeeze().tolist(),\n",
        "        'confidence': '√âlev√©e' if max(predictions.squeeze().tolist()) > 0.8 else 'Mod√©r√©e'\n",
        "    }\n",
        "\n",
        "# Pr√©diction du mod√®le fine-tun√©\n",
        "finetuned_prediction = compare_with_finetuned(example_question['question'], model, tokenizer)\n",
        "\n",
        "print(\"\\n=== COMPARAISON DES APPROCHES ===\")\n",
        "print(f\"\\nQuestion: {example_question['question']}\")\n",
        "print(f\"\\nR√©ponse correcte attendue: A, C, D\")\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"MOD√àLE FINE-TUN√â (CamemBERT):\")\n",
        "print(f\"  Pr√©dictions: {', '.join(finetuned_prediction['predicted_answers'])}\")\n",
        "print(f\"  Probabilit√©s: {[f'{p:.3f}' for p in finetuned_prediction['probabilities']]}\")\n",
        "print(f\"  Confiance: {finetuned_prediction['confidence']}\")\n",
        "\n",
        "for model_name, response in llm_responses.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"PROMPTING - {model_name.upper()}:\")\n",
        "    print(f\"  Pr√©dictions: {', '.join(response['predicted_answers'])}\")\n",
        "    print(f\"  Justification: {response['justification'][:150]}...\")\n",
        "    print(f\"  Confiance: {response['confidence']}\")\n",
        "\n",
        "# Analyse de concordance\n",
        "correct_answers = set(['A', 'C', 'D'])\n",
        "finetuned_set = set(finetuned_prediction['predicted_answers'])\n",
        "\n",
        "print(f\"\\n=== ANALYSE DE PERFORMANCE ===\")\n",
        "print(f\"R√©ponses correctes: {', '.join(sorted(correct_answers))}\")\n",
        "print(f\"\\nPr√©cision par approche:\")\n",
        "\n",
        "# Calcul de la pr√©cision\n",
        "def calculate_precision_recall(predicted, correct):\n",
        "    predicted_set = set(predicted)\n",
        "    correct_set = set(correct)\n",
        "    \n",
        "    if len(predicted_set) == 0:\n",
        "        precision = 0\n",
        "    else:\n",
        "        precision = len(predicted_set & correct_set) / len(predicted_set)\n",
        "    \n",
        "    if len(correct_set) == 0:\n",
        "        recall = 0\n",
        "    else:\n",
        "        recall = len(predicted_set & correct_set) / len(correct_set)\n",
        "    \n",
        "    if precision + recall == 0:\n",
        "        f1 = 0\n",
        "    else:\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    \n",
        "    return precision, recall, f1\n",
        "\n",
        "approaches = {\n",
        "    'Fine-tun√©': finetuned_prediction['predicted_answers'],\n",
        "    'ChatGPT': llm_responses['chatgpt']['predicted_answers'],\n",
        "    'Gemini': llm_responses['gemini']['predicted_answers'],\n",
        "    'Claude': llm_responses['claude']['predicted_answers']\n",
        "}\n",
        "\n",
        "for approach_name, predictions in approaches.items():\n",
        "    precision, recall, f1 = calculate_precision_recall(predictions, correct_answers)\n",
        "    print(f\"  {approach_name:<12}: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Applications Cliniques et Cas d'Usage\n",
        "\n",
        "D√©monstration d'applications pratiques de la classification de textes m√©dicaux fran√ßais dans des contextes cliniques r√©els."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Applications cliniques pratiques\n",
        "print(\"=== APPLICATIONS CLINIQUES PRATIQUES ===\")\n",
        "\n",
        "class MedicalTextClassificationPipeline:\n",
        "    \"\"\"\n",
        "    Pipeline complet pour classification de textes m√©dicaux fran√ßais\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model, tokenizer, threshold=0.5):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.threshold = threshold\n",
        "        self.option_names = ['A', 'B', 'C', 'D', 'E']\n",
        "        \n",
        "    def classify_medical_question(self, question, options):\n",
        "        \"\"\"\n",
        "        Classifie une question m√©dicale avec ses options\n",
        "        \"\"\"\n",
        "        # Formatage de la question\n",
        "        formatted_text = f\"{question}\\n\"\n",
        "        for i, option in enumerate(options):\n",
        "            formatted_text += f\"{self.option_names[i]}) {option}\\n\"\n",
        "        \n",
        "        # Tokenisation et pr√©diction\n",
        "        inputs = self.tokenizer(\n",
        "            formatted_text.strip(),\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            probabilities = torch.sigmoid(outputs.logits).squeeze().tolist()\n",
        "        \n",
        "        # Analyse des r√©sultats\n",
        "        predictions = [(prob > self.threshold) for prob in probabilities]\n",
        "        correct_options = [self.option_names[i] for i, pred in enumerate(predictions) if pred]\n",
        "        \n",
        "        # Calcul de confiance\n",
        "        max_prob = max(probabilities)\n",
        "        if max_prob > 0.8:\n",
        "            confidence = \"√âlev√©e\"\n",
        "        elif max_prob > 0.6:\n",
        "            confidence = \"Mod√©r√©e\"\n",
        "        else:\n",
        "            confidence = \"Faible\"\n",
        "        \n",
        "        return {\n",
        "            'correct_answers': correct_options,\n",
        "            'probabilities': dict(zip(self.option_names, probabilities)),\n",
        "            'confidence': confidence,\n",
        "            'max_probability': max_prob\n",
        "        }\n",
        "    \n",
        "    def batch_classify_exam(self, exam_questions):\n",
        "        \"\"\"\n",
        "        Classifie un examen complet (lot de questions)\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        for i, question_data in enumerate(exam_questions):\n",
        "            result = self.classify_medical_question(\n",
        "                question_data['question'],\n",
        "                question_data['options']\n",
        "            )\n",
        "            result['question_id'] = i + 1\n",
        "            results.append(result)\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def generate_exam_report(self, results):\n",
        "        \"\"\"\n",
        "        G√©n√®re un rapport d'analyse d'examen\n",
        "        \"\"\"\n",
        "        total_questions = len(results)\n",
        "        high_confidence = sum(1 for r in results if r['confidence'] == '√âlev√©e')\n",
        "        questions_with_answers = sum(1 for r in results if len(r['correct_answers']) > 0)\n",
        "        \n",
        "        report = f\"\"\"\n",
        "=== RAPPORT D'ANALYSE D'EXAMEN M√âDICAL ===\n",
        "\n",
        "STATISTIQUES GLOBALES:\n",
        "  Total de questions: {total_questions}\n",
        "  Questions avec r√©ponses identifi√©es: {questions_with_answers} ({questions_with_answers/total_questions*100:.1f}%)\n",
        "  Pr√©dictions haute confiance: {high_confidence} ({high_confidence/total_questions*100:.1f}%)\n",
        "\n",
        "R√âPARTITION PAR CONFIANCE:\n",
        "\"\"\"\n",
        "        \n",
        "        confidence_counts = {'√âlev√©e': 0, 'Mod√©r√©e': 0, 'Faible': 0}\n",
        "        for result in results:\n",
        "            confidence_counts[result['confidence']] += 1\n",
        "        \n",
        "        for conf, count in confidence_counts.items():\n",
        "            percentage = (count / total_questions) * 100\n",
        "            report += f\"  {conf}: {count} questions ({percentage:.1f}%)\\n\"\n",
        "        \n",
        "        return report\n",
        "\n",
        "# Initialisation du pipeline\n",
        "classification_pipeline = MedicalTextClassificationPipeline(model, tokenizer)\n",
        "\n",
        "print(\"Pipeline de classification m√©dicale initialis√©\")\n",
        "print(f\"Mod√®le: {type(model).__name__}\")\n",
        "print(f\"Tokenizer: {type(tokenizer).__name__}\")\n",
        "print(f\"Seuil de classification: {classification_pipeline.threshold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cas d'usage 1: Aide √† la pr√©paration d'examens\n",
        "print(\"=== CAS D'USAGE 1: AIDE √Ä LA PR√âPARATION D'EXAMENS ===\")\n",
        "\n",
        "# Simulation d'un examen de pharmacie\n",
        "exam_questions = [\n",
        "    {\n",
        "        'question': \"Quels sont les effets ind√©sirables majeurs des cortico√Ødes au long terme?\",\n",
        "        'options': [\n",
        "            \"Ost√©oporose et fractures\",\n",
        "            \"Hypertension art√©rielle\",\n",
        "            \"Diab√®te secondaire\",\n",
        "            \"Insuffisance surr√©nalienne\",\n",
        "            \"Am√©lioration de l'immunit√©\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        'question': \"Dans quelles situations cliniques utilise-t-on pr√©f√©rentiellement la warfarine?\",\n",
        "        'options': [\n",
        "            \"Fibrillation auriculaire\",\n",
        "            \"Hypertension art√©rielle\",\n",
        "            \"Proth√®ses valvulaires m√©caniques\",\n",
        "            \"Thrombose veineuse profonde\",\n",
        "            \"Infarctus du myocarde aigu\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        'question': \"Quels param√®tres biologiques surveiller sous traitement par lithium?\",\n",
        "        'options': [\n",
        "            \"Lithi√©mie\",\n",
        "            \"Fonction r√©nale (cr√©atinine)\",\n",
        "            \"Fonction thyro√Ødienne (TSH)\",\n",
        "            \"Glyc√©mie √† jeun\",\n",
        "            \"Transaminases h√©patiques\"\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Classification de l'examen\n",
        "exam_results = classification_pipeline.batch_classify_exam(exam_questions)\n",
        "\n",
        "# Affichage des r√©sultats d√©taill√©s\n",
        "for i, (question_data, result) in enumerate(zip(exam_questions, exam_results)):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"QUESTION {i+1}:\")\n",
        "    print(f\"{question_data['question']}\")\n",
        "    print(f\"\\nOptions:\")\n",
        "    for j, option in enumerate(question_data['options']):\n",
        "        option_letter = classification_pipeline.option_names[j]\n",
        "        prob = result['probabilities'][option_letter]\n",
        "        is_correct = option_letter in result['correct_answers']\n",
        "        status = \"‚úì CORRECT\" if is_correct else \"‚úó Incorrect\"\n",
        "        print(f\"  {option_letter}) {option} [{prob:.3f}] {status}\")\n",
        "    \n",
        "    print(f\"\\nR√©ponses correctes identifi√©es: {', '.join(result['correct_answers'])}\")\n",
        "    print(f\"Confiance: {result['confidence']} (max: {result['max_probability']:.3f})\")\n",
        "\n",
        "# G√©n√©ration du rapport d'examen\n",
        "exam_report = classification_pipeline.generate_exam_report(exam_results)\n",
        "print(f\"\\n{exam_report}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cas d'usage 2: Triage automatique de documents m√©dicaux\n",
        "print(\"=== CAS D'USAGE 2: TRIAGE AUTOMATIQUE DE DOCUMENTS ===\")\n",
        "\n",
        "class MedicalDocumentTriager:\n",
        "    \"\"\"\n",
        "    Syst√®me de triage automatique pour documents m√©dicaux fran√ßais\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, classification_pipeline):\n",
        "        self.pipeline = classification_pipeline\n",
        "        \n",
        "        # D√©finition des cat√©gories de triage\n",
        "        self.triage_categories = {\n",
        "            'pharmacologie': ['m√©dicament', 'posologie', 'interaction', 'effet', 'traitement'],\n",
        "            'pathologie': ['maladie', 'sympt√¥me', 'diagnostic', 'syndrome', 'pathologie'],\n",
        "            'examens': ['analyse', 'pr√©l√®vement', 'radiographie', 'biologie', 'examen'],\n",
        "            'urgence': ['urgence', 'imm√©diat', 'critique', 'grave', 'aigu'],\n",
        "            'prevention': ['vaccination', 'pr√©vention', 'd√©pistage', 'surveillance', 'contr√¥le']\n",
        "        }\n",
        "    \n",
        "    def categorize_document(self, document_text):\n",
        "        \"\"\"\n",
        "        Cat√©gorise un document m√©dical par son contenu\n",
        "        \"\"\"\n",
        "        text_lower = document_text.lower()\n",
        "        \n",
        "        category_scores = {}\n",
        "        for category, keywords in self.triage_categories.items():\n",
        "            score = sum(1 for keyword in keywords if keyword in text_lower)\n",
        "            category_scores[category] = score\n",
        "        \n",
        "        # Cat√©gorie principale\n",
        "        main_category = max(category_scores, key=category_scores.get)\n",
        "        max_score = category_scores[main_category]\n",
        "        \n",
        "        # Niveau de priorit√© bas√© sur les mots-cl√©s d'urgence\n",
        "        urgency_words = self.triage_categories['urgence']\n",
        "        urgency_count = sum(1 for word in urgency_words if word in text_lower)\n",
        "        \n",
        "        if urgency_count > 0:\n",
        "            priority = \"√âLEV√âE\"\n",
        "        elif max_score > 2:\n",
        "            priority = \"MOD√âR√âE\"\n",
        "        else:\n",
        "            priority = \"NORMALE\"\n",
        "        \n",
        "        return {\n",
        "            'main_category': main_category,\n",
        "            'category_scores': category_scores,\n",
        "            'priority': priority,\n",
        "            'urgency_indicators': urgency_count\n",
        "        }\n",
        "    \n",
        "    def process_document_batch(self, documents):\n",
        "        \"\"\"\n",
        "        Traite un lot de documents pour triage\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        \n",
        "        for i, doc in enumerate(documents):\n",
        "            categorization = self.categorize_document(doc['content'])\n",
        "            \n",
        "            result = {\n",
        "                'document_id': doc.get('id', f'DOC_{i+1}'),\n",
        "                'title': doc.get('title', f'Document {i+1}'),\n",
        "                'content_preview': doc['content'][:100] + '...',\n",
        "                'category': categorization['main_category'],\n",
        "                'priority': categorization['priority'],\n",
        "                'category_scores': categorization['category_scores']\n",
        "            }\n",
        "            results.append(result)\n",
        "        \n",
        "        # Tri par priorit√©\n",
        "        priority_order = {'√âLEV√âE': 3, 'MOD√âR√âE': 2, 'NORMALE': 1}\n",
        "        results.sort(key=lambda x: priority_order[x['priority']], reverse=True)\n",
        "        \n",
        "        return results\n",
        "\n",
        "# Initialisation du syst√®me de triage\n",
        "triager = MedicalDocumentTriager(classification_pipeline)\n",
        "\n",
        "# Documents m√©dicaux de test\n",
        "test_documents = [\n",
        "    {\n",
        "        'id': 'DOC_001',\n",
        "        'title': 'Protocole antibiotique',\n",
        "        'content': 'Prescription d\\'amoxicilline pour infection respiratoire. Posologie: 1g trois fois par jour pendant 7 jours. Surveillance des effets ind√©sirables gastro-intestinaux.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'DOC_002',\n",
        "        'title': 'Urgence cardiologique',\n",
        "        'content': 'Patient en d√©tresse respiratoire aigu√´ avec douleurs thoraciques. Suspicion d\\'infarctus du myocarde. Prise en charge imm√©diate requise. ECG et troponines en urgence.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'DOC_003',\n",
        "        'title': 'R√©sultats de laboratoire',\n",
        "        'content': 'Analyses sanguines de contr√¥le: glyc√©mie, cr√©atinine, transaminases dans les normes. H√©moglobine l√©g√®rement diminu√©e. Contr√¥le √† pr√©voir dans 3 mois.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'DOC_004',\n",
        "        'title': 'Programme de vaccination',\n",
        "        'content': 'Mise √† jour du calendrier vaccinal. Vaccination contre la grippe saisonni√®re recommand√©e. Pr√©vention des infections chez les patients immunod√©prim√©s.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'DOC_005',\n",
        "        'title': 'Diagnostic diff√©rentiel',\n",
        "        'content': 'Syndrome f√©brile avec √©ruption cutan√©e. Diagnostic diff√©rentiel entre infection virale et r√©action allergique m√©dicamenteuse. Examens compl√©mentaires n√©cessaires.'\n",
        "    }\n",
        "]\n",
        "\n",
        "# Traitement du lot de documents\n",
        "triage_results = triager.process_document_batch(test_documents)\n",
        "\n",
        "print(\"\\n=== R√âSULTATS DU TRIAGE AUTOMATIQUE ===\")\n",
        "print(f\"Nombre de documents trait√©s: {len(triage_results)}\")\n",
        "print(f\"Tri√©s par ordre de priorit√© d√©croissante:\")\n",
        "\n",
        "for i, result in enumerate(triage_results, 1):\n",
        "    print(f\"\\n{i}. {result['document_id']} - {result['title']}\")\n",
        "    print(f\"   Priorit√©: {result['priority']}\")\n",
        "    print(f\"   Cat√©gorie: {result['category'].upper()}\")\n",
        "    print(f\"   Aper√ßu: {result['content_preview']}\")\n",
        "    print(f\"   Scores par cat√©gorie:\")\n",
        "    for cat, score in result['category_scores'].items():\n",
        "        if score > 0:\n",
        "            print(f\"     - {cat}: {score}\")\n",
        "\n",
        "# Statistiques du triage\n",
        "priority_stats = {'√âLEV√âE': 0, 'MOD√âR√âE': 0, 'NORMALE': 0}\n",
        "category_stats = {}\n",
        "\n",
        "for result in triage_results:\n",
        "    priority_stats[result['priority']] += 1\n",
        "    category = result['category']\n",
        "    category_stats[category] = category_stats.get(category, 0) + 1\n",
        "\n",
        "print(f\"\\n=== STATISTIQUES DU TRIAGE ===\")\n",
        "print(f\"R√©partition par priorit√©:\")\n",
        "for priority, count in priority_stats.items():\n",
        "    percentage = (count / len(triage_results)) * 100\n",
        "    print(f\"  {priority}: {count} documents ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\nR√©partition par cat√©gorie:\")\n",
        "for category, count in category_stats.items():\n",
        "    percentage = (count / len(triage_results)) * 100\n",
        "    print(f\"  {category.capitalize()}: {count} documents ({percentage:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R√©sum√© et Applications Futures\n",
        "\n",
        "### Comp√©tences Acquises\n",
        "\n",
        "Dans ce notebook, vous avez ma√Ætris√©:\n",
        "\n",
        "1. **Analyse de datasets m√©dicaux fran√ßais**\n",
        "   - Exploration du dataset FrenchMedMCQA\n",
        "   - Analyse du vocabulaire m√©dical sp√©cialis√©\n",
        "   - Pr√©paration pour classification multi-label\n",
        "\n",
        "2. **Classification multi-label avec CamemBERT**\n",
        "   - Configuration pour textes m√©dicaux fran√ßais\n",
        "   - Entra√Ænement optimis√© pour Google Colab\n",
        "   - M√©triques d'√©valuation sp√©cialis√©es\n",
        "\n",
        "3. **Comparaison fine-tuning vs prompting**\n",
        "   - Prompts optimis√©s pour ChatGPT, Gemini, Claude\n",
        "   - Analyse comparative des performances\n",
        "   - Avantages et limites de chaque approche\n",
        "\n",
        "4. **Applications cliniques pratiques**\n",
        "   - Pipeline de classification automatique\n",
        "   - Aide √† la pr√©paration d'examens\n",
        "   - Triage automatique de documents m√©dicaux\n",
        "\n",
        "### Applications M√©dicales Directes\n",
        "\n",
        "Ces comp√©tences vous permettront de:\n",
        "- **Automatiser l'analyse** de questions d'examens m√©dicaux\n",
        "- **Classer automatiquement** des documents cliniques\n",
        "- **Assister la formation** m√©dicale avec des outils IA\n",
        "- **Optimiser les workflows** hospitaliers par le triage automatique\n",
        "\n",
        "### Recommandations pour l'Utilisation Clinique\n",
        "\n",
        "1. **Validation m√©dicale requise**: Toujours faire valider les r√©sultats par un expert\n",
        "2. **Surveillance continue**: Monitorer les performances sur de nouvelles donn√©es\n",
        "3. **Mise √† jour r√©guli√®re**: R√©entra√Æner avec des donn√©es m√©dicales actualis√©es\n",
        "4. **Contexte fran√ßais**: Adapter aux sp√©cificit√©s de la m√©decine fran√ßaise\n",
        "\n",
        "### Prochaine √âtape\n",
        "\n",
        "Le prochain notebook vous enseignera l'**analyse compl√®te d'images radiologiques** avec TorchXRayVision, en utilisant les bases de traitement de donn√©es que vous venez d'acqu√©rir."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}