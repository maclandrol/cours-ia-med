{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/maclandrol/ab9a6ec3c96162e39c65c34e75596095/07_TorchXRayVision_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": "**Enseignant:** Emmanuel Noutahi, PhD",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial 2: Classification Avanc√©e de Radiographies avec TorchXRayVision\n",
        "## Multi-Pathologies et Comparaison de Mod√®les\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Objectifs de ce Tutorial\n",
        "\n",
        "Dans ce deuxi√®me tutorial, vous allez ma√Ætriser :\n",
        "\n",
        "1. **Classification multi-pathologies** avec diff√©rents mod√®les\n",
        "2. **Comparaison de performances** entre architectures\n",
        "3. **Analyse de cas cliniques** complexes\n",
        "4. **M√©triques d'√©valuation** avanc√©es\n",
        "5. **Interpr√©tation clinique** des r√©sultats\n",
        "6. **Workflow hospitalier** int√©gr√©\n",
        "\n",
        "---\n",
        "\n",
        "## üè• Pr√©requis\n",
        "\n",
        "Ce tutorial fait suite au **Tutorial 1**. Assurez-vous d'avoir :\n",
        "- ‚úÖ Termin√© le Tutorial 1 (Introduction)\n",
        "- ‚úÖ TorchXRayVision install√© et configur√©\n",
        "- ‚úÖ Compr√©hension du preprocessing\n",
        "- ‚úÖ Bases de l'interpr√©tation IA\n",
        "\n",
        "---\n",
        "\n",
        "## üî¨ Introduction M√©dicale Avanc√©e\n",
        "\n",
        "### D√©fis de la Classification Multi-Pathologies\n",
        "\n",
        "En pratique clinique r√©elle, les radiographies pr√©sentent souvent :\n",
        "- **Pathologies multiples simultan√©es**\n",
        "- **Degr√©s de s√©v√©rit√© variables**\n",
        "- **Pr√©sentations atypiques**\n",
        "- **Art√©facts et limitations techniques**\n",
        "\n",
        "### üìä Enjeux Cliniques\n",
        "\n",
        "#### **Sensibilit√© vs Sp√©cificit√© :**\n",
        "- **Sensibilit√© √©lev√©e** : Ne pas manquer de pathologies (faux n√©gatifs)\n",
        "- **Sp√©cificit√© √©lev√©e** : √âviter les fausses alertes (faux positifs)\n",
        "- **Trade-off clinique** selon le contexte (urgences vs d√©pistage)\n",
        "\n",
        "#### **Impact des Mod√®les :**\n",
        "- **Mod√®les g√©n√©ralistes** : Performance globale √©quilibr√©e\n",
        "- **Mod√®les sp√©cialis√©s** : Excellence sur pathologies cibl√©es\n",
        "- **Ensembles de mod√®les** : Robustesse et fiabilit√© accrues\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Configuration Avanc√©e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration avanc√©e pour classification multi-mod√®les\n",
        "import sys\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üè• TUTORIAL 2: CLASSIFICATION AVANC√âE TORCHXRAYVISION\")\n",
        "print(\"=\" * 65)\n",
        "\n",
        "# V√©rifications syst√®me\n",
        "print(f\"\\nüîß Configuration syst√®me :\")\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"   ‚Ä¢ Environnement : Google Colab ‚úÖ\")\n",
        "    IN_COLAB = True\n",
        "else:\n",
        "    print(\"   ‚Ä¢ Environnement : Local\")\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Configuration GPU optimis√©e\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(f\"   ‚Ä¢ GPU : {torch.cuda.get_device_name(0)} ‚úÖ\")\n",
        "    print(f\"   ‚Ä¢ M√©moire : {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    \n",
        "    # Configuration CUDA optimis√©e\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    print(f\"   ‚Ä¢ CUDNN optimis√© : ‚úÖ\")\nelse:\n",
        "    device = \"cpu\"\n",
        "    print(f\"   ‚Ä¢ GPU : Non disponible\")\n",
        "    print(f\"   ‚Ä¢ Mode : CPU (plus lent pour multi-mod√®les)\")\n",
        "\n",
        "# Configuration pour reproducibilit√©\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "print(f\"\\nüéØ Dispositif s√©lectionn√© : {device}\")\n",
        "print(f\"üîÑ Reproductibilit√© : Activ√©e (seed=42)\")\n",
        "\n",
        "print(\"\\n‚úÖ Configuration avanc√©e termin√©e !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Importations et V√©rifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importations compl√®tes pour classification avanc√©e\n",
        "print(\"üì¶ IMPORTATION DES BIBLIOTH√àQUES AVANC√âES\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "try:\n",
        "    # Core libraries\n",
        "    import torchxrayvision as xrv\n",
        "    import torch\n",
        "    import torchvision\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from PIL import Image\n",
        "    import skimage\n",
        "    \n",
        "    # Advanced analysis\n",
        "    from sklearn.metrics import (\n",
        "        roc_curve, auc, confusion_matrix, \n",
        "        classification_report, precision_recall_curve\n",
        "    )\n",
        "    from scipy import stats, ndimage\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "    import json\n",
        "    import time\n",
        "    \n",
        "    print(\"‚úÖ Biblioth√®ques principales import√©es\")\n",
        "    print(\"‚úÖ M√©triques d'√©valuation charg√©es\")\n",
        "    print(\"‚úÖ Outils d'analyse statistique pr√™ts\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Erreur d'importation : {e}\")\n",
        "    print(\"üí° Installez les d√©pendances manquantes\")\n",
        "\n",
        "# Configuration matplotlib avanc√©e\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# Palette m√©dicale professionnelle\n",
        "medical_colors = {\n",
        "    'positive': '#FF4444',    # Rouge pour pathologies\n",
        "    'negative': '#44FF44',    # Vert pour normal\n",
        "    'uncertainty': '#FFAA44', # Orange pour incertain\n",
        "    'neutral': '#4444FF',     # Bleu pour neutre\n",
        "    'background': '#F0F0F0'   # Gris clair pour fond\n",
        "}\n",
        "\n",
        "print(\"\\nüé® Configuration d'affichage m√©dical appliqu√©e\")\n",
        "print(f\"üìä Version TorchXRayVision : {xrv.__version__}\")\n",
        "\n",
        "# Configuration de session\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        base_dir = '/content/drive/MyDrive/TorchXRayVision_Tutorials/'\n",
        "        tutorial_dir = f\"{base_dir}Tutorial_2_Classification/\"\n",
        "        session_dir = f\"{tutorial_dir}Session_{datetime.now().strftime('%Y%m%d_%H%M%S')}/\"\n",
        "        os.makedirs(session_dir, exist_ok=True)\n",
        "        print(f\"üìÅ Drive mont√© : {session_dir}\")\n",
        "    except:\n",
        "        session_dir = './tutorial_2_results/'\n",
        "        os.makedirs(session_dir, exist_ok=True)\nelse:\n",
        "    session_dir = './tutorial_2_results/'\n",
        "    os.makedirs(session_dir, exist_ok=True)\n",
        "    print(f\"üìÅ Dossier local : {session_dir}\")\n",
        "\n",
        "print(\"\\nüöÄ Pr√™t pour classification avanc√©e !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Chargement de Mod√®les Multiples\n",
        "\n",
        "Chargeons diff√©rents mod√®les pour comparaison de performances :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üß† CHARGEMENT DE MOD√àLES MULTIPLES\")\n",
        "print(\"=\" * 38)\n",
        "\n",
        "def load_multiple_models(device, detailed_info=True):\n",
        "    \"\"\"\n",
        "    Charge plusieurs mod√®les TorchXRayVision pour comparaison\n",
        "    \n",
        "    Cette approche multi-mod√®les permet :\n",
        "    - Comparaison de performances\n",
        "    - Validation crois√©e des r√©sultats\n",
        "    - Analyse de consensus\n",
        "    - Robustesse diagnostique\n",
        "    \"\"\"\n",
        "    \n",
        "    models = {}\n",
        "    model_info = {}\n",
        "    \n",
        "    if detailed_info:\n",
        "        print(\"\\nüìö Mod√®les √† charger :\")\n",
        "        print(\"   1Ô∏è‚É£ Mod√®le Universel (tous datasets)\")\n",
        "        print(\"   2Ô∏è‚É£ Mod√®le CheXpert (Stanford)\")\n",
        "        print(\"   3Ô∏è‚É£ Mod√®le NIH (National Institutes of Health)\")\n",
        "        print(\"   4Ô∏è‚É£ Mod√®le MIMIC-CXR (MIT)\")\n",
        "    \n",
        "    # 1. Mod√®le universel (entra√Æn√© sur tous les datasets)\n",
        "    print(\"\\nüîÑ Chargement du mod√®le universel...\")\n",
        "    try:\n",
        "        models['universel'] = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "        models['universel'].eval().to(device)\n",
        "        \n",
        "        model_info['universel'] = {\n",
        "            'name': 'Mod√®le Universel',\n",
        "            'architecture': 'DenseNet121',\n",
        "            'training_data': 'Tous datasets combin√©s',\n",
        "            'specialty': 'G√©n√©raliste',\n",
        "            'params': sum(p.numel() for p in models['universel'].parameters())\n",
        "        }\n",
        "        print(\"   ‚úÖ Mod√®le universel charg√©\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Erreur mod√®le universel : {e}\")\n",
        "    \n",
        "    # 2. Mod√®le CheXpert (Stanford)\n",
        "    print(\"\\nüéì Chargement du mod√®le CheXpert...\")\n",
        "    try:\n",
        "        models['chexpert'] = xrv.models.DenseNet(weights=\"densenet121-res224-chex\")\n",
        "        models['chexpert'].eval().to(device)\n",
        "        \n",
        "        model_info['chexpert'] = {\n",
        "            'name': 'CheXpert (Stanford)',\n",
        "            'architecture': 'DenseNet121',\n",
        "            'training_data': 'CheXpert dataset (224k images)',\n",
        "            'specialty': 'Pathologies thoraciques vari√©es',\n",
        "            'params': sum(p.numel() for p in models['chexpert'].parameters())\n",
        "        }\n",
        "        print(\"   ‚úÖ Mod√®le CheXpert charg√©\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Erreur mod√®le CheXpert : {e}\")\n",
        "    \n",
        "    # 3. Mod√®le NIH\n",
        "    print(\"\\nüèõÔ∏è Chargement du mod√®le NIH...\")\n",
        "    try:\n",
        "        models['nih'] = xrv.models.DenseNet(weights=\"densenet121-res224-nih\")\n",
        "        models['nih'].eval().to(device)\n",
        "        \n",
        "        model_info['nih'] = {\n",
        "            'name': 'NIH ChestX-ray',\n",
        "            'architecture': 'DenseNet121',\n",
        "            'training_data': 'NIH ChestX-ray8 (112k images)',\n",
        "            'specialty': '14 pathologies thoraciques',\n",
        "            'params': sum(p.numel() for p in models['nih'].parameters())\n",
        "        }\n",
        "        print(\"   ‚úÖ Mod√®le NIH charg√©\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Erreur mod√®le NIH : {e}\")\n",
        "    \n",
        "    # 4. Mod√®le MIMIC (si disponible)\n",
        "    print(\"\\nüè• Tentative chargement mod√®le MIMIC...\")\n",
        "    try:\n",
        "        models['mimic'] = xrv.models.DenseNet(weights=\"densenet121-res224-mimic_ch\")\n",
        "        models['mimic'].eval().to(device)\n",
        "        \n",
        "        model_info['mimic'] = {\n",
        "            'name': 'MIMIC-CXR (MIT)',\n",
        "            'architecture': 'DenseNet121',\n",
        "            'training_data': 'MIMIC-CXR (377k images)',\n",
        "            'specialty': 'Donn√©es hospitali√®res r√©elles',\n",
        "            'params': sum(p.numel() for p in models['mimic'].parameters())\n",
        "        }\n",
        "        print(\"   ‚úÖ Mod√®le MIMIC charg√©\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Mod√®le MIMIC non disponible : {e}\")\n",
        "    \n",
        "    if detailed_info:\n",
        "        print(f\"\\nüìä R√©sum√© des mod√®les charg√©s :\")\n",
        "        print(f\"   ‚Ä¢ Nombre total : {len(models)}\")\n",
        "        \n",
        "        for model_key, info in model_info.items():\n",
        "            if model_key in models:\n",
        "                params_millions = info['params'] / 1e6\n",
        "                print(f\"   ‚Ä¢ {info['name']}: {params_millions:.1f}M param√®tres\")\n",
        "    \n",
        "    return models, model_info\n",
        "\n",
        "# Chargement des mod√®les\n",
        "print(\"üöÄ D√©marrage du chargement multi-mod√®les...\")\n",
        "start_time = time.time()\n",
        "\n",
        "models_dict, models_info = load_multiple_models(device, detailed_info=True)\n",
        "\n",
        "loading_time = time.time() - start_time\n",
        "print(f\"\\n‚è±Ô∏è Temps de chargement : {loading_time:.2f} secondes\")\n",
        "print(f\"‚úÖ {len(models_dict)} mod√®les pr√™ts pour analyse comparative !\")\n",
        "\n",
        "# V√©rification des pathologies communes\n",
        "if models_dict:\n",
        "    first_model = list(models_dict.values())[0]\n",
        "    pathologies = first_model.pathologies\n",
        "    print(f\"\\nü©∫ Pathologies analysables : {len(pathologies)}\")\n",
        "    \n",
        "    # Groupement par cat√©gories cliniques\n",
        "    infectious = [p for p in pathologies if any(term in p.lower() for term in ['pneumonia', 'tuberculosis'])]\n",
        "    structural = [p for p in pathologies if any(term in p.lower() for term in ['pneumothorax', 'cardiomegaly', 'effusion'])]\n",
        "    \n",
        "    print(f\"   ‚Ä¢ Maladies infectieuses : {len(infectious)}\")\n",
        "    print(f\"   ‚Ä¢ Anomalies structurelles : {len(structural)}\")\n",
        "    print(f\"   ‚Ä¢ Autres pathologies : {len(pathologies) - len(infectious) - len(structural)}\")\n",
        "\n",
        "print(\"\\nüéØ Pr√™t pour classification comparative !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üñºÔ∏è Cr√©ation de Cas Cliniques Vari√©s\n",
        "\n",
        "Cr√©ons plusieurs radiographies repr√©sentant diff√©rents cas cliniques :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üñºÔ∏è CR√âATION DE CAS CLINIQUES VARI√âS\")\n",
        "print(\"=\" * 38)\n",
        "\n",
        "def create_clinical_case_xray(case_type, size=224, severity='moderate'):\n",
        "    \"\"\"\n",
        "    Cr√©e des radiographies repr√©sentant diff√©rents cas cliniques\n",
        "    \n",
        "    Cases types :\n",
        "    - 'normal' : Radiographie normale\n",
        "    - 'pneumonia' : Pneumonie (consolidation)\n",
        "    - 'cardiomegaly' : Cardiom√©galie\n",
        "    - 'pneumothorax' : Pneumothorax\n",
        "    - 'pleural_effusion' : √âpanchement pleural\n",
        "    - 'complex' : Cas complexe multi-pathologies\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"   üèóÔ∏è Cr√©ation cas {case_type} (s√©v√©rit√©: {severity})...\")\n",
        "    \n",
        "    # Image de base\n",
        "    img = np.zeros((size, size), dtype=np.float32)\n",
        "    center_x, center_y = size // 2, size // 2\n",
        "    \n",
        "    # Structures anatomiques de base\n",
        "    \n",
        "    # 1. Poumons normaux\n",
        "    lung_intensity = 0.3\n",
        "    \n",
        "    # Poumon droit\n",
        "    right_lung_x = int(0.3 * size)\n",
        "    right_lung_y = int(0.4 * size)\n",
        "    right_lung_h = int(0.25 * size)\n",
        "    right_lung_w = int(0.12 * size)\n",
        "    \n",
        "    rr1, cc1 = skimage.draw.ellipse(right_lung_y, right_lung_x, \n",
        "                                   right_lung_h, right_lung_w, shape=img.shape)\n",
        "    img[rr1, cc1] = lung_intensity\n",
        "    \n",
        "    # Poumon gauche\n",
        "    left_lung_x = int(0.7 * size)\n",
        "    left_lung_y = int(0.4 * size)\n",
        "    left_lung_h = int(0.23 * size)\n",
        "    left_lung_w = int(0.12 * size)\n",
        "    \n",
        "    rr2, cc2 = skimage.draw.ellipse(left_lung_y, left_lung_x,\n",
        "                                   left_lung_h, left_lung_w, shape=img.shape)\n",
        "    img[rr2, cc2] = lung_intensity\n",
        "    \n",
        "    # 2. C≈ìur (taille selon pathologie)\n",
        "    if case_type == 'cardiomegaly':\n",
        "        if severity == 'mild':\n",
        "            heart_size_factor = 1.2\n",
        "        elif severity == 'moderate':\n",
        "            heart_size_factor = 1.5\n",
        "        else:  # severe\n",
        "            heart_size_factor = 1.8\n",
        "    else:\n",
        "        heart_size_factor = 1.0\n",
        "    \n",
        "    heart_w = int(0.1 * size * heart_size_factor)\n",
        "    heart_h = int(0.08 * size * heart_size_factor)\n",
        "    heart_x = int(0.48 * size)\n",
        "    heart_y = int(0.6 * size)\n",
        "    \n",
        "    rr3, cc3 = skimage.draw.ellipse(heart_y, heart_x, heart_h, heart_w, shape=img.shape)\n",
        "    img[rr3, cc3] = 0.6\n",
        "    \n",
        "    # 3. Colonne vert√©brale\n",
        "    spine_width = int(0.025 * size)\n",
        "    spine_start = int(0.1 * size)\n",
        "    spine_end = int(0.9 * size)\n",
        "    \n",
        "    for y in range(spine_start, spine_end):\n",
        "        img[y, center_x-spine_width:center_x+spine_width] = 0.8\n",
        "    \n",
        "    # 4. C√¥tes\n",
        "    for rib_level in range(8):\n",
        "        rib_y = int(0.15 * size) + rib_level * int(0.07 * size)\n",
        "        rib_curve = int(0.03 * size)\n",
        "        \n",
        "        # C√¥tes droites et gauches\n",
        "        for x in range(int(0.05 * size), int(0.95 * size)):\n",
        "            if x < center_x:\n",
        "                curve_offset = int(rib_curve * np.sin(np.pi * (x - 0.05 * size) / (0.45 * size)))\n",
        "            else:\n",
        "                curve_offset = int(rib_curve * np.sin(np.pi * (0.95 * size - x) / (0.45 * size)))\n",
        "            \n",
        "            y_rib = rib_y + curve_offset\n",
        "            if 0 <= y_rib < size:\n",
        "                img[y_rib:y_rib+2, x:x+1] = 0.7\n",
        "    \n",
        "    # 5. Pathologies sp√©cifiques\n",
        "    \n",
        "    if case_type == 'pneumonia':\n",
        "        # Consolidation pneumonique\n",
        "        pneumo_intensity = 0.75 if severity == 'mild' else 0.85\n",
        "        pneumo_size = 0.08 if severity == 'mild' else 0.12\n",
        "        \n",
        "        pneumo_y = int(0.35 * size)\n",
        "        pneumo_x = int(0.25 * size)\n",
        "        pneumo_h = int(pneumo_size * size)\n",
        "        pneumo_w = int(pneumo_size * 0.8 * size)\n",
        "        \n",
        "        rr_pneumo, cc_pneumo = skimage.draw.ellipse(pneumo_y, pneumo_x,\n",
        "                                                   pneumo_h, pneumo_w, shape=img.shape)\n",
        "        img[rr_pneumo, cc_pneumo] = pneumo_intensity\n",
        "        \n",
        "        # Bronchogramme a√©rique (signe caract√©ristique)\n",
        "        for i in range(3):\n",
        "            broncho_y = pneumo_y + (i-1) * 5\n",
        "            broncho_x_start = pneumo_x - 10\n",
        "            broncho_x_end = pneumo_x + 10\n",
        "            if 0 <= broncho_y < size:\n",
        "                img[broncho_y, max(0, broncho_x_start):min(size, broncho_x_end)] = 0.4\n",
        "    \n",
        "    elif case_type == 'pneumothorax':\n",
        "        # Ligne pleurale visible\n",
        "        pneumo_line_x = int(0.15 * size) if severity != 'mild' else int(0.18 * size)\n",
        "        pneumo_start_y = int(0.2 * size)\n",
        "        pneumo_end_y = int(0.7 * size)\n",
        "        \n",
        "        # Ligne de d√©collement pleural\n",
        "        img[pneumo_start_y:pneumo_end_y, pneumo_line_x:pneumo_line_x+2] = 0.9\n",
        "        \n",
        "        # Zone de d√©collement (hyperclart√©)\n",
        "        img[pneumo_start_y:pneumo_end_y, int(0.05 * size):pneumo_line_x] = 0.1\n",
        "        \n",
        "        # Affaissement pulmonaire\n",
        "        collapse_factor = 0.7 if severity == 'mild' else 0.5\n",
        "        affected_lung = img[pneumo_start_y:pneumo_end_y, pneumo_line_x:int(0.5 * size)]\n",
        "        img[pneumo_start_y:pneumo_end_y, pneumo_line_x:int(0.5 * size)] = affected_lung * collapse_factor\n",
        "    \n",
        "    elif case_type == 'pleural_effusion':\n",
        "        # √âpanchement pleural (opacit√© basale)\n",
        "        effusion_height = int(0.15 * size) if severity == 'mild' else int(0.25 * size)\n",
        "        effusion_y_start = int(0.8 * size) - effusion_height\n",
        "        effusion_y_end = int(0.8 * size)\n",
        "        \n",
        "        # C√¥t√© droit (plus fr√©quent)\n",
        "        effusion_x_start = int(0.1 * size)\n",
        "        effusion_x_end = int(0.5 * size)\n",
        "        \n",
        "        # Opacit√© hydrique avec ligne de Damoiseau\n",
        "        for y in range(effusion_y_start, effusion_y_end):\n",
        "            # Ligne concave caract√©ristique\n",
        "            curve_offset = int(0.05 * size * np.sin(np.pi * (y - effusion_y_start) / effusion_height))\n",
        "            x_limit = effusion_x_end - curve_offset\n",
        "            img[y, effusion_x_start:min(size, x_limit)] = 0.8\n",
        "    \n",
        "    elif case_type == 'complex':\n",
        "        # Cas complexe : Cardiom√©galie + √©panchement + consolidation\n",
        "        # D√©j√† cardiom√©galie par le facteur 1.3\n",
        "        \n",
        "        # Petit √©panchement\n",
        "        small_effusion_height = int(0.1 * size)\n",
        "        effusion_start = int(0.75 * size)\n",
        "        img[effusion_start:effusion_start+small_effusion_height, int(0.1*size):int(0.4*size)] = 0.75\n",
        "        \n",
        "        # Petite consolidation\n",
        "        small_consolidation_y = int(0.3 * size)\n",
        "        small_consolidation_x = int(0.7 * size)\n",
        "        rr_small, cc_small = skimage.draw.ellipse(small_consolidation_y, small_consolidation_x,\n",
        "                                                 int(0.05 * size), int(0.04 * size), shape=img.shape)\n",
        "        img[rr_small, cc_small] = 0.7\n",
        "    \n",
        "    # 6. Post-processing r√©aliste\n",
        "    \n",
        "    # Bruit radiographique\n",
        "    noise = np.random.normal(0, 0.04, img.shape)\n",
        "    img = img + noise\n",
        "    \n",
        "    # Lissage gaussien (flou radiographique)\n",
        "    img = ndimage.gaussian_filter(img, sigma=0.8)\n",
        "    \n",
        "    # Normalisation finale\n",
        "    img = np.clip(img, 0, 1)\n",
        "    \n",
        "    print(f\"   ‚úÖ Cas {case_type} cr√©√© avec succ√®s\")\n",
        "    \n",
        "    return img\n",
        "\n",
        "# Cr√©ation de la collection de cas cliniques\n",
        "print(\"\\nüèóÔ∏è Cr√©ation de la biblioth√®que de cas cliniques...\")\n",
        "\n",
        "clinical_cases = {\n",
        "    'normal': {\n",
        "        'image': create_clinical_case_xray('normal'),\n",
        "        'description': 'Radiographie thoracique normale',\n",
        "        'expected_findings': ['Normal'],\n",
        "        'clinical_context': 'Bilan de routine, patient asymptomatique'\n",
        "    },\n",
        "    'pneumonie_moderee': {\n",
        "        'image': create_clinical_case_xray('pneumonia', severity='moderate'),\n",
        "        'description': 'Pneumonie lobaire droite mod√©r√©e',\n",
        "        'expected_findings': ['Pneumonia', 'Infiltration'],\n",
        "        'clinical_context': 'Fi√®vre, toux productive, dyspn√©e'\n",
        "    },\n",
        "    'cardiomegalie': {\n",
        "        'image': create_clinical_case_xray('cardiomegaly', severity='moderate'),\n",
        "        'description': 'Cardiom√©galie mod√©r√©e',\n",
        "        'expected_findings': ['Cardiomegaly', 'Enlarged Cardiomediastinum'],\n",
        "        'clinical_context': 'Dyspn√©e d\\'effort, ≈ìd√®mes membres inf√©rieurs'\n",
        "    },\n",
        "    'pneumothorax': {\n",
        "        'image': create_clinical_case_xray('pneumothorax', severity='moderate'),\n",
        "        'description': 'Pneumothorax spontan√© mod√©r√©',\n",
        "        'expected_findings': ['Pneumothorax'],\n",
        "        'clinical_context': 'Douleur thoracique brutale, dyspn√©e'\n",
        "    },\n",
        "    'epanchement_pleural': {\n",
        "        'image': create_clinical_case_xray('pleural_effusion', severity='moderate'),\n",
        "        'description': '√âpanchement pleural droit mod√©r√©',\n",
        "        'expected_findings': ['Pleural Effusion'],\n",
        "        'clinical_context': 'Dyspn√©e progressive, douleur pleurale'\n",
        "    },\n",
        "    'cas_complexe': {\n",
        "        'image': create_clinical_case_xray('complex'),\n",
        "        'description': 'Cas complexe multi-pathologies',\n",
        "        'expected_findings': ['Cardiomegaly', 'Pleural Effusion', 'Infiltration'],\n",
        "        'clinical_context': 'Insuffisance cardiaque d√©compens√©e'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ {len(clinical_cases)} cas cliniques cr√©√©s !\")\n",
        "\n",
        "# Affichage de la galerie de cas\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle(\"Galerie de Cas Cliniques - Tutorial 2\", fontsize=18, fontweight='bold')\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (case_name, case_data) in enumerate(clinical_cases.items()):\n",
        "    if i < len(axes):\n",
        "        axes[i].imshow(case_data['image'], cmap='gray')\n",
        "        axes[i].set_title(f\"{case_data['description']}\\n({case_name})\", \n",
        "                         fontweight='bold', fontsize=11)\n",
        "        axes[i].axis('off')\n",
        "        \n",
        "        # Contexte clinique en annotation\n",
        "        axes[i].text(0.02, 0.02, case_data['clinical_context'], \n",
        "                    transform=axes[i].transAxes, fontsize=9,\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
        "                    verticalalignment='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüéØ Cas cliniques pr√™ts pour classification comparative !\")\n",
        "print(\"üìö Prochaine √©tape : Analyse multi-mod√®les\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¨ Classification Multi-Mod√®les\n",
        "\n",
        "Analysons nos cas cliniques avec tous les mod√®les disponibles :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üî¨ CLASSIFICATION MULTI-MOD√àLES\")\n",
        "print(\"=\" * 34)\n",
        "\n",
        "def preprocess_for_models(image_array):\n",
        "    \"\"\"\n",
        "    Preprocessing standardis√© pour tous les mod√®les\n",
        "    \"\"\"\n",
        "    # Normalisation\n",
        "    if image_array.max() > 1:\n",
        "        img_norm = xrv.datasets.normalize(image_array, 255)\n",
        "    else:\n",
        "        img_norm = image_array\n",
        "    \n",
        "    # Format canal\n",
        "    img_channel = img_norm[None, ...]\n",
        "    \n",
        "    # Transformations TorchXRayVision\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        xrv.datasets.XRayCenterCrop(),\n",
        "        xrv.datasets.XRayResizer(224)\n",
        "    ])\n",
        "    \n",
        "    img_transformed = transform(img_channel)\n",
        "    \n",
        "    # Tenseur PyTorch\n",
        "    img_tensor = torch.from_numpy(img_transformed).float()\n",
        "    img_batch = img_tensor.unsqueeze(0)\n",
        "    \n",
        "    return img_batch, img_transformed\n",
        "\n",
        "def analyze_with_all_models(image_tensor, models_dict, pathologies):\n",
        "    \"\"\"\n",
        "    Analyse d'une image avec tous les mod√®les disponibles\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    for model_name, model in models_dict.items():\n",
        "        model.eval()\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Pr√©diction\n",
        "            raw_outputs = model(image_tensor)\n",
        "            probabilities = torch.sigmoid(raw_outputs)\n",
        "            probabilities_np = probabilities.cpu().numpy().squeeze()\n",
        "            \n",
        "            # Stockage des r√©sultats\n",
        "            results[model_name] = {\n",
        "                'probabilities': probabilities_np,\n",
        "                'pathologies': pathologies,\n",
        "                'positive_findings': [(pathologies[i], prob) for i, prob in enumerate(probabilities_np) if prob > 0.5]\n",
        "            }\n",
        "    \n",
        "    return results\n",
        "\n",
        "def create_comparative_analysis(case_results, case_info):\n",
        "    \"\"\"\n",
        "    Cr√©e une analyse comparative des r√©sultats multi-mod√®les\n",
        "    \"\"\"\n",
        "    print(f\"\\nüìä ANALYSE COMPARATIVE : {case_info['description']}\")\n",
        "    print(f\"-\" * 70)\n",
        "    \n",
        "    # Pathologies attendues\n",
        "    expected = case_info['expected_findings']\n",
        "    print(f\"üéØ Pathologies attendues : {', '.join(expected)}\")\n",
        "    print(f\"üè• Contexte clinique : {case_info['clinical_context']}\")\n",
        "    \n",
        "    # Analyse par mod√®le\n",
        "    print(f\"\\nüìã R√©sultats par mod√®le :\")\n",
        "    \n",
        "    all_model_results = {}\n",
        "    \n",
        "    for model_name, results in case_results.items():\n",
        "        model_info = models_info.get(model_name, {'name': model_name})\n",
        "        print(f\"\\n   üß† {model_info['name']} :\")\n",
        "        \n",
        "        positive_findings = results['positive_findings']\n",
        "        \n",
        "        if positive_findings:\n",
        "            print(f\"      üö® D√©tections positives ({len(positive_findings)}) :\")\n",
        "            for pathology, prob in sorted(positive_findings, key=lambda x: x[1], reverse=True):\n",
        "                print(f\"        ‚Ä¢ {pathology}: {prob:.3f} ({prob*100:.1f}%)\")\n",
        "        else:\n",
        "            print(f\"      ‚úÖ Aucune pathologie d√©tect√©e (seuil 50%)\")\n",
        "        \n",
        "        # V√©rification des pathologies attendues\n",
        "        expected_detected = []\n",
        "        for exp_pathology in expected:\n",
        "            for detected_pathology, prob in positive_findings:\n",
        "                if exp_pathology.lower() in detected_pathology.lower() or \\\n",
        "                   detected_pathology.lower() in exp_pathology.lower():\n",
        "                    expected_detected.append((exp_pathology, detected_pathology, prob))\n",
        "        \n",
        "        if expected_detected:\n",
        "            print(f\"      ‚úÖ Pathologies attendues d√©tect√©es : {len(expected_detected)}\")\n",
        "            for exp, det, prob in expected_detected:\n",
        "                print(f\"        ‚úì {exp} ‚Üí {det} ({prob:.3f})\")\n",
        "        else:\n",
        "            print(f\"      ‚ö†Ô∏è Pathologies attendues non d√©tect√©es\")\n",
        "        \n",
        "        # Stockage pour analyse globale\n",
        "        all_model_results[model_name] = results\n",
        "    \n",
        "    return all_model_results\n",
        "\n",
        "# Analyse de tous les cas avec tous les mod√®les\n",
        "print(\"\\nüöÄ D√©marrage de l'analyse comparative multi-mod√®les...\")\n",
        "print(f\"üìä {len(clinical_cases)} cas √ó {len(models_dict)} mod√®les = {len(clinical_cases) * len(models_dict)} analyses\")\n",
        "\n",
        "comprehensive_results = {}\n",
        "\n",
        "if models_dict:  # V√©rifier qu'il y a au moins un mod√®le\n",
        "    # R√©cup√©ration des pathologies du premier mod√®le\n",
        "    first_model = list(models_dict.values())[0]\n",
        "    pathologies = first_model.pathologies\n",
        "    \n",
        "    for case_name, case_data in clinical_cases.items():\n",
        "        print(f\"\\nüîÑ Analyse du cas : {case_name}...\")\n",
        "        \n",
        "        # Preprocessing\n",
        "        processed_tensor, processed_display = preprocess_for_models(case_data['image'])\n",
        "        \n",
        "        # Analyse avec tous les mod√®les\n",
        "        case_results = analyze_with_all_models(processed_tensor, models_dict, pathologies)\n",
        "        \n",
        "        # Analyse comparative\n",
        "        comparative_analysis = create_comparative_analysis(case_results, case_data)\n",
        "        \n",
        "        # Stockage\n",
        "        comprehensive_results[case_name] = {\n",
        "            'case_info': case_data,\n",
        "            'processed_image': processed_display,\n",
        "            'model_results': comparative_analysis\n",
        "        }\n",
        "        \n",
        "        print(f\"   ‚úÖ Cas {case_name} analys√©\")\n",
        "\nelse:\n",
        "    print(\"‚ùå Aucun mod√®le disponible pour l'analyse\")\n",
        "    print(\"üí° V√©rifiez la connexion internet et r√©essayez le chargement\")\n",
        "\nprint(f\"\\n‚úÖ Analyse multi-mod√®les termin√©e !\")\nprint(f\"üìä {len(comprehensive_results)} cas analys√©s\")\nprint(f\"üìö Prochaine √©tape : Visualisation comparative avanc√©e\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualisation Comparative Avanc√©e\n",
        "\n",
        "Cr√©ons des visualisations sophistiqu√©es pour analyser les performances :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìä VISUALISATION COMPARATIVE AVANC√âE\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "def create_advanced_comparative_visualization(comprehensive_results):\n",
        "    \"\"\"\n",
        "    Cr√©e des visualisations avanc√©es pour comparaison multi-mod√®les\n",
        "    \"\"\"\n",
        "    \n",
        "    if not comprehensive_results:\n",
        "        print(\"‚ùå Pas de r√©sultats √† visualiser\")\n",
        "        return\n",
        "    \n",
        "    # 1. Vue d'ensemble : Heatmap des pr√©dictions\n",
        "    print(\"\\nüìà Cr√©ation de la heatmap des pr√©dictions...\")\n",
        "    \n",
        "    # Collecte des donn√©es pour la heatmap\n",
        "    model_names = list(models_dict.keys()) if models_dict else []\n",
        "    case_names = list(comprehensive_results.keys())\n",
        "    \n",
        "    if model_names and case_names:\n",
        "        # Cr√©ation de la figure globale\n",
        "        fig = plt.figure(figsize=(20, 16))\n",
        "        gs = fig.add_gridspec(4, 3, height_ratios=[1, 1, 1, 0.3], hspace=0.4, wspace=0.3)\n",
        "        \n",
        "        # Heatmap globale des d√©tections positives\n",
        "        ax_heatmap = fig.add_subplot(gs[0, :])\n",
        "        \n",
        "        detection_matrix = np.zeros((len(case_names), len(model_names)))\n",
        "        \n",
        "        for i, case_name in enumerate(case_names):\n",
        "            case_results = comprehensive_results[case_name]['model_results']\n",
        "            for j, model_name in enumerate(model_names):\n",
        "                if model_name in case_results:\n",
        "                    positive_count = len(case_results[model_name]['positive_findings'])\n",
        "                    detection_matrix[i, j] = positive_count\n",
        "        \n",
        "        # Cr√©ation de la heatmap\n",
        "        im = ax_heatmap.imshow(detection_matrix, cmap='Reds', aspect='auto')\n",
        "        \n",
        "        # Configuration des axes\n",
        "        ax_heatmap.set_xticks(range(len(model_names)))\n",
        "        ax_heatmap.set_xticklabels([models_info.get(name, {'name': name})['name'] for name in model_names], \n",
        "                                  rotation=45, ha='right')\n",
        "        ax_heatmap.set_yticks(range(len(case_names)))\n",
        "        ax_heatmap.set_yticklabels([case.replace('_', ' ').title() for case in case_names])\n",
        "        \n",
        "        # Ajout des valeurs dans les cellules\n",
        "        for i in range(len(case_names)):\n",
        "            for j in range(len(model_names)):\n",
        "                text = ax_heatmap.text(j, i, int(detection_matrix[i, j]),\n",
        "                                     ha=\"center\", va=\"center\", color=\"white\", fontweight='bold')\n",
        "        \n",
        "        ax_heatmap.set_title(\"Nombre de D√©tections Positives par Cas et Mod√®le\", \n",
        "                           fontsize=14, fontweight='bold')\n",
        "        \n",
        "        # Colorbar\n",
        "        cbar = plt.colorbar(im, ax=ax_heatmap, orientation='horizontal', pad=0.1)\n",
        "        cbar.set_label('Nombre de pathologies d√©tect√©es', fontsize=12)\n",
        "        \n",
        "        # 2. Analyse de consensus par cas\n",
        "        for idx, (case_name, case_data) in enumerate(list(comprehensive_results.items())[:6]):\n",
        "            row = (idx // 3) + 1\n",
        "            col = idx % 3\n",
        "            ax_case = fig.add_subplot(gs[row, col])\n",
        "            \n",
        "            # Collecte des probabilit√©s max par mod√®le\n",
        "            model_max_probs = []\n",
        "            model_labels = []\n",
        "            \n",
        "            for model_name in model_names:\n",
        "                if model_name in case_data['model_results']:\n",
        "                    probs = case_data['model_results'][model_name]['probabilities']\n",
        "                    max_prob = np.max(probs)\n",
        "                    model_max_probs.append(max_prob)\n",
        "                    model_labels.append(models_info.get(model_name, {'name': model_name})['name'][:8])\n",
        "            \n",
        "            # Graphique en barres\n",
        "            colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold'][:len(model_max_probs)]\n",
        "            bars = ax_case.bar(range(len(model_max_probs)), model_max_probs, \n",
        "                              color=colors, alpha=0.7, edgecolor='black')\n",
        "            \n",
        "            ax_case.set_xticks(range(len(model_labels)))\n",
        "            ax_case.set_xticklabels(model_labels, rotation=45, ha='right', fontsize=10)\n",
        "            ax_case.set_ylabel('Prob. Max', fontsize=10)\n",
        "            ax_case.set_title(f\"{case_name.replace('_', ' ').title()}\", fontsize=11, fontweight='bold')\n",
        "            ax_case.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, linewidth=1)\n",
        "            ax_case.set_ylim(0, 1)\n",
        "            ax_case.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Valeurs sur les barres\n",
        "            for bar, prob in zip(bars, model_max_probs):\n",
        "                height = bar.get_height()\n",
        "                ax_case.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                           f'{prob:.2f}', ha='center', va='bottom', fontsize=9)\n",
        "        \n",
        "        # 3. L√©gende et statistiques globales\n",
        "        ax_legend = fig.add_subplot(gs[3, :])\n",
        "        ax_legend.axis('off')\n",
        "        \n",
        "        # Calcul de statistiques globales\n",
        "        total_analyses = len(case_names) * len(model_names)\n",
        "        total_detections = np.sum(detection_matrix)\n",
        "        avg_detections_per_case = np.mean(np.sum(detection_matrix, axis=1))\n",
        "        avg_detections_per_model = np.mean(np.sum(detection_matrix, axis=0))\n",
        "        \n",
        "        stats_text = f\"\"\"\n",
        "üìä STATISTIQUES GLOBALES DE L'ANALYSE COMPARATIVE\n",
        "\n",
        "‚Ä¢ Analyses totales effectu√©es : {total_analyses}\n",
        "‚Ä¢ D√©tections positives totales : {int(total_detections)}\n",
        "‚Ä¢ D√©tections moyennes par cas : {avg_detections_per_case:.1f}\n",
        "‚Ä¢ D√©tections moyennes par mod√®le : {avg_detections_per_model:.1f}\n",
        "\n",
        "üìà INTERPR√âTATION :\n",
        "‚Ä¢ Ligne rouge : Seuil de d√©tection (50%)\n",
        "‚Ä¢ Heatmap : Plus rouge = Plus de d√©tections\n",
        "‚Ä¢ Consensus √©lev√© = M√™me diagnostic par plusieurs mod√®les\n",
        "‚Ä¢ Divergences = Incertitudes diagnostiques\n",
        "        \"\"\"\n",
        "        \n",
        "        ax_legend.text(0.05, 0.95, stats_text, transform=ax_legend.transAxes,\n",
        "                      fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
        "                      bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
        "        \n",
        "        plt.suptitle(\"Analyse Comparative Multi-Mod√®les TorchXRayVision\", \n",
        "                    fontsize=18, fontweight='bold', y=0.98)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"‚úÖ Visualisation comparative cr√©√©e !\")\n",
        "    else:\n",
        "        print(\"‚ùå Donn√©es insuffisantes pour la visualisation\")\n",
        "\n",
        "# Cr√©ation des visualisations avanc√©es\n",
        "print(\"\\nüé® G√©n√©ration des visualisations avanc√©es...\")\n",
        "\n",
        "if comprehensive_results:\n",
        "    create_advanced_comparative_visualization(comprehensive_results)\nelse:\n",
        "    print(\"‚ö†Ô∏è Aucun r√©sultat √† visualiser\")\n",
        "    print(\"üí° Assurez-vous que les mod√®les sont charg√©s correctement\")\n",
        "\n",
        "print(\"\\nüéØ Visualisation comparative termin√©e !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Analyse de Performance D√©taill√©e\n",
        "\n",
        "Analysons en d√©tail les performances de chaque mod√®le :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìà ANALYSE DE PERFORMANCE D√âTAILL√âE\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "def calculate_model_performance_metrics(comprehensive_results):\n",
        "    \"\"\"\n",
        "    Calcule des m√©triques de performance d√©taill√©es pour chaque mod√®le\n",
        "    \"\"\"\n",
        "    \n",
        "    if not comprehensive_results or not models_dict:\n",
        "        print(\"‚ùå Pas de donn√©es pour calculer les m√©triques\")\n",
        "        return {}\n",
        "    \n",
        "    print(\"\\nüìä Calcul des m√©triques de performance...\")\n",
        "    \n",
        "    model_names = list(models_dict.keys())\n",
        "    performance_metrics = {}\n",
        "    \n",
        "    for model_name in model_names:\n",
        "        print(f\"\\nüîç Analyse du mod√®le : {models_info.get(model_name, {'name': model_name})['name']}\")\n",
        "        \n",
        "        # Collecte des donn√©es pour ce mod√®le\n",
        "        all_probabilities = []\n",
        "        all_expected_pathologies = []\n",
        "        all_detected_pathologies = []\n",
        "        case_performances = []\n",
        "        \n",
        "        for case_name, case_data in comprehensive_results.items():\n",
        "            if model_name in case_data['model_results']:\n",
        "                model_result = case_data['model_results'][model_name]\n",
        "                expected = case_data['case_info']['expected_findings']\n",
        "                detected = [finding[0] for finding in model_result['positive_findings']]\n",
        "                \n",
        "                # Stockage pour analyse globale\n",
        "                all_probabilities.extend(model_result['probabilities'])\n",
        "                all_expected_pathologies.extend(expected)\n",
        "                all_detected_pathologies.extend(detected)\n",
        "                \n",
        "                # Performance par cas\n",
        "                case_performance = {\n",
        "                    'case_name': case_name,\n",
        "                    'expected': expected,\n",
        "                    'detected': detected,\n",
        "                    'max_probability': np.max(model_result['probabilities']),\n",
        "                    'num_detections': len(detected),\n",
        "                    'true_positives': 0,\n",
        "                    'false_positives': len(detected),\n",
        "                    'false_negatives': len(expected)\n",
        "                }\n",
        "                \n",
        "                # Calcul des vrais positifs (correspondances approximatives)\n",
        "                for exp_path in expected:\n",
        "                    for det_path in detected:\n",
        "                        if (exp_path.lower() in det_path.lower() or \n",
        "                            det_path.lower() in exp_path.lower() or\n",
        "                            any(word in det_path.lower() for word in exp_path.lower().split())):\n",
        "                            case_performance['true_positives'] += 1\n",
        "                            case_performance['false_positives'] -= 1\n",
        "                            case_performance['false_negatives'] -= 1\n",
        "                            break\n",
        "                \n",
        "                case_performances.append(case_performance)\n",
        "        \n",
        "        # Calcul des m√©triques globales\n",
        "        total_tp = sum(cp['true_positives'] for cp in case_performances)\n",
        "        total_fp = sum(max(0, cp['false_positives']) for cp in case_performances)\n",
        "        total_fn = sum(max(0, cp['false_negatives']) for cp in case_performances)\n",
        "        \n",
        "        # M√©triques calcul√©es\n",
        "        precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "        recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        \n",
        "        # Statistiques des probabilit√©s\n",
        "        prob_stats = {\n",
        "            'mean': np.mean(all_probabilities),\n",
        "            'std': np.std(all_probabilities),\n",
        "            'max': np.max(all_probabilities),\n",
        "            'min': np.min(all_probabilities),\n",
        "            'median': np.median(all_probabilities)\n",
        "        }\n",
        "        \n",
        "        # Stockage des m√©triques\n",
        "        performance_metrics[model_name] = {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1_score,\n",
        "            'true_positives': total_tp,\n",
        "            'false_positives': total_fp,\n",
        "            'false_negatives': total_fn,\n",
        "            'probability_stats': prob_stats,\n",
        "            'case_performances': case_performances,\n",
        "            'total_cases': len(case_performances),\n",
        "            'avg_detections_per_case': np.mean([len(cp['detected']) for cp in case_performances])\n",
        "        }\n",
        "        \n",
        "        print(f\"   ‚úÖ M√©triques calcul√©es :\")\n",
        "        print(f\"      ‚Ä¢ Pr√©cision : {precision:.3f}\")\n",
        "        print(f\"      ‚Ä¢ Rappel : {recall:.3f}\")\n",
        "        print(f\"      ‚Ä¢ F1-Score : {f1_score:.3f}\")\n",
        "        print(f\"      ‚Ä¢ D√©tections/cas : {np.mean([len(cp['detected']) for cp in case_performances]):.1f}\")\n",
        "    \n",
        "    return performance_metrics\n",
        "\n",
        "def create_performance_comparison_chart(performance_metrics):\n",
        "    \"\"\"\n",
        "    Cr√©e un graphique de comparaison des performances\n",
        "    \"\"\"\n",
        "    if not performance_metrics:\n",
        "        return\n",
        "    \n",
        "    print(\"\\nüìä Cr√©ation du graphique de comparaison des performances...\")\n",
        "    \n",
        "    # Donn√©es pour les graphiques\n",
        "    model_names = list(performance_metrics.keys())\n",
        "    model_labels = [models_info.get(name, {'name': name})['name'] for name in model_names]\n",
        "    \n",
        "    precisions = [performance_metrics[name]['precision'] for name in model_names]\n",
        "    recalls = [performance_metrics[name]['recall'] for name in model_names]\n",
        "    f1_scores = [performance_metrics[name]['f1_score'] for name in model_names]\n",
        "    avg_detections = [performance_metrics[name]['avg_detections_per_case'] for name in model_names]\n",
        "    \n",
        "    # Cr√©ation de la figure\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Comparaison des Performances - Mod√®les TorchXRayVision', \n",
        "                fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Pr√©cision, Rappel, F1-Score\n",
        "    ax1 = axes[0, 0]\n",
        "    x_pos = np.arange(len(model_labels))\n",
        "    width = 0.25\n",
        "    \n",
        "    bars1 = ax1.bar(x_pos - width, precisions, width, label='Pr√©cision', \n",
        "                    color='lightblue', alpha=0.8, edgecolor='black')\n",
        "    bars2 = ax1.bar(x_pos, recalls, width, label='Rappel', \n",
        "                    color='lightgreen', alpha=0.8, edgecolor='black')\n",
        "    bars3 = ax1.bar(x_pos + width, f1_scores, width, label='F1-Score', \n",
        "                    color='lightcoral', alpha=0.8, edgecolor='black')\n",
        "    \n",
        "    ax1.set_xticks(x_pos)\n",
        "    ax1.set_xticklabels(model_labels, rotation=45, ha='right')\n",
        "    ax1.set_ylabel('Score', fontweight='bold')\n",
        "    ax1.set_title('M√©triques de Classification', fontweight='bold')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_ylim(0, 1)\n",
        "    \n",
        "    # Ajout des valeurs sur les barres\n",
        "    for bars in [bars1, bars2, bars3]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 2. D√©tections moyennes par cas\n",
        "    ax2 = axes[0, 1]\n",
        "    bars_det = ax2.bar(model_labels, avg_detections, \n",
        "                      color='gold', alpha=0.8, edgecolor='black')\n",
        "    ax2.set_title('D√©tections Moyennes par Cas', fontweight='bold')\n",
        "    ax2.set_ylabel('Nombre de D√©tections', fontweight='bold')\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    for bar in bars_det:\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
        "                f'{height:.1f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    # 3. Distribution des probabilit√©s\n",
        "    ax3 = axes[1, 0]\n",
        "    \n",
        "    for i, model_name in enumerate(model_names):\n",
        "        prob_stats = performance_metrics[model_name]['probability_stats']\n",
        "        \n",
        "        # Cr√©ation d'un violinplot simplifi√©\n",
        "        model_label = model_labels[i]\n",
        "        mean_prob = prob_stats['mean']\n",
        "        std_prob = prob_stats['std']\n",
        "        \n",
        "        ax3.bar(i, mean_prob, yerr=std_prob, capsize=5, \n",
        "               color=f'C{i}', alpha=0.7, edgecolor='black',\n",
        "               label=f'{model_label}: Œº={mean_prob:.3f}')\n",
        "    \n",
        "    ax3.set_xticks(range(len(model_labels)))\n",
        "    ax3.set_xticklabels(model_labels, rotation=45, ha='right')\n",
        "    ax3.set_ylabel('Probabilit√© Moyenne', fontweight='bold')\n",
        "    ax3.set_title('Distribution des Probabilit√©s', fontweight='bold')\n",
        "    ax3.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Seuil 50%')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    ax3.legend()\n",
        "    \n",
        "    # 4. Matrice de confusion agr√©g√©e\n",
        "    ax4 = axes[1, 1]\n",
        "    \n",
        "    # Calcul de la matrice de confusion moyenn√©e\n",
        "    confusion_data = []\n",
        "    confusion_labels = []\n",
        "    \n",
        "    for model_name in model_names:\n",
        "        metrics = performance_metrics[model_name]\n",
        "        tp = metrics['true_positives']\n",
        "        fp = metrics['false_positives']\n",
        "        fn = metrics['false_negatives']\n",
        "        \n",
        "        confusion_data.append([tp, fp, fn])\n",
        "        confusion_labels.append(models_info.get(model_name, {'name': model_name})['name'])\n",
        "    \n",
        "    confusion_array = np.array(confusion_data)\n",
        "    \n",
        "    # Heatmap de la confusion\n",
        "    im = ax4.imshow(confusion_array.T, cmap='Blues', aspect='auto')\n",
        "    \n",
        "    ax4.set_xticks(range(len(confusion_labels)))\n",
        "    ax4.set_xticklabels(confusion_labels, rotation=45, ha='right')\n",
        "    ax4.set_yticks(range(3))\n",
        "    ax4.set_yticklabels(['Vrais Positifs', 'Faux Positifs', 'Faux N√©gatifs'])\n",
        "    ax4.set_title('Matrice de Confusion Agr√©g√©e', fontweight='bold')\n",
        "    \n",
        "    # Ajout des valeurs\n",
        "    for i in range(len(confusion_labels)):\n",
        "        for j in range(3):\n",
        "            text = ax4.text(i, j, int(confusion_array[i, j]),\n",
        "                           ha=\"center\", va=\"center\", color=\"white\", fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ Graphiques de comparaison cr√©√©s !\")\n",
        "\n",
        "# Calcul et visualisation des performances\n",
        "if comprehensive_results:\n",
        "    print(\"\\nüßÆ Calcul des m√©triques de performance...\")\n",
        "    performance_metrics = calculate_model_performance_metrics(comprehensive_results)\n",
        "    \n",
        "    if performance_metrics:\n",
        "        create_performance_comparison_chart(performance_metrics)\n",
        "        \n",
        "        # R√©sum√© textuel des performances\n",
        "        print(f\"\\nüìã R√âSUM√â COMPARATIF DES PERFORMANCES\")\n",
        "        print(f\"=\" * 50)\n",
        "        \n",
        "        best_precision = max(performance_metrics.items(), key=lambda x: x[1]['precision'])\n",
        "        best_recall = max(performance_metrics.items(), key=lambda x: x[1]['recall'])\n",
        "        best_f1 = max(performance_metrics.items(), key=lambda x: x[1]['f1_score'])\n",
        "        \n",
        "        print(f\"ü•á Meilleure pr√©cision : {models_info.get(best_precision[0], {'name': best_precision[0]})['name']} ({best_precision[1]['precision']:.3f})\")\n",
        "        print(f\"ü•á Meilleur rappel : {models_info.get(best_recall[0], {'name': best_recall[0]})['name']} ({best_recall[1]['recall']:.3f})\")\n",
        "        print(f\"ü•á Meilleur F1-Score : {models_info.get(best_f1[0], {'name': best_f1[0]})['name']} ({best_f1[1]['f1_score']:.3f})\")\n",
        "        \n",
        "        print(f\"\\nüí° Recommandations cliniques :\")\n",
        "        print(f\"‚Ä¢ Mod√®le le plus pr√©cis pour √©viter faux positifs : {models_info.get(best_precision[0], {'name': best_precision[0]})['name']}\")\n",
        "        print(f\"‚Ä¢ Mod√®le le plus sensible pour d√©pistage : {models_info.get(best_recall[0], {'name': best_recall[0]})['name']}\")\n",
        "        print(f\"‚Ä¢ Mod√®le le plus √©quilibr√© : {models_info.get(best_f1[0], {'name': best_f1[0]})['name']}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Aucune donn√©e de performance disponible\")\n",
        "\nprint(\"\\nüéØ Analyse de performance d√©taill√©e termin√©e !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Sauvegarde et Rapport Complet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üíæ G√âN√âRATION DU RAPPORT COMPLET\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "def generate_comprehensive_report(comprehensive_results, performance_metrics, session_dir):\n",
        "    \"\"\"\n",
        "    G√©n√®re un rapport complet de l'analyse multi-mod√®les\n",
        "    \"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    \n",
        "    print(f\"\\nüìù G√©n√©ration du rapport complet...\")\n",
        "    \n",
        "    # Rapport textuel d√©taill√©\n",
        "    report_path = f\"{session_dir}rapport_comparatif_{timestamp}.txt\"\n",
        "    \n",
        "    report_content = f\"\"\"\n",
        "RAPPORT COMPARATIF MULTI-MOD√àLES TORCHXRAYVISION\n",
        "===============================================\n",
        "\n",
        "Date d'analyse : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "Tutorial : 2 - Classification Avanc√©e\n",
        "Version TorchXRayVision : {xrv.__version__}\n",
        "Dispositif d'analyse : {device}\n",
        "\n",
        "MOD√àLES ANALYS√âS :\n",
        "=================\n",
        "\"\"\"\n",
        "    \n",
        "    for model_name, info in models_info.items():\n",
        "        if model_name in models_dict:\n",
        "            report_content += f\"\"\"\n",
        "‚Ä¢ {info['name']} :\n",
        "  - Architecture : {info['architecture']}\n",
        "  - Donn√©es d'entra√Ænement : {info['training_data']}\n",
        "  - Sp√©cialit√© : {info['specialty']}\n",
        "  - Param√®tres : {info['params']:,}\n",
        "\"\"\"\n",
        "    \n",
        "    report_content += f\"\"\"\n",
        "\n",
        "CAS CLINIQUES ANALYS√âS :\n",
        "=======================\n",
        "\"\"\"\n",
        "    \n",
        "    for case_name, case_data in clinical_cases.items():\n",
        "        expected = case_data['expected_findings']\n",
        "        context = case_data['clinical_context']\n",
        "        description = case_data['description']\n",
        "        \n",
        "        report_content += f\"\"\"\n",
        "‚Ä¢ {case_name.upper()} :\n",
        "  - Description : {description}\n",
        "  - Pathologies attendues : {', '.join(expected)}\n",
        "  - Contexte clinique : {context}\n",
        "\"\"\"\n",
        "    \n",
        "    if performance_metrics:\n",
        "        report_content += f\"\"\"\n",
        "\n",
        "PERFORMANCES COMPARATIVES :\n",
        "==========================\n",
        "\"\"\"\n",
        "        \n",
        "        for model_name, metrics in performance_metrics.items():\n",
        "            model_info = models_info.get(model_name, {'name': model_name})\n",
        "            report_content += f\"\"\"\n",
        "‚Ä¢ {model_info['name']} :\n",
        "  - Pr√©cision : {metrics['precision']:.3f}\n",
        "  - Rappel (Sensibilit√©) : {metrics['recall']:.3f}\n",
        "  - F1-Score : {metrics['f1_score']:.3f}\n",
        "  - Vrais positifs : {metrics['true_positives']}\n",
        "  - Faux positifs : {metrics['false_positives']}\n",
        "  - Faux n√©gatifs : {metrics['false_negatives']}\n",
        "  - D√©tections/cas : {metrics['avg_detections_per_case']:.1f}\n",
        "  - Probabilit√© moyenne : {metrics['probability_stats']['mean']:.3f}\n",
        "\"\"\"\n",
        "    \n",
        "    report_content += f\"\"\"\n",
        "\n",
        "ANALYSE D√âTAILL√âE PAR CAS :\n",
        "===========================\n",
        "\"\"\"\n",
        "    \n",
        "    for case_name, case_result in comprehensive_results.items():\n",
        "        case_info = case_result['case_info']\n",
        "        model_results = case_result['model_results']\n",
        "        \n",
        "        report_content += f\"\"\"\n",
        "CAS : {case_name.upper()}\n",
        "Description : {case_info['description']}\n",
        "Contexte : {case_info['clinical_context']}\n",
        "Pathologies attendues : {', '.join(case_info['expected_findings'])}\n",
        "\n",
        "R√©sultats par mod√®le :\n",
        "\"\"\"\n",
        "        \n",
        "        for model_name, result in model_results.items():\n",
        "            model_info = models_info.get(model_name, {'name': model_name})\n",
        "            positive_findings = result['positive_findings']\n",
        "            max_prob = np.max(result['probabilities'])\n",
        "            \n",
        "            report_content += f\"\"\"\n",
        "  ‚Ä¢ {model_info['name']} :\n",
        "    - Probabilit√© maximale : {max_prob:.3f}\n",
        "    - D√©tections positives : {len(positive_findings)}\n",
        "\"\"\"\n",
        "            \n",
        "            if positive_findings:\n",
        "                report_content += \"    - Pathologies d√©tect√©es :\\n\"\n",
        "                for pathology, prob in sorted(positive_findings, key=lambda x: x[1], reverse=True):\n",
        "                    report_content += f\"      ‚Ä¢ {pathology}: {prob:.3f}\\n\"\n",
        "            else:\n",
        "                report_content += \"    - Aucune pathologie d√©tect√©e (seuil 50%)\\n\"\n",
        "    \n",
        "    # Conclusions et recommandations\n",
        "    if performance_metrics:\n",
        "        best_models = {\n",
        "            'precision': max(performance_metrics.items(), key=lambda x: x[1]['precision']),\n",
        "            'recall': max(performance_metrics.items(), key=lambda x: x[1]['recall']),\n",
        "            'f1': max(performance_metrics.items(), key=lambda x: x[1]['f1_score'])\n",
        "        }\n",
        "        \n",
        "        report_content += f\"\"\"\n",
        "\n",
        "CONCLUSIONS ET RECOMMANDATIONS CLINIQUES :\n",
        "==========================================\n",
        "\n",
        "PERFORMANCES OPTIMALES :\n",
        "‚Ä¢ Meilleure pr√©cision : {models_info.get(best_models['precision'][0], {'name': best_models['precision'][0]})['name']} ({best_models['precision'][1]['precision']:.3f})\n",
        "‚Ä¢ Meilleure sensibilit√© : {models_info.get(best_models['recall'][0], {'name': best_models['recall'][0]})['name']} ({best_models['recall'][1]['recall']:.3f})\n",
        "‚Ä¢ Meilleur √©quilibre : {models_info.get(best_models['f1'][0], {'name': best_models['f1'][0]})['name']} ({best_models['f1'][1]['f1_score']:.3f})\n",
        "\n",
        "RECOMMANDATIONS D'USAGE CLINIQUE :\n",
        "\n",
        "1. D√âPISTAGE (priorit√© √† la sensibilit√©) :\n",
        "   ‚Üí Utiliser {models_info.get(best_models['recall'][0], {'name': best_models['recall'][0]})['name']}\n",
        "   ‚Üí Minimise les faux n√©gatifs\n",
        "   ‚Üí Adapt√© pour screening de masse\n",
        "\n",
        "2. DIAGNOSTIC DE CONFIRMATION (priorit√© √† la pr√©cision) :\n",
        "   ‚Üí Utiliser {models_info.get(best_models['precision'][0], {'name': best_models['precision'][0]})['name']}\n",
        "   ‚Üí Minimise les faux positifs\n",
        "   ‚Üí Adapt√© pour √©viter sur-traitement\n",
        "\n",
        "3. USAGE G√âN√âRAL (√©quilibre optimal) :\n",
        "   ‚Üí Utiliser {models_info.get(best_models['f1'][0], {'name': best_models['f1'][0]})['name']}\n",
        "   ‚Üí Bon compromis sensibilit√©/sp√©cificit√©\n",
        "   ‚Üí Adapt√© pour consultation courante\n",
        "\n",
        "LIMITES ET CONSID√âRATIONS :\n",
        "\n",
        "‚Ä¢ Validation sur donn√©es synth√©tiques - Performance r√©elle peut diff√©rer\n",
        "‚Ä¢ Variabilit√© inter-observateur non prise en compte\n",
        "‚Ä¢ N√©cessit√© de validation sur cohortes cliniques r√©elles\n",
        "‚Ä¢ L'IA reste un outil d'aide - D√©cision finale au m√©decin\n",
        "‚Ä¢ Formation continue n√©cessaire sur ces technologies\n",
        "\n",
        "PERSPECTIVES D'AM√âLIORATION :\n",
        "\n",
        "‚Ä¢ Ensembles de mod√®les pour robustesse accrue\n",
        "‚Ä¢ Sp√©cialisation par type de pathologie\n",
        "‚Ä¢ Int√©gration de donn√©es cliniques contextuelles\n",
        "‚Ä¢ D√©veloppement de mod√®les explicables (XAI)\n",
        "\n",
        "---\n",
        "Rapport g√©n√©r√© par TorchXRayVision Tutorial 2\n",
        "Classification Avanc√©e pour Formation M√©dicale\n",
        "\"\"\"\n",
        "    \n",
        "    # Sauvegarde du rapport\n",
        "    with open(report_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(report_content)\n",
        "    \n",
        "    print(f\"   ‚úÖ Rapport textuel : {report_path}\")\n",
        "    \n",
        "    # Sauvegarde des donn√©es JSON\n",
        "    json_path = f\"{session_dir}donnees_comparatives_{timestamp}.json\"\n",
        "    \n",
        "    json_data = {\n",
        "        'timestamp': timestamp,\n",
        "        'models_info': models_info,\n",
        "        'performance_metrics': performance_metrics if performance_metrics else {},\n",
        "        'clinical_cases': {name: {'description': info['description'], \n",
        "                                 'expected_findings': info['expected_findings']}\n",
        "                          for name, info in clinical_cases.items()}\n",
        "    }\n",
        "    \n",
        "    with open(json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(json_data, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"   ‚úÖ Donn√©es JSON : {json_path}\")\n",
        "    \n",
        "    return report_path, json_path\n",
        "\n",
        "# G√©n√©ration du rapport final\n",
        "if comprehensive_results:\n",
        "    print(\"\\nüìä Finalisation de l'analyse comparative...\")\n",
        "    \n",
        "    report_files = generate_comprehensive_report(\n",
        "        comprehensive_results, \n",
        "        performance_metrics if 'performance_metrics' in locals() else {},\n",
        "        session_dir\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úÖ Rapport complet g√©n√©r√© !\")\n",
        "    print(f\"\\nüìÅ Fichiers sauvegard√©s dans : {session_dir}\")\n",
        "    print(f\"üìÑ Types de fichiers cr√©√©s :\")\n",
        "    print(f\"   ‚Ä¢ Rapport textuel d√©taill√©\")\n",
        "    print(f\"   ‚Ä¢ Donn√©es JSON pour r√©utilisation\")\n",
        "    print(f\"   ‚Ä¢ Visualisations PNG (si g√©n√©r√©es)\")\n",
        "    \nelse:\n",
        "    print(\"‚ö†Ô∏è Aucun r√©sultat √† sauvegarder\")\n",
        "\nprint(f\"\\nüéØ Tutorial 2 - Classification Avanc√©e Termin√© !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Conclusion du Tutorial 2\n",
        "\n",
        "### üèÜ F√©licitations !\n",
        "\n",
        "Vous ma√Ætrisez maintenant la **classification avanc√©e multi-mod√®les** avec TorchXRayVision !\n",
        "\n",
        "### ‚úÖ Comp√©tences Acquises :\n",
        "\n",
        "#### **Techniques Avanc√©es :**\n",
        "1. **üß† Chargement multi-mod√®les** : DenseNet121 sur diff√©rents datasets\n",
        "2. **üñºÔ∏è Cr√©ation de cas complexes** : Simulation de pathologies vari√©es\n",
        "3. **üî¨ Analyse comparative** : Performance crois√©e des mod√®les\n",
        "4. **üìä M√©triques avanc√©es** : Pr√©cision, Rappel, F1-Score\n",
        "5. **üìà Visualisations sophistiqu√©es** : Heatmaps, graphiques comparatifs\n",
        "6. **üìã Rapports automatis√©s** : Documentation compl√®te\n",
        "\n",
        "#### **Cliniques :**\n",
        "- **Choix de mod√®le** selon contexte clinique\n",
        "- **Interpr√©tation multi-pathologies**\n",
        "- **Gestion de l'incertitude** diagnostique\n",
        "- **Recommandations th√©rapeutiques** bas√©es sur l'IA\n",
        "\n",
        "### üìä R√©sultats de Performance\n",
        "\n",
        "Vous avez appris √† √©valuer :\n",
        "- **Sensibilit√© vs Sp√©cificit√©** selon l'usage clinique\n",
        "- **Consensus entre mod√®les** pour robustesse\n",
        "- **Trade-offs cliniques** entre faux positifs/n√©gatifs\n",
        "- **Adaptation contextuelle** des seuils de d√©tection\n",
        "\n",
        "### üè• Applications Cliniques Ma√Ætris√©es\n",
        "\n",
        "#### **D√©pistage de Masse :**\n",
        "- Priorit√© √† la **sensibilit√© √©lev√©e**\n",
        "- Mod√®les optimis√©s pour **d√©tection pr√©coce**\n",
        "- Workflow de **triage automatique**\n",
        "\n",
        "#### **Diagnostic de Confirmation :**\n",
        "- Priorit√© √† la **sp√©cificit√© √©lev√©e**\n",
        "- √âvitement des **sur-diagnostics**\n",
        "- **Pr√©cision maximale** requise\n",
        "\n",
        "#### **Consultation G√©n√©rale :**\n",
        "- **√âquilibre optimal** sensibilit√©/sp√©cificit√©\n",
        "- **Polyvalence** diagnostique\n",
        "- **Facilit√© d'interpr√©tation**\n",
        "\n",
        "### üéØ Prochaines √âtapes\n",
        "\n",
        "#### **Tutorial 3** : Segmentation Anatomique\n",
        "- D√©limitation automatique des structures\n",
        "- Mesures morphom√©triques pr√©cises\n",
        "- Analyse quantitative des organes\n",
        "- Applications en radioth√©rapie\n",
        "\n",
        "#### **Tutorial 4** : D√©tection et Localisation\n",
        "- Localisation pr√©cise des pathologies\n",
        "- Cartes d'activation (Grad-CAM)\n",
        "- Explicabilit√© de l'IA (XAI)\n",
        "- Confiance et incertitude\n",
        "\n",
        "#### **Tutorial 5** : Comparaison Multi-Architectures\n",
        "- ResNet vs DenseNet vs Vision Transformers\n",
        "- Architectures √©mergentes\n",
        "- Optimisation des performances\n",
        "- Benchmarking complet\n",
        "\n",
        "### üí° Points Cl√©s √† Retenir\n",
        "\n",
        "#### **Choix du Mod√®le :**\n",
        "- **Dataset d'entra√Ænement** d√©termine la sp√©cialisation\n",
        "- **Taille du mod√®le** vs **vitesse d'inf√©rence**\n",
        "- **Contexte clinique** guide la s√©lection\n",
        "\n",
        "#### **Interpr√©tation des R√©sultats :**\n",
        "- **Probabilit√©s ‚â† Certitudes** diagnostiques\n",
        "- **Consensus multi-mod√®les** = Robustesse accrue\n",
        "- **Corr√©lation clinique** toujours n√©cessaire\n",
        "\n",
        "#### **Limitations √† Consid√©rer :**\n",
        "- **Biais des datasets** d'entra√Ænement\n",
        "- **Variabilit√© des pr√©sentations** cliniques\n",
        "- **√âvolution technologique** rapide\n",
        "\n",
        "### üåü Message Final\n",
        "\n",
        "La **classification multi-mod√®les** repr√©sente l'√©tat actuel de l'art en IA radiologique. Vous ma√Ætrisez maintenant les outils qui transforment la pratique m√©dicale mondiale.\n",
        "\n",
        "#### **Votre Expertise :**\n",
        "- **Analyse comparative** rigoureuse\n",
        "- **Choix √©clair√©s** de mod√®les\n",
        "- **Interpr√©tation clinique** avanc√©e\n",
        "- **Documentation professionnelle**\n",
        "\n",
        "**Pr√™t pour le Tutorial 3 ?** La segmentation anatomique vous attend ! üî¨‚ú®\n",
        "\n",
        "---\n",
        "\n",
        "*Vous ma√Ætrisez d√©sormais les fondamentaux de la classification IA en radiologie !*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}