{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/maclandrol/e3340c2a682583a24895c0e34d09e8da/13.2_MedSAM_Segmentation_Interactive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Segmentation d'Images M√©dicales avec MedSAM pour √âtudiants en M√©decine\n",
        "\n",
        "## Introduction pour les √âtudiants en M√©decine\n",
        "\n",
        "Bienvenue dans ce tutoriel d'intelligence artificielle appliqu√©e √† l'imagerie m√©dicale ! En tant que futurs m√©decins, vous allez d√©couvrir comment l'IA peut assister dans l'analyse d'images m√©dicales pour am√©liorer le diagnostic et le suivi des patients.\n",
        "\n",
        "### Qu'est-ce que MedSAM ?\n",
        "\n",
        "**MedSAM** (Medical Segment Anything Model) est une version sp√©cialement adapt√©e du mod√®le SAM de Meta AI pour le domaine m√©dical. Il permet de :\n",
        "- **Segmenter automatiquement** des structures anatomiques ou pathologiques\n",
        "- **D√©limiter pr√©cis√©ment** des r√©gions d'int√©r√™t (tumeurs, organes, l√©sions)\n",
        "- **Assister les radiologues** dans leur travail quotidien\n",
        "\n",
        "### Applications Cliniques :\n",
        "- ü©ª **Radiologie** : D√©limitation de tumeurs en imagerie\n",
        "- ü´Ä **Cardiologie** : Analyse des cavit√©s cardiaques\n",
        "- üß† **Neurologie** : Segmentation de structures c√©r√©brales\n",
        "- üëÅÔ∏è **Ophtalmologie** : Analyse de la r√©tine\n",
        "\n",
        "### Objectifs P√©dagogiques :\n",
        "1. Comprendre le principe de la segmentation d'images m√©dicales\n",
        "2. Utiliser MedSAM pour analyser des images de cancer du sein\n",
        "3. √âvaluer la performance du mod√®le\n",
        "4. Tester le mod√®le sur vos propres images\n",
        "\n",
        "---\n",
        "\n",
        "## Configuration de l'Environnement Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# V√©rification de l'environnement Google Colab et configuration GPU\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "# V√©rification de l'environnement\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"‚úÖ Environnement Google Colab d√©tect√©\")\n",
        "    IN_COLAB = True\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Environnement local d√©tect√©\")\n",
        "    IN_COLAB = False\n",
        "\n",
        "# V√©rification du GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(f\"‚úÖ GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"M√©moire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"‚ö†Ô∏è GPU non disponible, utilisation du CPU (plus lent)\")\n",
        "    \n",
        "print(f\"\\nüîß Dispositif utilis√©: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation des Biblioth√®ques Sp√©cialis√©es\n",
        "\n",
        "Nous installons les outils n√©cessaires pour l'analyse d'images m√©dicales :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation des biblioth√®ques sp√©cialis√©es pour l'IA m√©dicale\n",
        "print(\"üì¶ Installation des biblioth√®ques sp√©cialis√©es...\")\n",
        "\n",
        "# Installation de Transformers (version r√©cente pour MedSAM)\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "\n",
        "# Installation des biblioth√®ques pour les datasets m√©dicaux\n",
        "!pip install -q datasets\n",
        "\n",
        "# Biblioth√®ques pour l'analyse quantitative m√©dicale\n",
        "!pip install -q scikit-image matplotlib seaborn\n",
        "\n",
        "print(\"‚úÖ Installation termin√©e !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Montage de Google Drive (pour sauvegarder vos r√©sultats)\n",
        "\n",
        "Nous montons votre Google Drive pour pouvoir sauvegarder les analyses :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive mont√© avec succ√®s !\")\n",
        "    \n",
        "    # Cr√©ation du dossier pour vos analyses m√©dicales\n",
        "    import os\n",
        "    results_dir = '/content/drive/MyDrive/AnalysesMedicalesIA/'\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "    print(f\"üìÅ Dossier cr√©√© : {results_dir}\")\n",
        "else:\n",
        "    results_dir = './resultats_analyses/'\n",
        "    import os\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "    print(f\"üìÅ Dossier local cr√©√© : {results_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chargement du Mod√®le MedSAM\n",
        "\n",
        "MedSAM est un mod√®le sp√©cialement entra√Æn√© pour analyser des images m√©dicales. Il a √©t√© d√©velopp√© par l'√©quipe du Dr. Bo Wang et am√©liore significativement les performances par rapport aux mod√®les g√©n√©riques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import SamModel, SamProcessor\n",
        "import torch\n",
        "\n",
        "print(\"üè• Chargement du mod√®le MedSAM sp√©cialis√©...\")\n",
        "print(\"Ce mod√®le a √©t√© entra√Æn√© sur des milliers d'images m√©dicales !\")\n",
        "\n",
        "# Chargement du processeur (pr√©pare les images pour le mod√®le)\n",
        "processor = SamProcessor.from_pretrained(\"wanglab/medsam-vit-base\")\n",
        "print(\"‚úÖ Processeur d'images m√©dicales charg√©\")\n",
        "\n",
        "# Chargement du mod√®le MedSAM\n",
        "model = SamModel.from_pretrained(\"wanglab/medsam-vit-base\").to(device)\n",
        "print(\"‚úÖ Mod√®le MedSAM charg√© et configur√©\")\n",
        "\n",
        "print(f\"\\nüî¨ Le mod√®le est pr√™t √† analyser des images m√©dicales sur {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chargement des Donn√©es M√©dicales : Cancer du Sein\n",
        "\n",
        "Nous utilisons un dataset d'images √©chographiques de cancer du sein. Ces images proviennent d'examens r√©els et ont √©t√© annot√©es par des sp√©cialistes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"ü©ª Chargement du dataset d'√©chographies mammaires...\")\n",
        "\n",
        "# Chargement du dataset de cancer du sein\n",
        "dataset = load_dataset(\"nielsr/breast-cancer\", split=\"train\")\n",
        "print(f\"‚úÖ Dataset charg√© : {len(dataset)} images d'√©chographies mammaires\")\n",
        "\n",
        "# Information sur le dataset pour les √©tudiants\n",
        "print(\"\\nüìä Informations sur le dataset :\")\n",
        "print(f\"- Nombre d'images : {len(dataset)}\")\n",
        "print(f\"- Type d'imagerie : √âchographie mammaire\")\n",
        "print(f\"- Annotations : Segmentations des l√©sions par des radiologues\")\n",
        "\n",
        "# S√©lection d'un exemple repr√©sentatif\n",
        "idx = 10  # Image particuli√®rement int√©ressante pour l'enseignement\n",
        "\n",
        "# Chargement de l'image\n",
        "image = dataset[idx][\"image\"]\n",
        "print(f\"\\nüîç Image s√©lectionn√©e : #{idx}\")\n",
        "print(f\"Taille de l'image : {image.size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisation de l'Image √âchographique\n",
        "\n",
        "Examinons l'image √©chographique comme le ferait un radiologue :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affichage de l'image √©chographique\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(\"√âchographie Mammaire - Image Originale\\n(Recherchez les zones suspectes)\", fontsize=14, fontweight='bold')\n",
        "plt.axis('on')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Ajout d'annotations p√©dagogiques\n",
        "plt.xlabel(\"Largeur (pixels)\", fontsize=12)\n",
        "plt.ylabel(\"Hauteur (pixels)\", fontsize=12)\n",
        "\n",
        "print(\"\\nüè• Points d'observation clinique :\")\n",
        "print(\"- Recherchez les zones hypo√©chog√®nes (plus sombres)\")\n",
        "print(\"- Observez les contours et la forme des structures\")\n",
        "print(\"- Notez l'homog√©n√©it√© ou l'h√©t√©rog√©n√©it√© des tissus\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyse de la Segmentation de R√©f√©rence\n",
        "\n",
        "Voyons maintenant la segmentation r√©alis√©e par les radiologues experts :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement de la segmentation de r√©f√©rence (ground truth)\n",
        "ground_truth_seg = np.array(dataset[idx][\"label\"])\n",
        "\n",
        "print(\"üéØ Analyse de la segmentation de r√©f√©rence :\")\n",
        "print(f\"Valeurs uniques dans la segmentation : {np.unique(ground_truth_seg)}\")\n",
        "print(\"0 = Tissu normal, 1 = L√©sion/Structure d'int√©r√™t\")\n",
        "\n",
        "# Calcul de statistiques m√©dicales\n",
        "total_pixels = ground_truth_seg.size\n",
        "lesion_pixels = np.sum(ground_truth_seg == 1)\n",
        "normal_pixels = np.sum(ground_truth_seg == 0)\n",
        "lesion_percentage = (lesion_pixels / total_pixels) * 100\n",
        "\n",
        "print(f\"\\nüìä Statistiques quantitatives :\")\n",
        "print(f\"- Pixels totaux : {total_pixels:,}\")\n",
        "print(f\"- Pixels de l√©sion : {lesion_pixels:,}\")\n",
        "print(f\"- Pixels normaux : {normal_pixels:,}\")\n",
        "print(f\"- Pourcentage de l√©sion : {lesion_percentage:.2f}%\")\n",
        "\n",
        "# Visualisation de la segmentation avec palette m√©dicale\n",
        "palette = [[120, 120, 120], [255, 100, 100]]  # Gris pour normal, Rouge pour l√©sion\n",
        "color_seg = np.zeros((ground_truth_seg.shape[0], ground_truth_seg.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "for label, color in enumerate(palette):\n",
        "    color_seg[ground_truth_seg == label, :] = color\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(color_seg)\n",
        "plt.title(\"Segmentation de R√©f√©rence par les Radiologues\\n(Rouge = L√©sion, Gris = Tissu Normal)\", \n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.axis('on')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Ajout d'une l√©gende m√©dicale\n",
        "import matplotlib.patches as mpatches\n",
        "normal_patch = mpatches.Patch(color=[120/255, 120/255, 120/255], label='Tissu Normal')\n",
        "lesion_patch = mpatches.Patch(color=[1, 100/255, 100/255], label='L√©sion Identifi√©e')\n",
        "plt.legend(handles=[normal_patch, lesion_patch], loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## G√©n√©ration Automatique de la Bo√Æte Englobante\n",
        "\n",
        "Pour utiliser MedSAM, nous devons d√©finir une r√©gion d'int√©r√™t. En pratique clinique, cette r√©gion serait indiqu√©e par le radiologue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_bounding_box(ground_truth_map, perturbation=True):\n",
        "    \"\"\"\n",
        "    G√©n√®re une bo√Æte englobante autour de la l√©sion\n",
        "    \n",
        "    En pratique clinique, cette bo√Æte serait dessin√©e par le radiologue\n",
        "    sur l'interface du logiciel d'imagerie m√©dicale.\n",
        "    \"\"\"\n",
        "    # Recherche des coordonn√©es de la l√©sion\n",
        "    y_indices, x_indices = np.where(ground_truth_map > 0)\n",
        "    \n",
        "    if len(x_indices) == 0 or len(y_indices) == 0:\n",
        "        print(\"‚ö†Ô∏è Aucune l√©sion d√©tect√©e dans cette image\")\n",
        "        return None\n",
        "    \n",
        "    # Calcul des bornes\n",
        "    x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
        "    y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
        "    \n",
        "    # Simulation de l'impr√©cision humaine (optionnel)\n",
        "    if perturbation:\n",
        "        H, W = ground_truth_map.shape\n",
        "        x_min = max(0, x_min - np.random.randint(0, 20))\n",
        "        x_max = min(W, x_max + np.random.randint(0, 20))\n",
        "        y_min = max(0, y_min - np.random.randint(0, 20))\n",
        "        y_max = min(H, y_max + np.random.randint(0, 20))\n",
        "    \n",
        "    bbox = [x_min, y_min, x_max, y_max]\n",
        "    \n",
        "    # Calculs m√©dicaux\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "    area = width * height\n",
        "    \n",
        "    print(f\"üìè Dimensions de la r√©gion d'int√©r√™t :\")\n",
        "    print(f\"- Largeur : {width} pixels\")\n",
        "    print(f\"- Hauteur : {height} pixels\")\n",
        "    print(f\"- Surface : {area} pixels¬≤\")\n",
        "    \n",
        "    return bbox\n",
        "\n",
        "# G√©n√©ration de la bo√Æte englobante\n",
        "input_boxes = get_bounding_box(ground_truth_seg)\n",
        "print(f\"\\nüéØ Coordonn√©es de la bo√Æte : {input_boxes}\")\n",
        "print(\"Format : [x_min, y_min, x_max, y_max]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisation de la R√©gion d'Int√©r√™t\n",
        "\n",
        "Affichons la bo√Æte englobante sur l'image originale :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_box(box, ax, color='green', label='R√©gion d\\'Int√©r√™t'):\n",
        "    \"\"\"Affiche une bo√Æte englobante sur l'image\"\"\"\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, \n",
        "                              edgecolor=color, \n",
        "                              facecolor=(0,0,0,0), \n",
        "                              linewidth=3,\n",
        "                              label=label))\n",
        "\n",
        "def show_boxes_on_image(raw_image, boxes, title=\"Image avec R√©gion d'Int√©r√™t\"):\n",
        "    \"\"\"Affiche l'image avec les bo√Ætes englobantes\"\"\"\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.imshow(raw_image, cmap='gray')\n",
        "    \n",
        "    for i, box in enumerate(boxes):\n",
        "        show_box(box, plt.gca(), color='lime', label=f'ROI {i+1}')\n",
        "    \n",
        "    plt.title(title + \"\\n(Cadre vert = Zone √† analyser par MedSAM)\", \n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.legend()\n",
        "    plt.axis('on')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Annotations cliniques\n",
        "    plt.xlabel(\"Position horizontale (pixels)\", fontsize=12)\n",
        "    plt.ylabel(\"Position verticale (pixels)\", fontsize=12)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Affichage de l'image avec la r√©gion d'int√©r√™t\n",
        "show_boxes_on_image(image, [input_boxes], \"√âchographie avec R√©gion d'Int√©r√™t D√©finie\")\n",
        "\n",
        "print(\"\\nüè• Interpr√©tation clinique :\")\n",
        "print(\"- Le cadre vert indique la zone que MedSAM va analyser\")\n",
        "print(\"- Cette zone correspond √† la r√©gion suspecte identifi√©e\")\n",
        "print(\"- En pratique, cette zone serait s√©lectionn√©e par le radiologue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Traitement par le Mod√®le MedSAM\n",
        "\n",
        "Maintenant, laissons MedSAM analyser l'image et pr√©dire la segmentation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(\"üî¨ Pr√©paration de l'image pour l'analyse par MedSAM...\")\n",
        "\n",
        "# Pr√©paration des donn√©es d'entr√©e pour le mod√®le\n",
        "inputs = processor(image, input_boxes=[input_boxes], return_tensors=\"pt\").to(device)\n",
        "\n",
        "print(\"üìä Dimensions des donn√©es d'entr√©e :\")\n",
        "for k, v in inputs.items():\n",
        "    print(f\"- {k}: {v.shape}\")\n",
        "\n",
        "print(f\"\\nüß† Traitement par le mod√®le MedSAM...\")\n",
        "\n",
        "# Passage du mod√®le vers le bon dispositif\n",
        "model.to(device)\n",
        "\n",
        "# Analyse par MedSAM (sans calcul de gradients pour l'inf√©rence)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs, multimask_output=False)\n",
        "\n",
        "print(f\"‚úÖ Analyse termin√©e !\")\n",
        "print(f\"üìè Dimensions du masque pr√©dit : {outputs.pred_masks.shape}\")\n",
        "print(\"Format : [batch, masques, canaux, hauteur, largeur]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post-traitement Sp√©cifique √† MedSAM\n",
        "\n",
        "MedSAM utilise une fonction de perte sp√©cialis√©e (DiceWithSigmoid), nous devons appliquer le post-traitement appropri√© :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"‚öôÔ∏è Post-traitement sp√©cialis√© pour l'imagerie m√©dicale...\")\n",
        "\n",
        "# Application de la fonction sigmo√Øde (normalisation entre 0 et 1)\n",
        "medsam_seg_prob = torch.sigmoid(outputs.pred_masks.squeeze(1))\n",
        "print(f\"‚úÖ Probabilit√©s normalis√©es (0-1)\")\n",
        "\n",
        "# Conversion en numpy pour l'analyse\n",
        "medsam_seg_prob = medsam_seg_prob.cpu().numpy().squeeze()\n",
        "\n",
        "# Conversion en masque binaire (seuil √† 0.5)\n",
        "medsam_seg = (medsam_seg_prob > 0.5).astype(np.uint8)\n",
        "\n",
        "print(f\"üìä Statistiques de la pr√©diction :\")\n",
        "print(f\"- Probabilit√© moyenne : {np.mean(medsam_seg_prob):.3f}\")\n",
        "print(f\"- Probabilit√© maximale : {np.max(medsam_seg_prob):.3f}\")\n",
        "print(f\"- Probabilit√© minimale : {np.min(medsam_seg_prob):.3f}\")\n",
        "print(f\"- Pixels class√©s comme l√©sion : {np.sum(medsam_seg)} / {medsam_seg.size}\")\n",
        "print(f\"- Pourcentage de l√©sion pr√©dit : {(np.sum(medsam_seg)/medsam_seg.size)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisation des R√©sultats de MedSAM\n",
        "\n",
        "Comparons la pr√©diction de MedSAM avec la segmentation de r√©f√©rence :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_mask(mask, ax, color_rgba=[30/255, 144/255, 255/255, 0.6], title=\"\"):\n",
        "    \"\"\"Affiche un masque de segmentation avec transparence\"\"\"\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * np.array(color_rgba).reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
        "\n",
        "# Cr√©ation d'une figure comparative\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle(\"Analyse Comparative : MedSAM vs R√©f√©rence Clinique\", fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Image originale\n",
        "axes[0,0].imshow(np.array(image), cmap='gray')\n",
        "axes[0,0].set_title(\"Image √âchographique Originale\", fontweight='bold')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "# 2. Pr√©diction MedSAM\n",
        "axes[0,1].imshow(np.array(image), cmap='gray')\n",
        "show_mask(medsam_seg, axes[0,1], color_rgba=[0, 1, 0, 0.6])  # Vert\n",
        "axes[0,1].set_title(\"Pr√©diction MedSAM\\n(Masque Vert)\", fontweight='bold')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "# 3. Segmentation de r√©f√©rence\n",
        "axes[1,0].imshow(np.array(image), cmap='gray')\n",
        "show_mask(ground_truth_seg, axes[1,0], color_rgba=[1, 0, 0, 0.6])  # Rouge\n",
        "axes[1,0].set_title(\"Segmentation de R√©f√©rence\\n(Masque Rouge)\", fontweight='bold')\n",
        "axes[1,0].axis('off')\n",
        "\n",
        "# 4. Comparaison superpos√©e\n",
        "axes[1,1].imshow(np.array(image), cmap='gray')\n",
        "show_mask(ground_truth_seg, axes[1,1], color_rgba=[1, 0, 0, 0.4])  # Rouge transparent\n",
        "show_mask(medsam_seg, axes[1,1], color_rgba=[0, 1, 0, 0.4])      # Vert transparent\n",
        "axes[1,1].set_title(\"Superposition\\n(Rouge=R√©f√©rence, Vert=MedSAM)\", fontweight='bold')\n",
        "axes[1,1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüè• Interpr√©tation clinique :\")\n",
        "print(\"- Le masque vert montre la pr√©diction de MedSAM\")\n",
        "print(\"- Le masque rouge montre la segmentation de r√©f√©rence\")\n",
        "print(\"- La superposition permet d'√©valuer la concordance\")\n",
        "print(\"- Les zones jaunes (vert+rouge) indiquent un accord parfait\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## √âvaluation Quantitative des Performances\n",
        "\n",
        "Calculons des m√©triques m√©dicales pour √©valuer la performance de MedSAM :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_medical_metrics(pred_mask, true_mask):\n",
        "    \"\"\"\n",
        "    Calcule les m√©triques m√©dicales standard pour √©valuer la segmentation\n",
        "    \"\"\"\n",
        "    # Conversion en bool√©ens pour les calculs\n",
        "    pred = pred_mask.astype(bool)\n",
        "    true = true_mask.astype(bool)\n",
        "    \n",
        "    # Calculs des m√©triques de base\n",
        "    intersection = np.logical_and(pred, true)\n",
        "    union = np.logical_or(pred, true)\n",
        "    \n",
        "    # True Positives, False Positives, False Negatives\n",
        "    tp = np.sum(intersection)\n",
        "    fp = np.sum(pred) - tp\n",
        "    fn = np.sum(true) - tp\n",
        "    tn = np.sum(~union)\n",
        "    \n",
        "    # M√©triques m√©dicales\n",
        "    # Coefficient de Dice (F1-score) - tr√®s important en imagerie m√©dicale\n",
        "    dice_coeff = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
        "    \n",
        "    # Intersection over Union (IoU) - Jaccard Index\n",
        "    iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
        "    \n",
        "    # Sensibilit√© (Rappel) - capacit√© √† d√©tecter les l√©sions\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    \n",
        "    # Sp√©cificit√© - capacit√© √† identifier les tissus sains\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    \n",
        "    # Pr√©cision - fiabilit√© des d√©tections positives\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    \n",
        "    # Exactitude globale\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    \n",
        "    return {\n",
        "        'dice_coefficient': dice_coeff,\n",
        "        'iou': iou,\n",
        "        'sensitivity': sensitivity,\n",
        "        'specificity': specificity,\n",
        "        'precision': precision,\n",
        "        'accuracy': accuracy,\n",
        "        'true_positives': tp,\n",
        "        'false_positives': fp,\n",
        "        'false_negatives': fn,\n",
        "        'true_negatives': tn\n",
        "    }\n",
        "\n",
        "# Calcul des m√©triques\n",
        "metrics = calculate_medical_metrics(medsam_seg, ground_truth_seg)\n",
        "\n",
        "print(\"üìä √âVALUATION QUANTITATIVE DE MEDSAM\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nüéØ M√©triques de Performance :\")\n",
        "print(f\"- Coefficient de Dice : {metrics['dice_coefficient']:.3f} (0=mauvais, 1=parfait)\")\n",
        "print(f\"- IoU (Jaccard) : {metrics['iou']:.3f} (0=mauvais, 1=parfait)\")\n",
        "print(f\"- Exactitude : {metrics['accuracy']:.3f} ({metrics['accuracy']*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nü©∫ M√©triques Cliniques :\")\n",
        "print(f\"- Sensibilit√© : {metrics['sensitivity']:.3f} (d√©tection des l√©sions)\")\n",
        "print(f\"- Sp√©cificit√© : {metrics['specificity']:.3f} (identification tissu sain)\")\n",
        "print(f\"- Pr√©cision : {metrics['precision']:.3f} (fiabilit√© des d√©tections)\")\n",
        "\n",
        "print(f\"\\nüî¢ D√©tail des Pr√©dictions :\")\n",
        "print(f\"- Vrais Positifs : {metrics['true_positives']} pixels\")\n",
        "print(f\"- Faux Positifs : {metrics['false_positives']} pixels\")\n",
        "print(f\"- Faux N√©gatifs : {metrics['false_negatives']} pixels\")\n",
        "print(f\"- Vrais N√©gatifs : {metrics['true_negatives']} pixels\")\n",
        "\n",
        "# Interpr√©tation clinique\n",
        "print(f\"\\nüè• INTERPR√âTATION CLINIQUE :\")\n",
        "if metrics['dice_coefficient'] > 0.8:\n",
        "    print(\"‚úÖ Excellente concordance avec l'expert radiologue\")\n",
        "elif metrics['dice_coefficient'] > 0.6:\n",
        "    print(\"üëç Bonne concordance avec l'expert radiologue\")\n",
        "elif metrics['dice_coefficient'] > 0.4:\n",
        "    print(\"‚ö†Ô∏è Concordance mod√©r√©e - n√©cessite r√©vision\")\n",
        "else:\n",
        "    print(\"‚ùå Concordance faible - r√©sultat non fiable\")\n",
        "\n",
        "if metrics['sensitivity'] > 0.9:\n",
        "    print(\"‚úÖ Excellente d√©tection des l√©sions\")\n",
        "elif metrics['sensitivity'] < 0.7:\n",
        "    print(\"‚ö†Ô∏è Risque de manquer des l√©sions (faux n√©gatifs)\")\n",
        "\n",
        "if metrics['specificity'] > 0.9:\n",
        "    print(\"‚úÖ Excellente identification du tissu sain\")\n",
        "elif metrics['specificity'] < 0.8:\n",
        "    print(\"‚ö†Ô∏è Risque de sur-diagnostic (faux positifs)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyse de Cas Multiples\n",
        "\n",
        "Testons MedSAM sur plusieurs images pour √©valuer sa robustesse :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_multiple_cases(dataset, model, processor, device, num_cases=5):\n",
        "    \"\"\"\n",
        "    Analyse plusieurs cas pour √©valuer la robustesse du mod√®le\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    print(f\"üî¨ Analyse de {num_cases} cas cliniques...\")\n",
        "    \n",
        "    # S√©lection d'indices vari√©s\n",
        "    indices = np.linspace(0, len(dataset)-1, num_cases, dtype=int)\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        print(f\"\\nüìã Cas #{i+1} (Image #{idx}) :\")\n",
        "        \n",
        "        # Chargement des donn√©es\n",
        "        image = dataset[idx][\"image\"]\n",
        "        ground_truth = np.array(dataset[idx][\"label\"])\n",
        "        \n",
        "        # G√©n√©ration de la bo√Æte englobante\n",
        "        bbox = get_bounding_box(ground_truth, perturbation=False)\n",
        "        \n",
        "        if bbox is None:\n",
        "            print(\"   ‚ö†Ô∏è Pas de l√©sion dans cette image - cas ignor√©\")\n",
        "            continue\n",
        "        \n",
        "        # Pr√©diction MedSAM\n",
        "        inputs = processor(image, input_boxes=[bbox], return_tensors=\"pt\").to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, multimask_output=False)\n",
        "        \n",
        "        # Post-traitement\n",
        "        seg_prob = torch.sigmoid(outputs.pred_masks.squeeze(1))\n",
        "        prediction = (seg_prob.cpu().numpy().squeeze() > 0.5).astype(np.uint8)\n",
        "        \n",
        "        # Calcul des m√©triques\n",
        "        metrics = calculate_medical_metrics(prediction, ground_truth)\n",
        "        \n",
        "        results.append({\n",
        "            'case_id': idx,\n",
        "            'dice': metrics['dice_coefficient'],\n",
        "            'iou': metrics['iou'],\n",
        "            'sensitivity': metrics['sensitivity'],\n",
        "            'specificity': metrics['specificity']\n",
        "        })\n",
        "        \n",
        "        print(f\"   Dice: {metrics['dice_coefficient']:.3f}, IoU: {metrics['iou']:.3f}\")\n",
        "        print(f\"   Sensibilit√©: {metrics['sensitivity']:.3f}, Sp√©cificit√©: {metrics['specificity']:.3f}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Analyse de plusieurs cas\n",
        "multi_results = analyze_multiple_cases(dataset, model, processor, device, num_cases=5)\n",
        "\n",
        "if multi_results:\n",
        "    # Calcul des statistiques globales\n",
        "    mean_dice = np.mean([r['dice'] for r in multi_results])\n",
        "    std_dice = np.std([r['dice'] for r in multi_results])\n",
        "    mean_sensitivity = np.mean([r['sensitivity'] for r in multi_results])\n",
        "    mean_specificity = np.mean([r['specificity'] for r in multi_results])\n",
        "    \n",
        "    print(f\"\\nüìä PERFORMANCE GLOBALE SUR {len(multi_results)} CAS :\")\n",
        "    print(f\"=\" * 50)\n",
        "    print(f\"Coefficient de Dice moyen : {mean_dice:.3f} ¬± {std_dice:.3f}\")\n",
        "    print(f\"Sensibilit√© moyenne : {mean_sensitivity:.3f}\")\n",
        "    print(f\"Sp√©cificit√© moyenne : {mean_specificity:.3f}\")\n",
        "    \n",
        "    # Visualisation des performances\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    dice_scores = [r['dice'] for r in multi_results]\n",
        "    plt.bar(range(len(dice_scores)), dice_scores, color='skyblue', edgecolor='navy')\n",
        "    plt.axhline(y=mean_dice, color='red', linestyle='--', label=f'Moyenne: {mean_dice:.3f}')\n",
        "    plt.title('Coefficient de Dice par Cas')\n",
        "    plt.xlabel('Num√©ro du Cas')\n",
        "    plt.ylabel('Score de Dice')\n",
        "    plt.legend()\n",
        "    plt.ylim(0, 1)\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    metrics_names = ['Dice', 'IoU', 'Sensibilit√©', 'Sp√©cificit√©']\n",
        "    metrics_values = [\n",
        "        np.mean([r['dice'] for r in multi_results]),\n",
        "        np.mean([r['iou'] for r in multi_results]),\n",
        "        np.mean([r['sensitivity'] for r in multi_results]),\n",
        "        np.mean([r['specificity'] for r in multi_results])\n",
        "    ]\n",
        "    \n",
        "    colors = ['lightcoral', 'lightblue', 'lightgreen', 'gold']\n",
        "    plt.bar(metrics_names, metrics_values, color=colors, edgecolor='black')\n",
        "    plt.title('Performance Moyenne de MedSAM')\n",
        "    plt.ylabel('Score')\n",
        "    plt.ylim(0, 1)\n",
        "    \n",
        "    # Ajout des valeurs sur les barres\n",
        "    for i, v in enumerate(metrics_values):\n",
        "        plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fonction d'Upload et de Test Personnalis√©\n",
        "\n",
        "Testez MedSAM sur vos propres images m√©dicales !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "def test_custom_image():\n",
        "    \"\"\"\n",
        "    Permet de tester MedSAM sur une image personnalis√©e\n",
        "    \"\"\"\n",
        "    print(\"üìÅ Upload de votre image m√©dicale...\")\n",
        "    print(\"Formats support√©s : JPG, PNG, TIFF\")\n",
        "    print(\"Recommandations : Images en niveaux de gris, r√©solution 256x256 √† 1024x1024\")\n",
        "    \n",
        "    if IN_COLAB:\n",
        "        # Upload dans Google Colab\n",
        "        uploaded = files.upload()\n",
        "        \n",
        "        if not uploaded:\n",
        "            print(\"‚ùå Aucun fichier upload√©\")\n",
        "            return None\n",
        "        \n",
        "        # Traitement du premier fichier upload√©\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        print(f\"‚úÖ Fichier re√ßu : {filename}\")\n",
        "        \n",
        "        # Chargement de l'image\n",
        "        image_bytes = uploaded[filename]\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        \n",
        "    else:\n",
        "        # Mode local - demande le chemin\n",
        "        import tkinter as tk\n",
        "        from tkinter import filedialog\n",
        "        root = tk.Tk()\n",
        "        root.withdraw()\n",
        "        \n",
        "        file_path = filedialog.askopenfilename(\n",
        "            title=\"S√©lectionnez votre image m√©dicale\",\n",
        "            filetypes=[(\"Images\", \"*.png *.jpg *.jpeg *.tiff *.bmp\")]\n",
        "        )\n",
        "        \n",
        "        if not file_path:\n",
        "            print(\"‚ùå Aucun fichier s√©lectionn√©\")\n",
        "            return None\n",
        "            \n",
        "        image = Image.open(file_path)\n",
        "        filename = file_path.split('/')[-1]\n",
        "    \n",
        "    # Conversion en niveaux de gris si n√©cessaire\n",
        "    if image.mode != 'L':\n",
        "        print(\"üîÑ Conversion en niveaux de gris...\")\n",
        "        image = image.convert('L')\n",
        "    \n",
        "    print(f\"üìè Dimensions de l'image : {image.size}\")\n",
        "    \n",
        "    # Redimensionnement si trop grande\n",
        "    max_size = 1024\n",
        "    if max(image.size) > max_size:\n",
        "        print(f\"üîÑ Redimensionnement (max {max_size}px)...\")\n",
        "        image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)\n",
        "        print(f\"üìè Nouvelles dimensions : {image.size}\")\n",
        "    \n",
        "    return image, filename\n",
        "\n",
        "def interactive_roi_selection(image):\n",
        "    \"\"\"\n",
        "    Interface simple pour s√©lectionner une r√©gion d'int√©r√™t\n",
        "    \"\"\"\n",
        "    print(\"\\nüéØ S√©lection de la r√©gion d'int√©r√™t :\")\n",
        "    print(\"Cliquez pour d√©finir le coin sup√©rieur gauche, puis le coin inf√©rieur droit\")\n",
        "    \n",
        "    # Affichage de l'image pour s√©lection\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(\"Cliquez pour d√©finir la r√©gion d'int√©r√™t\\n(Coin sup. gauche puis coin inf. droit)\")\n",
        "    plt.axis('on')\n",
        "    \n",
        "    # R√©cup√©ration des clics (simulation - en r√©alit√© utilisez ginput)\n",
        "    coords = plt.ginput(2, timeout=30, show_clicks=True)\n",
        "    \n",
        "    if len(coords) < 2:\n",
        "        print(\"‚ùå S√©lection incompl√®te, utilisation de l'image enti√®re\")\n",
        "        return [0, 0, image.width, image.height]\n",
        "    \n",
        "    x1, y1 = int(coords[0][0]), int(coords[0][1])\n",
        "    x2, y2 = int(coords[1][0]), int(coords[1][1])\n",
        "    \n",
        "    # Assurer l'ordre correct\n",
        "    x_min, x_max = min(x1, x2), max(x1, x2)\n",
        "    y_min, y_max = min(y1, y2), max(y1, y2)\n",
        "    \n",
        "    plt.close()\n",
        "    \n",
        "    print(f\"‚úÖ ROI s√©lectionn√©e : [{x_min}, {y_min}, {x_max}, {y_max}]\")\n",
        "    return [x_min, y_min, x_max, y_max]\n",
        "\n",
        "def analyze_custom_image(image, bbox, filename):\n",
        "    \"\"\"\n",
        "    Analyse une image personnalis√©e avec MedSAM\n",
        "    \"\"\"\n",
        "    print(f\"\\nüî¨ Analyse de {filename} avec MedSAM...\")\n",
        "    \n",
        "    # Pr√©paration pour MedSAM\n",
        "    inputs = processor(image, input_boxes=[bbox], return_tensors=\"pt\").to(device)\n",
        "    \n",
        "    # Pr√©diction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, multimask_output=False)\n",
        "    \n",
        "    # Post-traitement\n",
        "    seg_prob = torch.sigmoid(outputs.pred_masks.squeeze(1))\n",
        "    prediction = (seg_prob.cpu().numpy().squeeze() > 0.5).astype(np.uint8)\n",
        "    probabilities = seg_prob.cpu().numpy().squeeze()\n",
        "    \n",
        "    # Statistiques\n",
        "    total_pixels = prediction.size\n",
        "    positive_pixels = np.sum(prediction)\n",
        "    positive_percentage = (positive_pixels / total_pixels) * 100\n",
        "    max_confidence = np.max(probabilities)\n",
        "    avg_confidence = np.mean(probabilities[prediction == 1]) if positive_pixels > 0 else 0\n",
        "    \n",
        "    print(f\"üìä R√©sultats de l'analyse :\")\n",
        "    print(f\"- Pixels d√©tect√©s : {positive_pixels} / {total_pixels}\")\n",
        "    print(f\"- Pourcentage de l√©sion : {positive_percentage:.2f}%\")\n",
        "    print(f\"- Confiance maximale : {max_confidence:.3f}\")\n",
        "    print(f\"- Confiance moyenne (zones positives) : {avg_confidence:.3f}\")\n",
        "    \n",
        "    # Visualisation\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    fig.suptitle(f\"Analyse MedSAM : {filename}\", fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Image originale avec ROI\n",
        "    axes[0].imshow(image, cmap='gray')\n",
        "    show_box(bbox, axes[0], color='lime')\n",
        "    axes[0].set_title(\"Image Originale + ROI\")\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Carte de probabilit√©s\n",
        "    im1 = axes[1].imshow(probabilities, cmap='hot', vmin=0, vmax=1)\n",
        "    axes[1].set_title(\"Carte de Probabilit√©s\")\n",
        "    axes[1].axis('off')\n",
        "    plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
        "    \n",
        "    # Segmentation finale\n",
        "    axes[2].imshow(image, cmap='gray')\n",
        "    show_mask(prediction, axes[2], color_rgba=[0, 1, 0, 0.6])\n",
        "    axes[2].set_title(\"Segmentation Pr√©dite\")\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Sauvegarde des r√©sultats\n",
        "    if IN_COLAB:\n",
        "        save_path = f\"{results_dir}analyse_{filename.split('.')[0]}.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"üíæ R√©sultats sauvegard√©s : {save_path}\")\n",
        "    \n",
        "    return prediction, probabilities\n",
        "\n",
        "# Interface pour tester une image personnalis√©e\n",
        "print(\"üè• TEST SUR IMAGE PERSONNALIS√âE\")\n",
        "print(\"=\" * 40)\n",
        "print(\"Vous pouvez maintenant tester MedSAM sur vos propres images m√©dicales !\")\n",
        "print(\"\\nPour commencer, ex√©cutez les cellules suivantes :\")\n",
        "print(\"1. Upload de votre image\")\n",
        "print(\"2. S√©lection de la r√©gion d'int√©r√™t\")\n",
        "print(\"3. Analyse automatique par MedSAM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELLULE D'UPLOAD - Ex√©cutez pour tester votre image\n",
        "custom_image, custom_filename = test_custom_image()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELLULE DE S√âLECTION ROI\n",
        "if 'custom_image' in locals() and custom_image is not None:\n",
        "    # Affichage pour s√©lection manuelle ou automatique\n",
        "    print(\"Choisissez le mode de s√©lection :\")\n",
        "    print(\"1. Manuel (recommand√©) : Vous cliquez sur l'image\")\n",
        "    print(\"2. Automatique : Analyse de l'image enti√®re\")\n",
        "    \n",
        "    mode = input(\"Tapez 1 ou 2 : \").strip()\n",
        "    \n",
        "    if mode == \"1\":\n",
        "        custom_bbox = interactive_roi_selection(custom_image)\n",
        "    else:\n",
        "        # Mode automatique - toute l'image\n",
        "        custom_bbox = [0, 0, custom_image.width, custom_image.height]\n",
        "        print(f\"‚úÖ ROI automatique : toute l'image {custom_image.size}\")\n",
        "else:\n",
        "    print(\"‚ùå Pas d'image charg√©e. Ex√©cutez d'abord la cellule d'upload.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELLULE D'ANALYSE\n",
        "if 'custom_image' in locals() and 'custom_bbox' in locals():\n",
        "    custom_prediction, custom_probabilities = analyze_custom_image(\n",
        "        custom_image, custom_bbox, custom_filename\n",
        "    )\n",
        "    \n",
        "    print(\"\\n‚úÖ Analyse termin√©e !\")\n",
        "    print(\"\\nüè• Recommandations cliniques :\")\n",
        "    print(\"- Ces r√©sultats sont √† des fins √©ducatives uniquement\")\n",
        "    print(\"- Toujours consulter un radiologue qualifi√© pour le diagnostic\")\n",
        "    print(\"- L'IA est un outil d'assistance, pas de remplacement\")\n",
        "    print(\"- Corr√©ler avec la clinique et autres examens\")\nelse:\n",
        "    print(\"‚ùå Pas d'image ou de ROI d√©finie. Ex√©cutez les cellules pr√©c√©dentes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sauvegarde et Documentation de vos Analyses\n",
        "\n",
        "Cr√©ons un rapport de vos analyses pour r√©vision :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "import json\n",
        "\n",
        "def create_analysis_report(results, custom_results=None):\n",
        "    \"\"\"\n",
        "    Cr√©e un rapport d'analyse pour documentation\n",
        "    \"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    \n",
        "    report = {\n",
        "        \"session_info\": {\n",
        "            \"timestamp\": timestamp,\n",
        "            \"model\": \"MedSAM (wanglab/medsam-vit-base)\",\n",
        "            \"device\": str(device),\n",
        "            \"dataset\": \"nielsr/breast-cancer\"\n",
        "        },\n",
        "        \"standard_analysis\": {\n",
        "            \"num_cases\": len(results) if results else 0,\n",
        "            \"performance_metrics\": {}\n",
        "        },\n",
        "        \"custom_analysis\": {}\n",
        "    }\n",
        "    \n",
        "    # M√©triques sur les cas standards\n",
        "    if results:\n",
        "        metrics_summary = {\n",
        "            \"mean_dice\": float(np.mean([r['dice'] for r in results])),\n",
        "            \"std_dice\": float(np.std([r['dice'] for r in results])),\n",
        "            \"mean_sensitivity\": float(np.mean([r['sensitivity'] for r in results])),\n",
        "            \"mean_specificity\": float(np.mean([r['specificity'] for r in results]))\n",
        "        }\n",
        "        report[\"standard_analysis\"][\"performance_metrics\"] = metrics_summary\n",
        "    \n",
        "    # R√©sultats personnalis√©s\n",
        "    if custom_results:\n",
        "        report[\"custom_analysis\"] = {\n",
        "            \"filename\": custom_results.get(\"filename\", \"unknown\"),\n",
        "            \"image_size\": custom_results.get(\"image_size\", [0, 0]),\n",
        "            \"roi_coordinates\": custom_results.get(\"bbox\", [0, 0, 0, 0]),\n",
        "            \"positive_pixels\": int(custom_results.get(\"positive_pixels\", 0)),\n",
        "            \"positive_percentage\": float(custom_results.get(\"positive_percentage\", 0)),\n",
        "            \"max_confidence\": float(custom_results.get(\"max_confidence\", 0))\n",
        "        }\n",
        "    \n",
        "    return report\n",
        "\n",
        "# Cr√©ation du rapport\n",
        "custom_data = None\n",
        "if 'custom_prediction' in locals():\n",
        "    custom_data = {\n",
        "        \"filename\": custom_filename,\n",
        "        \"image_size\": list(custom_image.size),\n",
        "        \"bbox\": custom_bbox,\n",
        "        \"positive_pixels\": np.sum(custom_prediction),\n",
        "        \"positive_percentage\": (np.sum(custom_prediction) / custom_prediction.size) * 100,\n",
        "        \"max_confidence\": np.max(custom_probabilities)\n",
        "    }\n",
        "\n",
        "analysis_report = create_analysis_report(multi_results, custom_data)\n",
        "\n",
        "# Sauvegarde du rapport\n",
        "report_filename = f\"rapport_analyse_MedSAM_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "report_path = f\"{results_dir}{report_filename}\"\n",
        "\n",
        "with open(report_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(analysis_report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"üìÑ Rapport d'analyse sauvegard√© : {report_path}\")\n",
        "print(f\"\\nüìã R√©sum√© de la session :\")\n",
        "print(f\"- Timestamp : {analysis_report['session_info']['timestamp']}\")\n",
        "print(f\"- Mod√®le utilis√© : {analysis_report['session_info']['model']}\")\n",
        "print(f\"- Device : {analysis_report['session_info']['device']}\")\n",
        "if multi_results:\n",
        "    print(f\"- Cas analys√©s : {len(multi_results)}\")\n",
        "    print(f\"- Performance moyenne : {analysis_report['standard_analysis']['performance_metrics'].get('mean_dice', 0):.3f}\")\n",
        "if custom_data:\n",
        "    print(f\"- Image personnalis√©e : {custom_data['filename']}\")\n",
        "    print(f\"- D√©tection : {custom_data['positive_percentage']:.2f}% de l'image\")\n",
        "\n",
        "print(f\"\\nüíæ Tous vos r√©sultats sont sauvegard√©s dans : {results_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Consid√©rations √âthiques et Cliniques\n",
        "\n",
        "### üè• Points Importants pour les Futurs M√©decins :\n",
        "\n",
        "#### Responsabilit√©s Professionnelles :\n",
        "- **L'IA est un outil d'aide au diagnostic**, jamais un remplacement du jugement clinique\n",
        "- **Toujours corr√©ler** avec l'examen clinique, l'anamn√®se et autres examens\n",
        "- **Maintenir la formation continue** sur les nouvelles technologies d'IA m√©dicale\n",
        "- **Comprendre les limites** de chaque syst√®me d'IA utilis√©\n",
        "\n",
        "#### √âthique M√©dicale et IA :\n",
        "- **Consentement √©clair√©** : Informer les patients de l'utilisation d'IA\n",
        "- **Transparence** : Expliquer le r√¥le de l'IA dans le diagnostic\n",
        "- **Responsabilit√©** : Le m√©decin reste responsable du diagnostic final\n",
        "- **√âquit√©** : S'assurer que l'IA ne g√©n√®re pas de biais discriminatoires\n",
        "\n",
        "#### Qualit√© et S√©curit√© :\n",
        "- **Validation clinique** : Utiliser uniquement des syst√®mes valid√©s cliniquement\n",
        "- **Formation** : Se former r√©guli√®rement sur les outils d'IA utilis√©s\n",
        "- **Double v√©rification** : Toujours v√©rifier les r√©sultats de l'IA\n",
        "- **Documentation** : Documenter l'utilisation d'IA dans le dossier patient\n",
        "\n",
        "### üî¨ Applications Futures en M√©decine :\n",
        "\n",
        "#### Radiologie :\n",
        "- D√©tection pr√©coce de cancers\n",
        "- Analyse quantitative des l√©sions\n",
        "- Priorisation des cas urgents\n",
        "\n",
        "#### Pathologie :\n",
        "- Analyse histopathologique automatis√©e\n",
        "- Gradation tumorale assist√©e\n",
        "- D√©tection de micro-m√©tastases\n",
        "\n",
        "#### Autres Sp√©cialit√©s :\n",
        "- Ophtalmologie : D√©pistage r√©tinopathie diab√©tique\n",
        "- Dermatologie : Classification des l√©sions cutan√©es\n",
        "- Cardiologie : Analyse √©chocardiographique\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "F√©licitations ! Vous avez appris √† :\n",
        "1. ‚úÖ **Utiliser MedSAM** pour la segmentation d'images m√©dicales\n",
        "2. ‚úÖ **√âvaluer quantitativement** les performances d'un mod√®le d'IA\n",
        "3. ‚úÖ **Tester sur vos propres images** m√©dicales\n",
        "4. ‚úÖ **Comprendre les implications √©thiques** de l'IA en m√©decine\n",
        "\n",
        "### üìö Pour Approfondir :\n",
        "- Article original MedSAM : [arXiv:2304.12306](https://arxiv.org/abs/2304.12306)\n",
        "- Repo GitHub : [bowang-lab/MedSAM](https://github.com/bowang-lab/MedSAM)\n",
        "- Documentation Hugging Face : [transformers/sam](https://huggingface.co/docs/transformers/model_doc/sam)\n",
        "\n",
        "### üéì Message pour les Futurs M√©decins :\n",
        "L'intelligence artificielle transforme rapidement la pratique m√©dicale. En tant que futurs praticiens, vous devez √™tre pr√©par√©s √† utiliser ces outils de mani√®re √©thique et efficace. L'IA ne remplacera jamais l'empathie, le jugement clinique et l'expertise m√©dicale humaine, mais elle peut consid√©rablement am√©liorer la pr√©cision diagnostique et l'efficacit√© des soins.\n",
        "\n",
        "**Continuez √† apprendre, restez curieux, et gardez toujours le patient au centre de vos pr√©occupations !**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}