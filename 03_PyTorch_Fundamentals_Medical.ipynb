{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/maclandrol/cours-ia-med/blob/master/03_PyTorch_Fundamentals_Medical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03. Fondamentaux PyTorch pour Applications Médicales\n",
        "\n",
        "**Enseignant:** Emmanuel Noutahi, PhD\n",
        "\n",
        "---\n",
        "\n",
        "**Objectif:** Maîtriser les outils PyTorch essentiels pour l'intelligence artificielle médicale.\n",
        "\n",
        "**Applications pratiques :**\n",
        "- Manipulation de données patients avec les tenseurs\n",
        "- Intégration des modèles HuggingFace en contexte médical\n",
        "- Traitement d'images médicales par lots\n",
        "- Utilisation de modèles pré-entraînés pour l'inférence\n",
        "\n",
        "**Important:** Ce cours vous enseigne l'utilisation pratique de PyTorch, pas la programmation avancée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation et Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation des bibliothèques essentielles pour l'IA médicale\n",
        "!pip install torch torchvision transformers datasets huggingface_hub -q\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn -q\n",
        "!pip install pydicom pillow -q\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration pour la reproductibilité\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Détection du dispositif de calcul\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Dispositif utilisé: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU détecté: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Mémoire GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "print(\"Configuration PyTorch médical terminée.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Tenseurs PyTorch pour Données Médicales\n",
        "\n",
        "Les tenseurs PyTorch sont la structure de données fondamentale pour l'IA médicale. Ils permettent de manipuler efficacement les données patients, images médicales et paramètres biologiques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 1: Données de cohorte de patients\n",
        "print(\"=== GESTION DE COHORTES DE PATIENTS ===\")\n",
        "\n",
        "# Simuler des données de 100 patients\n",
        "n_patients = 100\n",
        "\n",
        "# Caractéristiques démographiques et cliniques\n",
        "# [âge, poids_kg, taille_m, tension_systolique, tension_diastolique, glycémie]\n",
        "patient_data = torch.tensor([\n",
        "    [np.random.normal(65, 15), np.random.normal(70, 12), np.random.normal(1.70, 0.15),\n",
        "     np.random.normal(130, 20), np.random.normal(80, 10), np.random.normal(5.5, 1.2)]\n",
        "    for _ in range(n_patients)\n",
        "], dtype=torch.float32)\n",
        "\n",
        "print(f\"Cohorte de patients: {patient_data.shape}\")\n",
        "print(f\"Caractéristiques: Âge, Poids(kg), Taille(m), TA_sys, TA_dia, Glycémie\")\n",
        "\n",
        "# Calculs vectorisés d'indices cliniques\n",
        "ages = patient_data[:, 0]\n",
        "poids = patient_data[:, 1]\n",
        "tailles = patient_data[:, 2]\n",
        "ta_sys = patient_data[:, 3]\n",
        "ta_dia = patient_data[:, 4]\n",
        "glycemie = patient_data[:, 5]\n",
        "\n",
        "# Calcul de l'IMC pour toute la cohorte\n",
        "imc = poids / (tailles ** 2)\n",
        "\n",
        "# Pression artérielle moyenne\n",
        "pam = ta_dia + (ta_sys - ta_dia) / 3\n",
        "\n",
        "# Catégorisation automatique\n",
        "obesite = imc > 30\n",
        "hypertension = ta_sys > 140\n",
        "diabete = glycemie > 7.0\n",
        "\n",
        "print(f\"\\nRésultats de la cohorte:\")\n",
        "print(f\"IMC moyen: {imc.mean():.1f} ± {imc.std():.1f}\")\n",
        "print(f\"Patients obèses: {obesite.sum().item()}/{n_patients} ({obesite.float().mean()*100:.1f}%)\")\n",
        "print(f\"Patients hypertendus: {hypertension.sum().item()}/{n_patients} ({hypertension.float().mean()*100:.1f}%)\")\n",
        "print(f\"Patients diabétiques: {diabete.sum().item()}/{n_patients} ({diabete.float().mean()*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 2: Matrices de corrélation clinique\n",
        "print(\"=== ANALYSE DE CORRÉLATIONS CLINIQUES ===\")\n",
        "\n",
        "# Calcul de la matrice de corrélation\n",
        "correlation_matrix = torch.corrcoef(patient_data.T)\n",
        "\n",
        "# Visualisation avec matplotlib\n",
        "features = ['Âge', 'Poids', 'Taille', 'TA_sys', 'TA_dia', 'Glycémie']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix.numpy(), annot=True, cmap='coolwarm', center=0,\n",
        "            xticklabels=features, yticklabels=features, fmt='.2f')\n",
        "plt.title('Matrice de Corrélation - Paramètres Cliniques')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Identification des corrélations significatives\n",
        "print(\"\\nCorrélations cliniques notables:\")\n",
        "for i in range(len(features)):\n",
        "    for j in range(i+1, len(features)):\n",
        "        corr_val = correlation_matrix[i, j].item()\n",
        "        if abs(corr_val) > 0.3:  # Seuil de corrélation modérée\n",
        "            print(f\"{features[i]} ↔ {features[j]}: r = {corr_val:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Images Médicales et Tenseurs\n",
        "\n",
        "Les images médicales nécessitent une manipulation spécialisée. PyTorch offre des outils efficaces pour le traitement par lots d'images radiologiques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Création d'images médicales simulées\n",
        "print(\"=== TRAITEMENT D'IMAGES MÉDICALES ===\")\n",
        "\n",
        "def create_medical_image_batch(batch_size=8, image_size=256):\n",
        "    \"\"\"\n",
        "    Crée un lot d'images médicales simulées pour démonstration\n",
        "    Format: (batch_size, channels, height, width)\n",
        "    \"\"\"\n",
        "    images = torch.zeros(batch_size, 1, image_size, image_size)\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        # Base d'image (tissu normal)\n",
        "        base_intensity = 0.3 + torch.rand(1) * 0.2\n",
        "        images[i, 0] = base_intensity\n",
        "        \n",
        "        # Ajout de structures anatomiques\n",
        "        center_x, center_y = image_size // 2, image_size // 2\n",
        "        \n",
        "        # Structure circulaire (organe)\n",
        "        y_coords, x_coords = torch.meshgrid(torch.arange(image_size), torch.arange(image_size), indexing='ij')\n",
        "        distance = torch.sqrt((x_coords - center_x)**2 + (y_coords - center_y)**2)\n",
        "        organ_mask = distance < (30 + torch.rand(1) * 20)\n",
        "        images[i, 0][organ_mask] = 0.7 + torch.rand(1) * 0.2\n",
        "        \n",
        "        # Anomalie potentielle (probabilité 30%)\n",
        "        if torch.rand(1) < 0.3:\n",
        "            anomaly_x = torch.randint(50, image_size-50, (1,)).item()\n",
        "            anomaly_y = torch.randint(50, image_size-50, (1,)).item()\n",
        "            anomaly_size = torch.randint(10, 25, (1,)).item()\n",
        "            \n",
        "            anomaly_distance = torch.sqrt((x_coords - anomaly_x)**2 + (y_coords - anomaly_y)**2)\n",
        "            anomaly_mask = anomaly_distance < anomaly_size\n",
        "            images[i, 0][anomaly_mask] = 0.9 + torch.rand(1) * 0.1\n",
        "    \n",
        "    return images\n",
        "\n",
        "# Génération du lot d'images\n",
        "medical_batch = create_medical_image_batch(batch_size=8, image_size=256)\n",
        "print(f\"Lot d'images médicales créé: {medical_batch.shape}\")\n",
        "print(f\"Format: [batch, canaux, hauteur, largeur]\")\n",
        "print(f\"Plage d'intensité: [{medical_batch.min():.3f}, {medical_batch.max():.3f}]\")\n",
        "\n",
        "# Statistiques par image\n",
        "print(\"\\nAnalyse du lot:\")\n",
        "for i in range(medical_batch.shape[0]):\n",
        "    img = medical_batch[i, 0]\n",
        "    mean_intensity = img.mean()\n",
        "    std_intensity = img.std()\n",
        "    max_intensity = img.max()\n",
        "    \n",
        "    # Détection d'anomalie basée sur l'intensité maximale\n",
        "    anomaly_detected = max_intensity > 0.8\n",
        "    status = \"ANOMALIE\" if anomaly_detected else \"NORMAL\"\n",
        "    \n",
        "    print(f\"Image {i+1}: Moyenne={mean_intensity:.3f}, Écart-type={std_intensity:.3f}, Max={max_intensity:.3f} [{status}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation du lot d'images médicales\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "fig.suptitle('Lot d\\'Images Médicales - Analyse Automatisée', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < medical_batch.shape[0]:\n",
        "        img = medical_batch[i, 0]\n",
        "        im = ax.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
        "        \n",
        "        # Classification automatique\n",
        "        max_intensity = img.max().item()\n",
        "        if max_intensity > 0.8:\n",
        "            title_color = 'red'\n",
        "            classification = 'ANOMALIE'\n",
        "        else:\n",
        "            title_color = 'green'\n",
        "            classification = 'NORMAL'\n",
        "        \n",
        "        ax.set_title(f'Image {i+1}\\n{classification}', color=title_color, fontweight='bold')\n",
        "        ax.axis('off')\n",
        "        \n",
        "        # Ajouter une barre de couleur pour la première image\n",
        "        if i == 0:\n",
        "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Transformations Médicales Standardisées\n",
        "\n",
        "Les images médicales nécessitent des prétraitements spécifiques pour optimiser les performances des modèles d'IA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline de transformations médicales\n",
        "print(\"=== PIPELINE DE TRANSFORMATIONS MÉDICALES ===\")\n",
        "\n",
        "class MedicalImageProcessor:\n",
        "    \"\"\"\n",
        "    Processeur d'images médicales avec transformations standardisées\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, target_size=224, normalize_to_unit=True):\n",
        "        self.target_size = target_size\n",
        "        self.normalize_to_unit = normalize_to_unit\n",
        "        \n",
        "        # Transformations pour l'entraînement (avec augmentation)\n",
        "        self.train_transforms = transforms.Compose([\n",
        "            transforms.Resize((target_size, target_size)),\n",
        "            transforms.RandomRotation(degrees=5),  # Rotation légère médicalement plausible\n",
        "            transforms.RandomHorizontalFlip(p=0.1),  # Flip limité (asymétrie anatomique)\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Variation d'acquisition\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        \n",
        "        # Transformations pour l'inférence (sans augmentation)\n",
        "        self.inference_transforms = transforms.Compose([\n",
        "            transforms.Resize((target_size, target_size)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "    \n",
        "    def normalize_medical_image(self, image_tensor):\n",
        "        \"\"\"\n",
        "        Normalisation spécifique aux images médicales\n",
        "        \"\"\"\n",
        "        if self.normalize_to_unit:\n",
        "            # Normalisation min-max à [0,1]\n",
        "            min_val = image_tensor.min()\n",
        "            max_val = image_tensor.max()\n",
        "            if max_val > min_val:\n",
        "                image_tensor = (image_tensor - min_val) / (max_val - min_val)\n",
        "        \n",
        "        return image_tensor\n",
        "    \n",
        "    def process_batch(self, image_batch, mode='inference'):\n",
        "        \"\"\"\n",
        "        Traite un lot d'images médicales\n",
        "        \"\"\"\n",
        "        processed_images = []\n",
        "        \n",
        "        for i in range(image_batch.shape[0]):\n",
        "            # Conversion en PIL Image pour les transformations\n",
        "            img_array = image_batch[i, 0].numpy()\n",
        "            img_pil = Image.fromarray((img_array * 255).astype(np.uint8), mode='L')\n",
        "            \n",
        "            # Application des transformations\n",
        "            if mode == 'train':\n",
        "                img_transformed = self.train_transforms(img_pil)\n",
        "            else:\n",
        "                img_transformed = self.inference_transforms(img_pil)\n",
        "            \n",
        "            # Normalisation médicale\n",
        "            img_normalized = self.normalize_medical_image(img_transformed)\n",
        "            processed_images.append(img_normalized)\n",
        "        \n",
        "        return torch.stack(processed_images)\n",
        "\n",
        "# Test du processeur\n",
        "processor = MedicalImageProcessor(target_size=224)\n",
        "\n",
        "# Traitement pour l'inférence\n",
        "processed_batch = processor.process_batch(medical_batch, mode='inference')\n",
        "print(f\"Lot original: {medical_batch.shape}\")\n",
        "print(f\"Lot traité: {processed_batch.shape}\")\n",
        "print(f\"Plage normalisée: [{processed_batch.min():.3f}, {processed_batch.max():.3f}]\")\n",
        "\n",
        "# Comparaison visuelle\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "fig.suptitle('Comparaison: Avant et Après Traitement', fontsize=16)\n",
        "\n",
        "for i in range(4):\n",
        "    # Image originale\n",
        "    axes[0, i].imshow(medical_batch[i, 0], cmap='gray')\n",
        "    axes[0, i].set_title(f'Original {i+1}\\n{medical_batch.shape[2]}x{medical_batch.shape[3]}')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Image traitée\n",
        "    axes[1, i].imshow(processed_batch[i, 0], cmap='gray')\n",
        "    axes[1, i].set_title(f'Traité {i+1}\\n{processed_batch.shape[2]}x{processed_batch.shape[3]}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Intégration HuggingFace pour Modèles Médicaux\n",
        "\n",
        "HuggingFace propose une vaste collection de modèles pré-entraînés adaptés au domaine médical. Apprenons à les intégrer efficacement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement d'un modèle médical depuis HuggingFace\n",
        "print(\"=== INTÉGRATION HUGGINGFACE POUR LE MÉDICAL ===\")\n",
        "\n",
        "# Exemple 1: Modèle de texte médical français\n",
        "try:\n",
        "    # Tokenizer et modèle pour le français médical\n",
        "    model_name = \"camembert-base\"  # Base pour le français\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "    \n",
        "    print(f\"Modèle chargé: {model_name}\")\n",
        "    print(f\"Taille du vocabulaire: {len(tokenizer)}\")\n",
        "    \n",
        "    # Test avec du texte médical français\n",
        "    medical_texts = [\n",
        "        \"Patient présentant une dyspnée d'effort avec douleurs thoraciques.\",\n",
        "        \"Radiographie pulmonaire montrant une opacité lobaire supérieure droite.\",\n",
        "        \"Échographie abdominale révélant une hépatomégalie modérée.\",\n",
        "        \"Électrocardiogramme normal, rythme sinusal régulier.\"\n",
        "    ]\n",
        "    \n",
        "    print(\"\\nTokenisation d'exemples médicaux:\")\n",
        "    for i, text in enumerate(medical_texts):\n",
        "        # Tokenisation\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "        \n",
        "        print(f\"\\nTexte {i+1}: {text[:50]}...\")\n",
        "        print(f\"Nombre de tokens: {len(tokens)}\")\n",
        "        print(f\"Premiers tokens: {tokens[:5]}\")\n",
        "        \n",
        "        # Inférence rapide (embeddings)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids)\n",
        "            embeddings = outputs.last_hidden_state\n",
        "            \n",
        "        print(f\"Dimensions embeddings: {embeddings.shape}\")\n",
        "        \n",
        "        # Embedding moyen de la phrase (représentation vectorielle)\n",
        "        sentence_embedding = embeddings.mean(dim=1).squeeze()\n",
        "        print(f\"Représentation vectorielle: {sentence_embedding.shape} (norme: {torch.norm(sentence_embedding):.3f})\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement du modèle: {e}\")\n",
        "    print(\"Vérifiez votre connexion internet ou utilisez un modèle local.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple 2: Similarité sémantique entre termes médicaux\n",
        "print(\"\\n=== ANALYSE DE SIMILARITÉ MÉDICALE ===\")\n",
        "\n",
        "def compute_medical_similarity(texts, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Calcule la similarité cosinus entre textes médicaux\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    \n",
        "    for text in texts:\n",
        "        # Encodage et inférence\n",
        "        input_ids = tokenizer.encode(text, return_tensors='pt', truncation=True, max_length=128)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids)\n",
        "            # Moyenne des embeddings comme représentation de la phrase\n",
        "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "            embeddings.append(embedding)\n",
        "    \n",
        "    # Conversion en matrice\n",
        "    embeddings = torch.stack(embeddings)\n",
        "    \n",
        "    # Calcul de similarité cosinus\n",
        "    similarity_matrix = torch.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
        "    \n",
        "    return similarity_matrix\n",
        "\n",
        "# Termes médicaux pour test de similarité\n",
        "medical_terms = [\n",
        "    \"pneumonie\",\n",
        "    \"infection pulmonaire\",\n",
        "    \"cardiomégalie\",\n",
        "    \"hypertrophie cardiaque\",\n",
        "    \"fracture osseuse\",\n",
        "    \"diabète sucré\"\n",
        "]\n",
        "\n",
        "try:\n",
        "    # Calcul des similarités\n",
        "    similarity_matrix = compute_medical_similarity(medical_terms, model, tokenizer)\n",
        "    \n",
        "    # Visualisation\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(similarity_matrix.numpy(), annot=True, cmap='YlOrRd', \n",
        "                xticklabels=medical_terms, yticklabels=medical_terms, fmt='.3f')\n",
        "    plt.title('Matrice de Similarité Sémantique - Termes Médicaux')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Analyse des paires les plus similaires\n",
        "    print(\"\\nPaires de termes médicaux les plus similaires:\")\n",
        "    for i in range(len(medical_terms)):\n",
        "        for j in range(i+1, len(medical_terms)):\n",
        "            similarity = similarity_matrix[i, j].item()\n",
        "            if similarity > 0.7:  # Seuil de similarité élevée\n",
        "                print(f\"'{medical_terms[i]}' ↔ '{medical_terms[j]}': {similarity:.3f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du calcul de similarité: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Inférence avec Modèles Pré-entraînés\n",
        "\n",
        "L'utilisation de modèles pré-entraînés est essentielle pour des applications médicales rapides et fiables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simuler l'utilisation d'un modèle de classification d'images médicales\n",
        "print(\"=== INFÉRENCE AVEC MODÈLES PRÉ-ENTRAÎNÉS ===\")\n",
        "\n",
        "class MedicalImageClassifier:\n",
        "    \"\"\"\n",
        "    Simulateur de modèle de classification d'images médicales\n",
        "    En pratique, ceci serait un vrai modèle comme TorchXRayVision\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=5):\n",
        "        self.num_classes = num_classes\n",
        "        self.class_names = [\n",
        "            \"Normal\",\n",
        "            \"Pneumonie\",\n",
        "            \"Cardiomégalie\", \n",
        "            \"Œdème pulmonaire\",\n",
        "            \"Pneumothorax\"\n",
        "        ]\n",
        "        \n",
        "        # Architecture simple pour démonstration\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        \n",
        "        self.classifier = nn.Linear(32, num_classes)\n",
        "        \n",
        "        # Initialisation simple\n",
        "        self._initialize_weights()\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Initialisation des poids du modèle\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "    \n",
        "    def predict(self, images):\n",
        "        \"\"\"\n",
        "        Prédiction sur un lot d'images\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            features = self.features(images)\n",
        "            logits = self.classifier(features)\n",
        "            probabilities = torch.softmax(logits, dim=1)\n",
        "            predictions = torch.argmax(probabilities, dim=1)\n",
        "            \n",
        "        return predictions, probabilities\n",
        "    \n",
        "    def get_prediction_summary(self, images):\n",
        "        \"\"\"\n",
        "        Génère un résumé détaillé des prédictions\n",
        "        \"\"\"\n",
        "        predictions, probabilities = self.predict(images)\n",
        "        \n",
        "        results = []\n",
        "        for i in range(len(images)):\n",
        "            pred_idx = predictions[i].item()\n",
        "            pred_class = self.class_names[pred_idx]\n",
        "            confidence = probabilities[i, pred_idx].item()\n",
        "            \n",
        "            # Distribution complète des probabilités\n",
        "            prob_dist = {name: probabilities[i, j].item() \n",
        "                        for j, name in enumerate(self.class_names)}\n",
        "            \n",
        "            results.append({\n",
        "                'image_id': i,\n",
        "                'predicted_class': pred_class,\n",
        "                'confidence': confidence,\n",
        "                'probability_distribution': prob_dist\n",
        "            })\n",
        "        \n",
        "        return results\n",
        "\n",
        "# Instanciation et test du modèle\n",
        "classifier = MedicalImageClassifier()\n",
        "print(f\"Modèle créé avec {sum(p.numel() for p in classifier.parameters())} paramètres\")\n",
        "\n",
        "# Prédiction sur notre lot d'images médicales\n",
        "results = classifier.get_prediction_summary(processed_batch)\n",
        "\n",
        "print(\"\\nRésultats de classification:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for result in results:\n",
        "    img_id = result['image_id']\n",
        "    pred_class = result['predicted_class']\n",
        "    confidence = result['confidence']\n",
        "    \n",
        "    print(f\"\\nImage {img_id + 1}:\")\n",
        "    print(f\"  Diagnostic: {pred_class}\")\n",
        "    print(f\"  Confiance: {confidence:.1%}\")\n",
        "    \n",
        "    # Affichage des top 3 probabilités\n",
        "    prob_dist = result['probability_distribution']\n",
        "    sorted_probs = sorted(prob_dist.items(), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    print(f\"  Top 3 diagnostics:\")\n",
        "    for j, (class_name, prob) in enumerate(sorted_probs[:3]):\n",
        "        print(f\"    {j+1}. {class_name}: {prob:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation des résultats de classification\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 10))\n",
        "fig.suptitle('Classification Automatique d\\'Images Médicales', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i, (result, ax) in enumerate(zip(results, axes.flat)):\n",
        "    # Affichage de l'image\n",
        "    ax.imshow(processed_batch[i, 0], cmap='gray')\n",
        "    \n",
        "    # Informations de classification\n",
        "    pred_class = result['predicted_class']\n",
        "    confidence = result['confidence']\n",
        "    \n",
        "    # Couleur selon la confiance\n",
        "    if confidence > 0.7:\n",
        "        title_color = 'green'\n",
        "        conf_level = 'HAUTE'\n",
        "    elif confidence > 0.5:\n",
        "        title_color = 'orange'\n",
        "        conf_level = 'MODÉRÉE'\n",
        "    else:\n",
        "        title_color = 'red'\n",
        "        conf_level = 'FAIBLE'\n",
        "    \n",
        "    ax.set_title(f'Image {i+1}\\n{pred_class}\\nConfiance: {confidence:.1%} ({conf_level})', \n",
        "                color=title_color, fontweight='bold', fontsize=10)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistiques globales de la classification\n",
        "print(\"\\n=== STATISTIQUES DE CLASSIFICATION ===\")\n",
        "predictions_count = {}\n",
        "confidence_levels = {'HAUTE': 0, 'MODÉRÉE': 0, 'FAIBLE': 0}\n",
        "total_confidence = 0\n",
        "\n",
        "for result in results:\n",
        "    pred_class = result['predicted_class']\n",
        "    confidence = result['confidence']\n",
        "    \n",
        "    # Comptage des prédictions\n",
        "    predictions_count[pred_class] = predictions_count.get(pred_class, 0) + 1\n",
        "    \n",
        "    # Niveaux de confiance\n",
        "    if confidence > 0.7:\n",
        "        confidence_levels['HAUTE'] += 1\n",
        "    elif confidence > 0.5:\n",
        "        confidence_levels['MODÉRÉE'] += 1\n",
        "    else:\n",
        "        confidence_levels['FAIBLE'] += 1\n",
        "    \n",
        "    total_confidence += confidence\n",
        "\n",
        "print(f\"Répartition des diagnostics:\")\n",
        "for diagnosis, count in predictions_count.items():\n",
        "    percentage = (count / len(results)) * 100\n",
        "    print(f\"  {diagnosis}: {count} cas ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\nNiveaux de confiance:\")\n",
        "for level, count in confidence_levels.items():\n",
        "    percentage = (count / len(results)) * 100\n",
        "    print(f\"  {level}: {count} cas ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\nConfiance moyenne: {total_confidence / len(results):.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Optimisation et Déploiement\n",
        "\n",
        "Pour une utilisation clinique efficace, l'optimisation des modèles PyTorch est cruciale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Techniques d'optimisation pour modèles médicaux\n",
        "print(\"=== OPTIMISATION POUR DÉPLOIEMENT CLINIQUE ===\")\n",
        "\n",
        "import time\n",
        "\n",
        "class OptimizedMedicalClassifier:\n",
        "    \"\"\"\n",
        "    Version optimisée du classificateur médical pour déploiement\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, original_model):\n",
        "        self.original_model = original_model\n",
        "        self.optimized_model = None\n",
        "        self.class_names = original_model.class_names\n",
        "    \n",
        "    def optimize_for_inference(self):\n",
        "        \"\"\"\n",
        "        Optimise le modèle pour l'inférence rapide\n",
        "        \"\"\"\n",
        "        # Mode évaluation\n",
        "        self.original_model.eval()\n",
        "        \n",
        "        # Optimisation avec TorchScript\n",
        "        example_input = torch.randn(1, 1, 224, 224)\n",
        "        \n",
        "        try:\n",
        "            # Création du modèle TorchScript\n",
        "            self.optimized_model = torch.jit.trace(self.original_model, example_input)\n",
        "            self.optimized_model.eval()\n",
        "            print(\"Optimisation TorchScript: SUCCÈS\")\n",
        "        except Exception as e:\n",
        "            print(f\"Optimisation TorchScript: ÉCHEC ({e})\")\n",
        "            self.optimized_model = self.original_model\n",
        "        \n",
        "        return self.optimized_model\n",
        "    \n",
        "    def benchmark_performance(self, test_batch, num_runs=100):\n",
        "        \"\"\"\n",
        "        Compare les performances avant et après optimisation\n",
        "        \"\"\"\n",
        "        print(f\"\\nBenchmark de performance ({num_runs} exécutions):\")\n",
        "        \n",
        "        # Test du modèle original\n",
        "        start_time = time.time()\n",
        "        for _ in range(num_runs):\n",
        "            with torch.no_grad():\n",
        "                _ = self.original_model.predict(test_batch[:1])  # 1 image à la fois\n",
        "        original_time = time.time() - start_time\n",
        "        \n",
        "        # Test du modèle optimisé\n",
        "        if self.optimized_model:\n",
        "            start_time = time.time()\n",
        "            for _ in range(num_runs):\n",
        "                with torch.no_grad():\n",
        "                    # Pour TorchScript, appel direct\n",
        "                    features = self.optimized_model.features(test_batch[:1])\n",
        "                    _ = self.optimized_model.classifier(features)\n",
        "            optimized_time = time.time() - start_time\n",
        "            \n",
        "            speedup = original_time / optimized_time\n",
        "            \n",
        "            print(f\"  Modèle original: {original_time:.3f}s ({original_time/num_runs*1000:.1f}ms par image)\")\n",
        "            print(f\"  Modèle optimisé: {optimized_time:.3f}s ({optimized_time/num_runs*1000:.1f}ms par image)\")\n",
        "            print(f\"  Accélération: {speedup:.2f}x\")\n",
        "        else:\n",
        "            print(f\"  Modèle original: {original_time:.3f}s ({original_time/num_runs*1000:.1f}ms par image)\")\n",
        "            print(\"  Pas d'optimisation disponible\")\n",
        "    \n",
        "    def save_for_production(self, save_path):\n",
        "        \"\"\"\n",
        "        Sauvegarde le modèle optimisé pour production\n",
        "        \"\"\"\n",
        "        if self.optimized_model:\n",
        "            torch.jit.save(self.optimized_model, save_path + \"_optimized.pt\")\n",
        "            print(f\"Modèle optimisé sauvegardé: {save_path}_optimized.pt\")\n",
        "        \n",
        "        # Sauvegarde des métadonnées\n",
        "        metadata = {\n",
        "            'class_names': self.class_names,\n",
        "            'input_size': [224, 224],\n",
        "            'num_classes': len(self.class_names),\n",
        "            'optimization': 'TorchScript' if self.optimized_model else 'None'\n",
        "        }\n",
        "        \n",
        "        torch.save(metadata, save_path + \"_metadata.pt\")\n",
        "        print(f\"Métadonnées sauvegardées: {save_path}_metadata.pt\")\n",
        "\n",
        "# Test d'optimisation\n",
        "optimizer = OptimizedMedicalClassifier(classifier)\n",
        "optimized_model = optimizer.optimize_for_inference()\n",
        "\n",
        "# Benchmark de performance\n",
        "optimizer.benchmark_performance(processed_batch, num_runs=50)\n",
        "\n",
        "# Sauvegarde pour production\n",
        "optimizer.save_for_production(\"./medical_classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse de l'utilisation mémoire\n",
        "print(\"\\n=== ANALYSE DE L'UTILISATION MÉMOIRE ===\")\n",
        "\n",
        "def analyze_memory_usage(model, input_batch):\n",
        "    \"\"\"\n",
        "    Analyse l'utilisation mémoire du modèle\n",
        "    \"\"\"\n",
        "    # Taille du modèle\n",
        "    model_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
        "    print(f\"Taille du modèle: {model_size / 1024**2:.1f} MB\")\n",
        "    \n",
        "    # Taille des paramètres\n",
        "    num_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Nombre de paramètres: {num_params:,}\")\n",
        "    \n",
        "    # Mémoire d'entrée\n",
        "    input_memory = input_batch.element_size() * input_batch.numel()\n",
        "    print(f\"Mémoire d'entrée (batch de {input_batch.shape[0]}): {input_memory / 1024**2:.1f} MB\")\n",
        "    \n",
        "    # Estimation mémoire totale\n",
        "    total_memory = model_size + input_memory\n",
        "    print(f\"Estimation mémoire totale: {total_memory / 1024**2:.1f} MB\")\n",
        "    \n",
        "    return {\n",
        "        'model_size_mb': model_size / 1024**2,\n",
        "        'num_params': num_params,\n",
        "        'input_memory_mb': input_memory / 1024**2,\n",
        "        'total_memory_mb': total_memory / 1024**2\n",
        "    }\n",
        "\n",
        "memory_stats = analyze_memory_usage(classifier, processed_batch)\n",
        "\n",
        "# Recommandations de déploiement\n",
        "print(\"\\n=== RECOMMANDATIONS DE DÉPLOIEMENT ===\")\n",
        "\n",
        "total_memory = memory_stats['total_memory_mb']\n",
        "\n",
        "if total_memory < 100:\n",
        "    deployment_tier = \"MOBILE/EDGE\"\n",
        "    recommendations = [\n",
        "        \"Déploiement possible sur appareils mobiles\",\n",
        "        \"Utilisation en consultation sans connexion\",\n",
        "        \"Intégration dans équipements médicaux portables\"\n",
        "    ]\n",
        "elif total_memory < 500:\n",
        "    deployment_tier = \"SERVEUR LOCAL\"\n",
        "    recommendations = [\n",
        "        \"Déploiement sur serveur hospitalier\",\n",
        "        \"Intégration PACS locale\",\n",
        "        \"Traitement en temps réel des examens\"\n",
        "    ]\n",
        "else:\n",
        "    deployment_tier = \"CLOUD/GPU\"\n",
        "    recommendations = [\n",
        "        \"Déploiement cloud nécessaire\",\n",
        "        \"Utilisation GPU recommandée\",\n",
        "        \"Traitement par lots optimisé\"\n",
        "    ]\n",
        "\n",
        "print(f\"Niveau de déploiement recommandé: {deployment_tier}\")\n",
        "print(\"Recommandations:\")\n",
        "for rec in recommendations:\n",
        "    print(f\"  • {rec}\")\n",
        "\n",
        "# Estimation du débit\n",
        "images_per_second = 1000 / (memory_stats['total_memory_mb'] / 10)  # Estimation simplifiée\n",
        "print(f\"\\nDébit estimé: {images_per_second:.0f} images/seconde\")\n",
        "print(f\"Capacité journalière estimée: {images_per_second * 3600 * 8:.0f} images/jour (8h)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Résumé et Applications Pratiques\n",
        "\n",
        "### Compétences Acquises\n",
        "\n",
        "Dans ce notebook, vous avez appris à:\n",
        "\n",
        "1. **Manipuler des données médicales** avec les tenseurs PyTorch\n",
        "   - Calculs vectorisés sur cohortes de patients\n",
        "   - Analyses statistiques et corrélations cliniques\n",
        "   - Traitement par lots d'images médicales\n",
        "\n",
        "2. **Intégrer des modèles HuggingFace** pour le médical\n",
        "   - Chargement de modèles français pré-entraînés\n",
        "   - Tokenisation et embeddings de textes médicaux\n",
        "   - Analyse de similarité sémantique\n",
        "\n",
        "3. **Effectuer l'inférence** avec modèles pré-entraînés\n",
        "   - Classification automatique d'images médicales\n",
        "   - Interprétation des probabilités et confiance\n",
        "   - Génération de rapports automatisés\n",
        "\n",
        "4. **Optimiser pour le déploiement** clinique\n",
        "   - TorchScript pour accélération\n",
        "   - Analyse d'utilisation mémoire\n",
        "   - Recommandations de déploiement\n",
        "\n",
        "### Applications Cliniques Directes\n",
        "\n",
        "Ces compétences PyTorch vous permettront de:\n",
        "- **Intégrer des modèles IA** dans vos workflows médicaux\n",
        "- **Analyser des cohortes** de patients efficacement\n",
        "- **Traiter des images médicales** par lots\n",
        "- **Déployer des solutions** dans votre environnement clinique\n",
        "\n",
        "### Prochaine Étape\n",
        "\n",
        "Le prochain notebook vous enseignera la **classification de textes médicaux en français** avec des modèles spécialisés, en utilisant les bases PyTorch que vous venez d'acquérir."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}