{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/maclandrol/cours-ia-med/blob/master/09_AI_Model_Selection_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "instructor-info"
   },
   "source": [
    "**Enseignant:** Emmanuel Noutahi, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title-section"
   },
   "source": [
    "# Tutorial 9: AI Model Selection Framework\n",
    "\n",
    "## Medical Context\n",
    "\n",
    "### For Medical Students\n",
    "Understanding how to select appropriate AI models is crucial for:\n",
    "- **Research projects**: Choosing the right model for your study objectives\n",
    "- **Clinical applications**: Understanding which AI tools work best for specific tasks\n",
    "- **Evidence-based practice**: Making informed decisions about AI implementation\n",
    "- **Future practice**: Preparing for AI-assisted medical decision making\n",
    "\n",
    "### For Practitioners\n",
    "- **Radiologists**: Selecting AI tools for different imaging modalities and pathologies\n",
    "- **Clinicians**: Understanding AI model capabilities and limitations\n",
    "- **Medical informaticists**: Implementing appropriate AI solutions in clinical workflows\n",
    "- **Researchers**: Designing studies with optimal AI model selection\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "1. **Evaluate** different AI models systematically\n",
    "2. **Compare** model performance across multiple metrics\n",
    "3. **Select** the most appropriate model for specific clinical scenarios\n",
    "4. **Understand** trade-offs between different AI approaches\n",
    "5. **Apply** decision frameworks for model selection\n",
    "6. **Interpret** model performance in clinical context\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This tutorial integrates concepts from **Tutorials 1-8**. You should be familiar with:\n",
    "- Basic AI model concepts\n",
    "- Performance metrics and evaluation\n",
    "- Different types of medical AI tasks\n",
    "- Model interpretation and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-libraries"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install torchxrayvision\n",
    "!pip install torch torchvision\n",
    "!pip install transformers\n",
    "!pip install matplotlib seaborn\n",
    "!pip install numpy pandas\n",
    "!pip install scikit-learn scikit-image\n",
    "!pip install plotly\n",
    "!pip install opencv-python\n",
    "\n",
    "print(\"Installation completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchxrayvision as xrv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display configuration\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"Libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TorchXRayVision version: {xrv.__version__}\")\n",
    "\n",
    "# GPU check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device used: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-catalog"
   },
   "source": [
    "## Medical AI Model Catalog\n",
    "\n",
    "Let's create a comprehensive catalog of available medical AI models with their specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-model-catalog"
   },
   "outputs": [],
   "source": [
    "class MedicalAIModelCatalog:\n",
    "    \"\"\"\n",
    "    Comprehensive catalog of medical AI models with specifications and performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self._initialize_xray_models()\n",
    "        self._initialize_text_models()\n",
    "        self._initialize_segmentation_models()\n",
    "    \n",
    "    def _initialize_xray_models(self):\n",
    "        \"\"\"Initialize chest X-ray models\"\"\"\n",
    "        self.models['chest_xray'] = {\n",
    "            'densenet_all': {\n",
    "                'name': 'DenseNet121-All',\n",
    "                'type': 'multi-label_classification',\n",
    "                'modality': 'chest_xray',\n",
    "                'input_size': (224, 224),\n",
    "                'pathologies': ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', \n",
    "                              'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', \n",
    "                              'Pleural_Thickening', 'Cardiomegaly', 'Nodule', 'Mass', \n",
    "                              'Hernia', 'Lung Lesion', 'Fracture', 'Lung Opacity', \n",
    "                              'Enlarged Cardiomediastinum'],\n",
    "                'training_data': 'Multiple datasets (CheXpert, MIMIC-CXR, NIH, etc.)',\n",
    "                'performance': {'avg_auc': 0.85, 'inference_time': '50ms'},\n",
    "                'strengths': ['Comprehensive pathology coverage', 'Robust across datasets'],\n",
    "                'limitations': ['General purpose', 'Not specialized for specific conditions'],\n",
    "                'use_cases': ['General screening', 'Multi-pathology detection', 'Research'],\n",
    "                'clinical_context': 'Emergency departments, general radiology'\n",
    "            },\n",
    "            'densenet_chexpert': {\n",
    "                'name': 'DenseNet121-CheXpert',\n",
    "                'type': 'multi-label_classification',\n",
    "                'modality': 'chest_xray',\n",
    "                'input_size': (224, 224),\n",
    "                'pathologies': ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', \n",
    "                              'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n",
    "                              'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Pleural_Thickening'],\n",
    "                'training_data': 'CheXpert dataset (Stanford)',\n",
    "                'performance': {'avg_auc': 0.87, 'inference_time': '45ms'},\n",
    "                'strengths': ['High accuracy on CheXpert pathologies', 'Well-validated'],\n",
    "                'limitations': ['Limited to CheXpert label set', 'May not generalize to other datasets'],\n",
    "                'use_cases': ['Academic research', 'CheXpert-compatible studies'],\n",
    "                'clinical_context': 'Academic medical centers, research studies'\n",
    "            },\n",
    "            'densenet_nih': {\n",
    "                'name': 'DenseNet121-NIH',\n",
    "                'type': 'multi-label_classification',\n",
    "                'modality': 'chest_xray',\n",
    "                'input_size': (224, 224),\n",
    "                'pathologies': ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
    "                              'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation',\n",
    "                              'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'],\n",
    "                'training_data': 'NIH ChestX-ray14 dataset',\n",
    "                'performance': {'avg_auc': 0.83, 'inference_time': '40ms'},\n",
    "                'strengths': ['Good generalization', 'Established baseline'],\n",
    "                'limitations': ['Older training data', 'Lower performance on some pathologies'],\n",
    "                'use_cases': ['Baseline comparisons', 'Historical data analysis'],\n",
    "                'clinical_context': 'General radiology departments'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _initialize_text_models(self):\n",
    "        \"\"\"Initialize medical text models\"\"\"\n",
    "        self.models['medical_text'] = {\n",
    "            'camembert_medical': {\n",
    "                'name': 'CamemBERT-Medical',\n",
    "                'type': 'classification',\n",
    "                'modality': 'french_text',\n",
    "                'input_size': 512,  # token limit\n",
    "                'pathologies': 'Medical QA and classification tasks',\n",
    "                'training_data': 'French medical texts, FrenchMedMCQA',\n",
    "                'performance': {'accuracy': 0.78, 'f1_score': 0.76},\n",
    "                'strengths': ['French medical language', 'Question answering'],\n",
    "                'limitations': ['French only', 'Requires fine-tuning'],\n",
    "                'use_cases': ['Medical QA', 'Clinical decision support', 'Medical education'],\n",
    "                'clinical_context': 'French-speaking medical environments'\n",
    "            },\n",
    "            'flaubert_medical': {\n",
    "                'name': 'FlauBERT-Medical',\n",
    "                'type': 'classification',\n",
    "                'modality': 'french_text',\n",
    "                'input_size': 512,\n",
    "                'pathologies': 'Medical text classification',\n",
    "                'training_data': 'French medical literature',\n",
    "                'performance': {'accuracy': 0.75, 'f1_score': 0.73},\n",
    "                'strengths': ['French medical vocabulary', 'Lightweight'],\n",
    "                'limitations': ['Smaller model capacity', 'Limited performance'],\n",
    "                'use_cases': ['Text classification', 'Medical document analysis'],\n",
    "                'clinical_context': 'Clinical documentation, medical records'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _initialize_segmentation_models(self):\n",
    "        \"\"\"Initialize medical segmentation models\"\"\"\n",
    "        self.models['segmentation'] = {\n",
    "            'medsam': {\n",
    "                'name': 'MedSAM',\n",
    "                'type': 'interactive_segmentation',\n",
    "                'modality': 'medical_images',\n",
    "                'input_size': (1024, 1024),\n",
    "                'pathologies': 'Any anatomical structure with user guidance',\n",
    "                'training_data': 'Large-scale medical imaging dataset',\n",
    "                'performance': {'dice_score': 0.85, 'inference_time': '200ms'},\n",
    "                'strengths': ['Interactive prompting', 'General purpose', 'High accuracy'],\n",
    "                'limitations': ['Requires user interaction', 'Large model size'],\n",
    "                'use_cases': ['Interactive segmentation', 'Research annotation', 'Teaching'],\n",
    "                'clinical_context': 'Radiology workstations, research environments'\n",
    "            },\n",
    "            'nnunet': {\n",
    "                'name': 'nnU-Net',\n",
    "                'type': 'automatic_segmentation',\n",
    "                'modality': 'medical_images',\n",
    "                'input_size': 'Variable',\n",
    "                'pathologies': 'Task-specific (requires training)',\n",
    "                'training_data': 'Task-specific datasets',\n",
    "                'performance': {'dice_score': 0.90, 'inference_time': '500ms'},\n",
    "                'strengths': ['State-of-the-art performance', 'Automatic configuration'],\n",
    "                'limitations': ['Requires training per task', 'Complex setup'],\n",
    "                'use_cases': ['Clinical segmentation', 'Research studies', 'Treatment planning'],\n",
    "                'clinical_context': 'Specialized imaging centers, research institutions'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_models_by_modality(self, modality):\n",
    "        \"\"\"Get all models for a specific modality\"\"\"\n",
    "        return self.models.get(modality, {})\n",
    "    \n",
    "    def get_model_info(self, modality, model_name):\n",
    "        \"\"\"Get detailed information about a specific model\"\"\"\n",
    "        return self.models.get(modality, {}).get(model_name, None)\n",
    "    \n",
    "    def compare_models(self, modality, metric='performance'):\n",
    "        \"\"\"Compare models within a modality\"\"\"\n",
    "        models = self.get_models_by_modality(modality)\n",
    "        comparison = {}\n",
    "        \n",
    "        for model_name, model_info in models.items():\n",
    "            comparison[model_name] = {\n",
    "                'name': model_info['name'],\n",
    "                'performance': model_info['performance'],\n",
    "                'strengths': len(model_info['strengths']),\n",
    "                'limitations': len(model_info['limitations']),\n",
    "                'use_cases': len(model_info['use_cases'])\n",
    "            }\n",
    "        \n",
    "        return comparison\n",
    "\n",
    "# Initialize the catalog\n",
    "model_catalog = MedicalAIModelCatalog()\n",
    "\n",
    "print(\"Medical AI Model Catalog initialized\")\n",
    "print(f\"Available modalities: {list(model_catalog.models.keys())}\")\n",
    "print(f\"Total models: {sum(len(models) for models in model_catalog.models.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-comparison"
   },
   "source": [
    "## Interactive Model Comparison Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-comparison-dashboard"
   },
   "outputs": [],
   "source": [
    "def create_model_comparison_dashboard(catalog):\n",
    "    \"\"\"\n",
    "    Create interactive dashboard for comparing medical AI models\n",
    "    \"\"\"\n",
    "    print(\"MEDICAL AI MODEL COMPARISON DASHBOARD\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Chest X-ray Models Comparison\n",
    "    print(\"\\n1. CHEST X-RAY MODELS COMPARISON\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    xray_models = catalog.get_models_by_modality('chest_xray')\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_data = []\n",
    "    for model_key, model_info in xray_models.items():\n",
    "        comparison_data.append({\n",
    "            'Model': model_info['name'],\n",
    "            'Pathologies': len(model_info['pathologies']),\n",
    "            'Avg AUC': model_info['performance']['avg_auc'],\n",
    "            'Inference Time': model_info['performance']['inference_time'],\n",
    "            'Training Data': model_info['training_data'][:30] + '...' if len(model_info['training_data']) > 30 else model_info['training_data'],\n",
    "            'Primary Use': model_info['use_cases'][0] if model_info['use_cases'] else 'N/A'\n",
    "        })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    print(df_comparison.to_string(index=False))\n",
    "    \n",
    "    # Visualization: Performance vs Pathology Coverage\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Performance comparison\n",
    "    models_names = [info['name'] for info in xray_models.values()]\n",
    "    aucs = [info['performance']['avg_auc'] for info in xray_models.values()]\n",
    "    pathology_counts = [len(info['pathologies']) for info in xray_models.values()]\n",
    "    \n",
    "    axes[0, 0].bar(models_names, aucs, alpha=0.7, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "    axes[0, 0].set_title('Model Performance (Average AUC)')\n",
    "    axes[0, 0].set_ylabel('AUC Score')\n",
    "    axes[0, 0].set_ylim(0.8, 0.9)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Pathology coverage\n",
    "    axes[0, 1].bar(models_names, pathology_counts, alpha=0.7, color=['orange', 'purple', 'brown'])\n",
    "    axes[0, 1].set_title('Pathology Coverage')\n",
    "    axes[0, 1].set_ylabel('Number of Pathologies')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Performance vs Coverage scatter\n",
    "    axes[1, 0].scatter(pathology_counts, aucs, s=200, alpha=0.7, c=['red', 'blue', 'green'])\n",
    "    for i, name in enumerate(models_names):\n",
    "        axes[1, 0].annotate(name.split('-')[0], (pathology_counts[i], aucs[i]), \n",
    "                          xytext=(5, 5), textcoords='offset points')\n",
    "    axes[1, 0].set_xlabel('Number of Pathologies')\n",
    "    axes[1, 0].set_ylabel('Average AUC')\n",
    "    axes[1, 0].set_title('Performance vs Pathology Coverage')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Strengths and limitations radar\n",
    "    strengths_counts = [len(info['strengths']) for info in xray_models.values()]\n",
    "    limitations_counts = [len(info['limitations']) for info in xray_models.values()]\n",
    "    \n",
    "    x = np.arange(len(models_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 1].bar(x - width/2, strengths_counts, width, label='Strengths', alpha=0.7, color='green')\n",
    "    axes[1, 1].bar(x + width/2, limitations_counts, width, label='Limitations', alpha=0.7, color='red')\n",
    "    axes[1, 1].set_xlabel('Models')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('Strengths vs Limitations')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels([name.split('-')[0] for name in models_names], rotation=45)\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Chest X-ray Models Comprehensive Comparison', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Detailed Model Profiles\n",
    "    print(\"\\n\\n2. DETAILED MODEL PROFILES\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for model_key, model_info in xray_models.items():\n",
    "        print(f\"\\n** {model_info['name']} **\")\n",
    "        print(f\"   Type: {model_info['type']}\")\n",
    "        print(f\"   Training Data: {model_info['training_data']}\")\n",
    "        print(f\"   Performance: {model_info['performance']}\")\n",
    "        print(f\"   Strengths: {', '.join(model_info['strengths'])}\")\n",
    "        print(f\"   Limitations: {', '.join(model_info['limitations'])}\")\n",
    "        print(f\"   Best Use Cases: {', '.join(model_info['use_cases'])}\")\n",
    "        print(f\"   Clinical Context: {model_info['clinical_context']}\")\n",
    "        print(f\"   Pathologies Covered ({len(model_info['pathologies'])}): {', '.join(model_info['pathologies'][:5])}{'...' if len(model_info['pathologies']) > 5 else ''}\")\n",
    "\n",
    "# Create the comparison dashboard\n",
    "create_model_comparison_dashboard(model_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "selection-framework"
   },
   "source": [
    "## AI Model Selection Decision Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-selection-framework"
   },
   "outputs": [],
   "source": [
    "class AIModelSelectionFramework:\n",
    "    \"\"\"\n",
    "    Systematic framework for selecting appropriate medical AI models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, catalog):\n",
    "        self.catalog = catalog\n",
    "        self.selection_criteria = {\n",
    "            'performance_priority': 'high',\n",
    "            'speed_priority': 'medium',\n",
    "            'interpretability_priority': 'medium',\n",
    "            'generalizability_priority': 'high',\n",
    "            'resource_constraints': 'medium'\n",
    "        }\n",
    "    \n",
    "    def clinical_scenario_selector(self):\n",
    "        \"\"\"\n",
    "        Interactive selector based on clinical scenarios\n",
    "        \"\"\"\n",
    "        print(\"AI MODEL SELECTION FRAMEWORK\")\n",
    "        print(\"=\" * 40)\n",
    "        print(\"Answer the following questions to get personalized model recommendations:\\n\")\n",
    "        \n",
    "        # Question 1: Clinical Setting\n",
    "        print(\"1. What is your clinical setting?\")\n",
    "        print(\"   a) Emergency Department\")\n",
    "        print(\"   b) Radiology Department\")\n",
    "        print(\"   c) Research Institution\")\n",
    "        print(\"   d) Primary Care Clinic\")\n",
    "        print(\"   e) Specialized Medical Center\")\n",
    "        \n",
    "        setting = input(\"\\nYour choice (a-e): \").lower().strip()\n",
    "        \n",
    "        # Question 2: Primary Task\n",
    "        print(\"\\n2. What is your primary task?\")\n",
    "        print(\"   a) General screening for multiple pathologies\")\n",
    "        print(\"   b) Specific pathology detection\")\n",
    "        print(\"   c) Research and validation studies\")\n",
    "        print(\"   d) Medical education and training\")\n",
    "        print(\"   e) Clinical decision support\")\n",
    "        \n",
    "        task = input(\"\\nYour choice (a-e): \").lower().strip()\n",
    "        \n",
    "        # Question 3: Performance Requirements\n",
    "        print(\"\\n3. What is most important for your use case?\")\n",
    "        print(\"   a) Highest possible accuracy\")\n",
    "        print(\"   b) Fast inference speed\")\n",
    "        print(\"   c) Broad pathology coverage\")\n",
    "        print(\"   d) Established validation\")\n",
    "        print(\"   e) Research reproducibility\")\n",
    "        \n",
    "        priority = input(\"\\nYour choice (a-e): \").lower().strip()\n",
    "        \n",
    "        # Question 4: Resource Constraints\n",
    "        print(\"\\n4. What are your computational resources?\")\n",
    "        print(\"   a) High-end GPU workstation\")\n",
    "        print(\"   b) Standard laptop/desktop\")\n",
    "        print(\"   c) Cloud computing\")\n",
    "        print(\"   d) Mobile/edge device\")\n",
    "        print(\"   e) Server cluster\")\n",
    "        \n",
    "        resources = input(\"\\nYour choice (a-e): \").lower().strip()\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = self._generate_recommendations(setting, task, priority, resources)\n",
    "        self._display_recommendations(recommendations, setting, task, priority, resources)\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _generate_recommendations(self, setting, task, priority, resources):\n",
    "        \"\"\"\n",
    "        Generate model recommendations based on user inputs\n",
    "        \"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # Decision logic for chest X-ray models\n",
    "        xray_models = self.catalog.get_models_by_modality('chest_xray')\n",
    "        \n",
    "        # Emergency Department: Fast, comprehensive screening\n",
    "        if setting == 'a':\n",
    "            if task in ['a', 'e']:  # General screening or clinical support\n",
    "                if priority == 'b':  # Speed priority\n",
    "                    recommendations.append({\n",
    "                        'model': 'densenet_nih',\n",
    "                        'score': 0.85,\n",
    "                        'reasoning': 'Fast inference for emergency screening'\n",
    "                    })\n",
    "                else:\n",
    "                    recommendations.append({\n",
    "                        'model': 'densenet_all',\n",
    "                        'score': 0.90,\n",
    "                        'reasoning': 'Comprehensive pathology coverage for emergency triage'\n",
    "                    })\n",
    "        \n",
    "        # Radiology Department: High accuracy, established validation\n",
    "        elif setting == 'b':\n",
    "            if priority == 'a':  # Accuracy priority\n",
    "                recommendations.append({\n",
    "                    'model': 'densenet_chexpert',\n",
    "                    'score': 0.95,\n",
    "                    'reasoning': 'Highest accuracy for radiological interpretation'\n",
    "                })\n",
    "            else:\n",
    "                recommendations.append({\n",
    "                    'model': 'densenet_all',\n",
    "                    'score': 0.88,\n",
    "                    'reasoning': 'Balanced performance and coverage for routine radiology'\n",
    "                })\n",
    "        \n",
    "        # Research Institution: Reproducibility and validation\n",
    "        elif setting == 'c':\n",
    "            if task == 'c':  # Research and validation\n",
    "                recommendations.extend([\n",
    "                    {\n",
    "                        'model': 'densenet_chexpert',\n",
    "                        'score': 0.92,\n",
    "                        'reasoning': 'Well-validated for research reproducibility'\n",
    "                    },\n",
    "                    {\n",
    "                        'model': 'densenet_all',\n",
    "                        'score': 0.85,\n",
    "                        'reasoning': 'Broad coverage for comparative studies'\n",
    "                    }\n",
    "                ])\n",
    "            else:\n",
    "                recommendations.append({\n",
    "                    'model': 'densenet_all',\n",
    "                    'score': 0.87,\n",
    "                    'reasoning': 'Versatile for various research applications'\n",
    "                })\n",
    "        \n",
    "        # Primary Care: Simple, reliable screening\n",
    "        elif setting == 'd':\n",
    "            recommendations.append({\n",
    "                'model': 'densenet_all',\n",
    "                'score': 0.83,\n",
    "                'reasoning': 'General screening appropriate for primary care'\n",
    "            })\n",
    "        \n",
    "        # Specialized Center: Task-specific optimization\n",
    "        elif setting == 'e':\n",
    "            if task == 'b':  # Specific pathology\n",
    "                recommendations.append({\n",
    "                    'model': 'densenet_chexpert',\n",
    "                    'score': 0.88,\n",
    "                    'reasoning': 'Specialized performance for specific pathologies'\n",
    "                })\n",
    "            else:\n",
    "                recommendations.append({\n",
    "                    'model': 'densenet_all',\n",
    "                    'score': 0.86,\n",
    "                    'reasoning': 'Comprehensive coverage for specialized practice'\n",
    "                })\n",
    "        \n",
    "        # Sort by score\n",
    "        recommendations.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        return recommendations[:3]  # Top 3 recommendations\n",
    "    \n",
    "    def _display_recommendations(self, recommendations, setting, task, priority, resources):\n",
    "        \"\"\"\n",
    "        Display personalized recommendations\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"PERSONALIZED MODEL RECOMMENDATIONS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Display user context\n",
    "        settings_map = {'a': 'Emergency Department', 'b': 'Radiology Department', 'c': 'Research Institution',\n",
    "                       'd': 'Primary Care Clinic', 'e': 'Specialized Medical Center'}\n",
    "        tasks_map = {'a': 'General screening', 'b': 'Specific pathology detection', 'c': 'Research studies',\n",
    "                    'd': 'Medical education', 'e': 'Clinical decision support'}\n",
    "        priorities_map = {'a': 'Highest accuracy', 'b': 'Fast inference', 'c': 'Broad coverage',\n",
    "                         'd': 'Established validation', 'e': 'Research reproducibility'}\n",
    "        \n",
    "        print(f\"\\nYour Profile:\")\n",
    "        print(f\"   Clinical Setting: {settings_map.get(setting, 'Unknown')}\")\n",
    "        print(f\"   Primary Task: {tasks_map.get(task, 'Unknown')}\")\n",
    "        print(f\"   Priority: {priorities_map.get(priority, 'Unknown')}\")\n",
    "        \n",
    "        print(f\"\\nTop Recommendations:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            model_info = None\n",
    "            for model_key, info in self.catalog.get_models_by_modality('chest_xray').items():\n",
    "                if model_key == rec['model']:\n",
    "                    model_info = info\n",
    "                    break\n",
    "            \n",
    "            if model_info:\n",
    "                print(f\"\\n{i}. {model_info['name']} (Score: {rec['score']:.2f})\")\n",
    "                print(f\"   Reasoning: {rec['reasoning']}\")\n",
    "                print(f\"   Performance: AUC {model_info['performance']['avg_auc']}, {model_info['performance']['inference_time']}\")\n",
    "                print(f\"   Pathologies: {len(model_info['pathologies'])} covered\")\n",
    "                print(f\"   Best for: {', '.join(model_info['use_cases'][:2])}\")\n",
    "        \n",
    "        # Additional considerations\n",
    "        print(f\"\\n\\nAdditional Considerations:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        if resources in ['b', 'd']:  # Limited resources\n",
    "            print(\"• Consider model optimization for your hardware constraints\")\n",
    "            print(\"• Cloud deployment may be more suitable for complex models\")\n",
    "        \n",
    "        if setting in ['a', 'e']:  # Clinical settings\n",
    "            print(\"• Ensure model validation on your specific patient population\")\n",
    "            print(\"• Consider regulatory requirements for clinical deployment\")\n",
    "        \n",
    "        if task == 'c':  # Research\n",
    "            print(\"• Document model versions and parameters for reproducibility\")\n",
    "            print(\"• Consider multiple models for comparative analysis\")\n",
    "        \n",
    "        print(\"• Always validate AI results with clinical expertise\")\n",
    "        print(\"• Monitor model performance over time for distribution shifts\")\n",
    "\n",
    "# Create selection framework\n",
    "selection_framework = AIModelSelectionFramework(model_catalog)\n",
    "\n",
    "print(\"AI Model Selection Framework ready\")\n",
    "print(\"Run the interactive selector to get personalized recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive-selector"
   },
   "source": [
    "## Interactive Model Selector\n",
    "\n",
    "Run the following cell to get personalized AI model recommendations based on your specific clinical scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-interactive-selector"
   },
   "outputs": [],
   "source": [
    "# Run the interactive model selector\n",
    "recommendations = selection_framework.clinical_scenario_selector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "performance-analysis"
   },
   "source": [
    "## Model Performance Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "performance-analysis-code"
   },
   "outputs": [],
   "source": [
    "def create_performance_analysis():\n",
    "    \"\"\"\n",
    "    Create detailed performance analysis and comparison\n",
    "    \"\"\"\n",
    "    print(\"MODEL PERFORMANCE DEEP DIVE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Simulated performance data for demonstration\n",
    "    # In practice, this would come from actual model evaluations\n",
    "    \n",
    "    # Performance metrics for different pathologies\n",
    "    performance_data = {\n",
    "        'Pathology': ['Pneumonia', 'Cardiomegaly', 'Pneumothorax', 'Atelectasis', 'Effusion', \n",
    "                     'Infiltration', 'Mass', 'Nodule', 'Consolidation', 'Edema'],\n",
    "        'DenseNet-All': [0.87, 0.89, 0.92, 0.84, 0.91, 0.78, 0.82, 0.80, 0.85, 0.88],\n",
    "        'DenseNet-CheXpert': [0.91, 0.92, 0.94, 0.86, 0.93, 0.81, 0.85, 0.83, 0.88, 0.90],\n",
    "        'DenseNet-NIH': [0.84, 0.86, 0.89, 0.81, 0.88, 0.75, 0.79, 0.77, 0.82, 0.85],\n",
    "        'Clinical_Priority': ['High', 'High', 'Critical', 'Medium', 'High', \n",
    "                             'Medium', 'Critical', 'High', 'High', 'Critical']\n",
    "    }\n",
    "    \n",
    "    df_perf = pd.DataFrame(performance_data)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "    \n",
    "    # 1. AUC comparison heatmap\n",
    "    model_cols = ['DenseNet-All', 'DenseNet-CheXpert', 'DenseNet-NIH']\n",
    "    perf_matrix = df_perf[model_cols].T\n",
    "    perf_matrix.columns = df_perf['Pathology']\n",
    "    \n",
    "    sns.heatmap(perf_matrix, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "                vmin=0.75, vmax=0.95, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Model Performance by Pathology (AUC)', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Pathologies')\n",
    "    axes[0, 0].set_ylabel('Models')\n",
    "    plt.setp(axes[0, 0].get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # 2. Performance distribution\n",
    "    for i, model in enumerate(model_cols):\n",
    "        axes[0, 1].hist(df_perf[model], alpha=0.6, label=model.split('-')[1], \n",
    "                       bins=10, color=['blue', 'red', 'green'][i])\n",
    "    \n",
    "    axes[0, 1].set_xlabel('AUC Score')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Performance Distribution Across Pathologies')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Performance by clinical priority\n",
    "    priority_performance = df_perf.groupby('Clinical_Priority')[model_cols].mean()\n",
    "    \n",
    "    x = np.arange(len(priority_performance.index))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, model in enumerate(model_cols):\n",
    "        axes[1, 0].bar(x + i*width, priority_performance[model], width, \n",
    "                      label=model.split('-')[1], alpha=0.8)\n",
    "    \n",
    "    axes[1, 0].set_xlabel('Clinical Priority')\n",
    "    axes[1, 0].set_ylabel('Average AUC')\n",
    "    axes[1, 0].set_title('Performance by Clinical Priority Level')\n",
    "    axes[1, 0].set_xticks(x + width)\n",
    "    axes[1, 0].set_xticklabels(priority_performance.index)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Model ranking by pathology\n",
    "    pathologies = df_perf['Pathology'][:6]  # Top 6 for visibility\n",
    "    rankings = []\n",
    "    \n",
    "    for path in pathologies:\n",
    "        path_data = df_perf[df_perf['Pathology'] == path][model_cols].iloc[0]\n",
    "        ranked = path_data.sort_values(ascending=False)\n",
    "        rankings.append([ranked.index[0].split('-')[1], ranked.index[1].split('-')[1], ranked.index[2].split('-')[1]])\n",
    "    \n",
    "    # Create ranking visualization\n",
    "    ranking_df = pd.DataFrame(rankings, columns=['1st', '2nd', '3rd'], index=pathologies)\n",
    "    \n",
    "    # Color map for rankings\n",
    "    color_map = {'All': 'gold', 'CheXpert': 'silver', 'NIH': 'bronze'}\n",
    "    colors = [[color_map.get(model, 'gray') for model in row] for row in rankings]\n",
    "    \n",
    "    # Create table\n",
    "    table_data = []\n",
    "    for i, path in enumerate(pathologies):\n",
    "        row_data = df_perf[df_perf['Pathology'] == path][model_cols].iloc[0]\n",
    "        best_model = row_data.idxmax().split('-')[1]\n",
    "        best_score = row_data.max()\n",
    "        table_data.append([path, best_model, f'{best_score:.3f}'])\n",
    "    \n",
    "    axes[1, 1].axis('tight')\n",
    "    axes[1, 1].axis('off')\n",
    "    table = axes[1, 1].table(cellText=table_data,\n",
    "                            colLabels=['Pathology', 'Best Model', 'AUC'],\n",
    "                            cellLoc='center',\n",
    "                            loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.5)\n",
    "    axes[1, 1].set_title('Best Performing Model by Pathology')\n",
    "    \n",
    "    plt.suptitle('Comprehensive Model Performance Analysis', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance summary\n",
    "    print(\"\\nPERFORMance SUMMARY\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for model in model_cols:\n",
    "        avg_score = df_perf[model].mean()\n",
    "        std_score = df_perf[model].std()\n",
    "        best_pathologies = df_perf.nlargest(3, model)['Pathology'].tolist()\n",
    "        \n",
    "        print(f\"\\n{model}:\")\n",
    "        print(f\"   Average AUC: {avg_score:.3f} ± {std_score:.3f}\")\n",
    "        print(f\"   Best performance: {', '.join(best_pathologies)}\")\n",
    "        print(f\"   Consistency: {'High' if std_score < 0.05 else 'Medium' if std_score < 0.08 else 'Variable'}\")\n",
    "    \n",
    "    return df_perf\n",
    "\n",
    "# Run performance analysis\n",
    "performance_results = create_performance_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "decision-tree"
   },
   "source": [
    "## Clinical Decision Tree for Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-decision-tree"
   },
   "outputs": [],
   "source": [
    "def create_clinical_decision_tree():\n",
    "    \"\"\"\n",
    "    Create a visual decision tree for clinical model selection\n",
    "    \"\"\"\n",
    "    print(\"CLINICAL AI MODEL SELECTION DECISION TREE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create decision tree visualization\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 12))\n",
    "    \n",
    "    # Define decision tree structure\n",
    "    decision_tree = {\n",
    "        'root': {'text': 'Medical AI Model Selection', 'pos': (0.5, 0.9), 'color': 'lightblue'},\n",
    "        'imaging': {'text': 'Medical Imaging Task?', 'pos': (0.3, 0.75), 'color': 'lightgreen'},\n",
    "        'text': {'text': 'Text Analysis Task?', 'pos': (0.7, 0.75), 'color': 'lightgreen'},\n",
    "        \n",
    "        # Imaging branch\n",
    "        'chest_xray': {'text': 'Chest X-ray Analysis', 'pos': (0.15, 0.6), 'color': 'lightyellow'},\n",
    "        'segmentation': {'text': 'Image Segmentation', 'pos': (0.45, 0.6), 'color': 'lightyellow'},\n",
    "        \n",
    "        # Text branch\n",
    "        'french_text': {'text': 'French Medical Text', 'pos': (0.6, 0.6), 'color': 'lightyellow'},\n",
    "        'english_text': {'text': 'English Medical Text', 'pos': (0.8, 0.6), 'color': 'lightyellow'},\n",
    "        \n",
    "        # Chest X-ray subbranches\n",
    "        'emergency': {'text': 'Emergency/Fast\\nDenseNet-All', 'pos': (0.05, 0.45), 'color': 'lightcoral'},\n",
    "        'accuracy': {'text': 'Accuracy Priority\\nDenseNet-CheXpert', 'pos': (0.15, 0.45), 'color': 'lightcoral'},\n",
    "        'research': {'text': 'Research/Baseline\\nDenseNet-NIH', 'pos': (0.25, 0.45), 'color': 'lightcoral'},\n",
    "        \n",
    "        # Segmentation subbranches\n",
    "        'interactive': {'text': 'Interactive\\nMedSAM', 'pos': (0.38, 0.45), 'color': 'lightcoral'},\n",
    "        'automatic': {'text': 'Automatic\\nnnU-Net', 'pos': (0.52, 0.45), 'color': 'lightcoral'},\n",
    "        \n",
    "        # Text subbranches\n",
    "        'camembert': {'text': 'QA/Classification\\nCamemBERT', 'pos': (0.6, 0.45), 'color': 'lightcoral'},\n",
    "        'flaubert': {'text': 'Document Analysis\\nFlauBERT', 'pos': (0.75, 0.45), 'color': 'lightcoral'},\n",
    "        'prompt_eng': {'text': 'Prompting\\nChatGPT/Claude', 'pos': (0.9, 0.45), 'color': 'lightcoral'},\n",
    "    }\n",
    "    \n",
    "    # Define connections\n",
    "    connections = [\n",
    "        ('root', 'imaging'),\n",
    "        ('root', 'text'),\n",
    "        ('imaging', 'chest_xray'),\n",
    "        ('imaging', 'segmentation'),\n",
    "        ('text', 'french_text'),\n",
    "        ('text', 'english_text'),\n",
    "        ('chest_xray', 'emergency'),\n",
    "        ('chest_xray', 'accuracy'),\n",
    "        ('chest_xray', 'research'),\n",
    "        ('segmentation', 'interactive'),\n",
    "        ('segmentation', 'automatic'),\n",
    "        ('french_text', 'camembert'),\n",
    "        ('english_text', 'flaubert'),\n",
    "        ('english_text', 'prompt_eng'),\n",
    "    ]\n",
    "    \n",
    "    # Draw connections\n",
    "    for start, end in connections:\n",
    "        x1, y1 = decision_tree[start]['pos']\n",
    "        x2, y2 = decision_tree[end]['pos']\n",
    "        ax.plot([x1, x2], [y1, y2], 'k-', alpha=0.6, linewidth=1.5)\n",
    "    \n",
    "    # Draw nodes\n",
    "    for node, info in decision_tree.items():\n",
    "        x, y = info['pos']\n",
    "        \n",
    "        # Adjust box size based on text length\n",
    "        if len(info['text']) > 15:\n",
    "            bbox = dict(boxstyle=\"round,pad=0.3\", facecolor=info['color'], alpha=0.8)\n",
    "            fontsize = 9\n",
    "        else:\n",
    "            bbox = dict(boxstyle=\"round,pad=0.5\", facecolor=info['color'], alpha=0.8)\n",
    "            fontsize = 10\n",
    "        \n",
    "        ax.text(x, y, info['text'], ha='center', va='center', \n",
    "               fontsize=fontsize, fontweight='bold', bbox=bbox)\n",
    "    \n",
    "    # Add decision criteria as annotations\n",
    "    criteria_annotations = [\n",
    "        {'pos': (0.1, 0.3), 'text': 'Speed > Accuracy\\nTime Critical'},\n",
    "        {'pos': (0.25, 0.3), 'text': 'Research\\nReproducibility'},\n",
    "        {'pos': (0.4, 0.3), 'text': 'User Interaction\\nRequired'},\n",
    "        {'pos': (0.55, 0.3), 'text': 'Fully Automated\\nHigh Accuracy'},\n",
    "        {'pos': (0.7, 0.3), 'text': 'French Language\\nQA Tasks'},\n",
    "        {'pos': (0.85, 0.3), 'text': 'No Training\\nQuick Deployment'},\n",
    "    ]\n",
    "    \n",
    "    for annotation in criteria_annotations:\n",
    "        x, y = annotation['pos']\n",
    "        ax.text(x, y, annotation['text'], ha='center', va='center', \n",
    "               fontsize=8, style='italic', alpha=0.7,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.2\", facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0.2, 1)\n",
    "    ax.set_title('Clinical AI Model Selection Decision Tree', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightblue', alpha=0.8, label='Start Point'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightgreen', alpha=0.8, label='Task Category'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightyellow', alpha=0.8, label='Specific Task'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightcoral', alpha=0.8, label='Model Recommendation')\n",
    "    ]\n",
    "    \n",
    "    ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.98))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print textual decision guide\n",
    "    print(\"\\nTEXTUAL DECISION GUIDE\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    decision_guide = {\n",
    "        \"Medical Imaging Tasks\": {\n",
    "            \"Chest X-ray Analysis\": {\n",
    "                \"Emergency/Time-Critical\": \"Use DenseNet-All (fast, comprehensive)\",\n",
    "                \"Accuracy Priority\": \"Use DenseNet-CheXpert (highest performance)\",\n",
    "                \"Research/Baseline\": \"Use DenseNet-NIH (established, reproducible)\"\n",
    "            },\n",
    "            \"Image Segmentation\": {\n",
    "                \"Interactive/Teaching\": \"Use MedSAM (user-guided, flexible)\",\n",
    "                \"Automatic/Clinical\": \"Use nnU-Net (state-of-the-art, automated)\"\n",
    "            }\n",
    "        },\n",
    "        \"Text Analysis Tasks\": {\n",
    "            \"French Medical Text\": {\n",
    "                \"Question Answering\": \"Use CamemBERT-Medical\",\n",
    "                \"Document Classification\": \"Use FlauBERT-Medical\"\n",
    "            },\n",
    "            \"Quick Deployment\": {\n",
    "                \"No Training Required\": \"Use Prompting (ChatGPT/Claude)\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for category, subcategories in decision_guide.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for subcat, options in subcategories.items():\n",
    "            print(f\"  {subcat}:\")\n",
    "            if isinstance(options, dict):\n",
    "                for scenario, recommendation in options.items():\n",
    "                    print(f\"    • {scenario}: {recommendation}\")\n",
    "            else:\n",
    "                print(f\"    • {options}\")\n",
    "\n",
    "# Create the decision tree\n",
    "create_clinical_decision_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "practical-examples"
   },
   "source": [
    "## Practical Clinical Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "practical-examples-code"
   },
   "outputs": [],
   "source": [
    "def create_practical_examples():\n",
    "    \"\"\"\n",
    "    Create practical clinical examples for model selection\n",
    "    \"\"\"\n",
    "    print(\"PRACTICAL CLINICAL EXAMPLES\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Define clinical scenarios\n",
    "    clinical_scenarios = [\n",
    "        {\n",
    "            'title': 'Emergency Department Triage',\n",
    "            'context': 'Busy urban emergency department with high patient volume',\n",
    "            'requirements': [\n",
    "                'Fast analysis (<100ms per image)',\n",
    "                'High sensitivity for critical conditions',\n",
    "                'Comprehensive pathology screening',\n",
    "                'Integration with existing PACS'\n",
    "            ],\n",
    "            'recommended_model': 'DenseNet121-All',\n",
    "            'reasoning': [\n",
    "                'Fastest inference time among high-performance models',\n",
    "                'Broad pathology coverage for comprehensive screening',\n",
    "                'Robust performance across different patient populations',\n",
    "                'Well-established for emergency applications'\n",
    "            ],\n",
    "            'implementation_tips': [\n",
    "                'Deploy on dedicated GPU hardware for consistent speed',\n",
    "                'Set conservative thresholds to maximize sensitivity',\n",
    "                'Implement automated flagging for critical findings',\n",
    "                'Regular calibration with local patient data'\n",
    "            ],\n",
    "            'expected_outcomes': [\n",
    "                '30% reduction in radiologist interpretation time',\n",
    "                'Improved detection of missed pneumothorax cases',\n",
    "                'Better triage prioritization for critical patients'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'title': 'Academic Radiology Research',\n",
    "            'context': 'University hospital conducting comparative AI research',\n",
    "            'requirements': [\n",
    "                'Highest possible accuracy',\n",
    "                'Reproducible results',\n",
    "                'Published validation data',\n",
    "                'Comparison with literature benchmarks'\n",
    "            ],\n",
    "            'recommended_model': 'DenseNet121-CheXpert',\n",
    "            'reasoning': [\n",
    "                'Highest average AUC across pathologies',\n",
    "                'Extensively validated on CheXpert dataset',\n",
    "                'Standard benchmark for research comparisons',\n",
    "                'Strong performance on academic evaluation metrics'\n",
    "            ],\n",
    "            'implementation_tips': [\n",
    "                'Use exact preprocessing as original validation studies',\n",
    "                'Document all hyperparameters and model versions',\n",
    "                'Perform statistical testing for significance',\n",
    "                'Cross-validate on multiple test sets'\n",
    "            ],\n",
    "            'expected_outcomes': [\n",
    "                'Publication-ready performance metrics',\n",
    "                'Reliable baseline for new algorithm development',\n",
    "                'Reproducible research results'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'title': 'Rural Health Clinic Screening',\n",
    "            'context': 'Remote clinic with limited radiology expertise',\n",
    "            'requirements': [\n",
    "                'Simple deployment and maintenance',\n",
    "                'High reliability with minimal oversight',\n",
    "                'Clear, interpretable outputs',\n",
    "                'Telemedicine integration'\n",
    "            ],\n",
    "            'recommended_model': 'DenseNet121-All',\n",
    "            'reasoning': [\n",
    "                'Robust performance across diverse populations',\n",
    "                'Comprehensive pathology detection',\n",
    "                'Established reliability in clinical settings',\n",
    "                'Good balance of sensitivity and specificity'\n",
    "            ],\n",
    "            'implementation_tips': [\n",
    "                'Use cloud-based deployment for easier maintenance',\n",
    "                'Implement clear confidence scoring',\n",
    "                'Provide structured reports for telemedicine',\n",
    "                'Regular quality monitoring and feedback'\n",
    "            ],\n",
    "            'expected_outcomes': [\n",
    "                'Earlier detection of serious conditions',\n",
    "                'Reduced need for patient transfers',\n",
    "                'Improved diagnostic confidence for general practitioners'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'title': 'Specialized Lung Cancer Center',\n",
    "            'context': 'Oncology center focusing on lung cancer detection and monitoring',\n",
    "            'requirements': [\n",
    "                'Excellent performance on lung nodules and masses',\n",
    "                'Integration with existing workflow',\n",
    "                'Detailed probability outputs',\n",
    "                'Support for follow-up tracking'\n",
    "            ],\n",
    "            'recommended_model': 'DenseNet121-CheXpert + Custom Fine-tuning',\n",
    "            'reasoning': [\n",
    "                'Strong baseline performance on nodule detection',\n",
    "                'Can be fine-tuned on institution-specific data',\n",
    "                'Detailed probability outputs for clinical decision-making',\n",
    "                'Proven performance in oncology applications'\n",
    "            ],\n",
    "            'implementation_tips': [\n",
    "                'Fine-tune on institutional lung cancer dataset',\n",
    "                'Implement longitudinal comparison features',\n",
    "                'Integrate with oncology information systems',\n",
    "                'Provide detailed region-of-interest highlighting'\n",
    "            ],\n",
    "            'expected_outcomes': [\n",
    "                'Improved early-stage lung cancer detection',\n",
    "                'More consistent nodule tracking over time',\n",
    "                'Enhanced radiologist confidence in screening'\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Display scenarios\n",
    "    for i, scenario in enumerate(clinical_scenarios, 1):\n",
    "        print(f\"\\n{i}. {scenario['title']}\")\n",
    "        print(\"=\" * (len(scenario['title']) + 4))\n",
    "        \n",
    "        print(f\"\\nContext: {scenario['context']}\")\n",
    "        \n",
    "        print(f\"\\nRequirements:\")\n",
    "        for req in scenario['requirements']:\n",
    "            print(f\"   • {req}\")\n",
    "        \n",
    "        print(f\"\\nRecommended Model: {scenario['recommended_model']}\")\n",
    "        \n",
    "        print(f\"\\nReasoning:\")\n",
    "        for reason in scenario['reasoning']:\n",
    "            print(f\"   • {reason}\")\n",
    "        \n",
    "        print(f\"\\nImplementation Tips:\")\n",
    "        for tip in scenario['implementation_tips']:\n",
    "            print(f\"   • {tip}\")\n",
    "        \n",
    "        print(f\"\\nExpected Outcomes:\")\n",
    "        for outcome in scenario['expected_outcomes']:\n",
    "            print(f\"   • {outcome}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Create comparison matrix\n",
    "    print(\"\\n\\nSCENARIO COMPARISON MATRIX\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    comparison_matrix = pd.DataFrame({\n",
    "        'Scenario': [s['title'] for s in clinical_scenarios],\n",
    "        'Model': [s['recommended_model'] for s in clinical_scenarios],\n",
    "        'Speed Priority': ['High', 'Low', 'Medium', 'Medium'],\n",
    "        'Accuracy Priority': ['Medium', 'High', 'Medium', 'High'],\n",
    "        'Deployment Complexity': ['Medium', 'High', 'Low', 'High'],\n",
    "        'Maintenance Needs': ['Medium', 'Low', 'Low', 'High']\n",
    "    })\n",
    "    \n",
    "    print(comparison_matrix.to_string(index=False))\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Priority heatmap\n",
    "    priority_data = comparison_matrix[['Speed Priority', 'Accuracy Priority', 'Deployment Complexity', 'Maintenance Needs']]\n",
    "    priority_numeric = priority_data.replace({'Low': 1, 'Medium': 2, 'High': 3})\n",
    "    \n",
    "    sns.heatmap(priority_numeric.T, annot=True, fmt='d', cmap='RdYlBu_r', \n",
    "                xticklabels=[s['title'][:15] + '...' if len(s['title']) > 15 else s['title'] for s in clinical_scenarios],\n",
    "                yticklabels=['Speed Priority', 'Accuracy Priority', 'Deployment Complexity', 'Maintenance Needs'],\n",
    "                ax=axes[0])\n",
    "    axes[0].set_title('Clinical Scenario Requirements Matrix')\n",
    "    plt.setp(axes[0].get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Model distribution\n",
    "    model_counts = comparison_matrix['Model'].value_counts()\n",
    "    axes[1].pie(model_counts.values, labels=model_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title('Model Selection Distribution\\nAcross Clinical Scenarios')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return clinical_scenarios, comparison_matrix\n",
    "\n",
    "# Create practical examples\n",
    "scenarios, comparison_df = create_practical_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-limitations"
   },
   "source": [
    "## Model Limitations and Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model-limitations-code"
   },
   "outputs": [],
   "source": [
    "def create_limitations_guide():\n",
    "    \"\"\"\n",
    "    Create comprehensive guide on model limitations and considerations\n",
    "    \"\"\"\n",
    "    print(\"AI MODEL LIMITATIONS AND CONSIDERATIONS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    limitations_guide = {\n",
    "        \"Technical Limitations\": {\n",
    "            \"Distribution Shift\": {\n",
    "                'description': 'Models may perform poorly on data different from training set',\n",
    "                'examples': ['Different imaging equipment', 'Varied patient populations', 'New pathology presentations'],\n",
    "                'mitigation': ['Regular performance monitoring', 'Domain adaptation techniques', 'Continuous learning systems']\n",
    "            },\n",
    "            \"Bias and Fairness\": {\n",
    "                'description': 'Models may exhibit bias toward certain demographic groups',\n",
    "                'examples': ['Age-related performance differences', 'Gender bias in predictions', 'Racial disparities in accuracy'],\n",
    "                'mitigation': ['Diverse training data', 'Bias testing protocols', 'Fairness-aware algorithms']\n",
    "            },\n",
    "            \"Adversarial Vulnerability\": {\n",
    "                'description': 'Models can be fooled by carefully crafted inputs',\n",
    "                'examples': ['Noise injection attacks', 'Image perturbations', 'Data poisoning'],\n",
    "                'mitigation': ['Robust training methods', 'Input validation', 'Ensemble approaches']\n",
    "            }\n",
    "        },\n",
    "        \"Clinical Limitations\": {\n",
    "            \"False Positives\": {\n",
    "                'description': 'Model detects pathologies that are not clinically present',\n",
    "                'examples': ['Overcalling normal variants', 'Artifacts as pathology', 'Incidental findings'],\n",
    "                'mitigation': ['Conservative thresholds', 'Clinical correlation', 'Radiologist oversight']\n",
    "            },\n",
    "            \"False Negatives\": {\n",
    "                'description': 'Model misses actual pathologies',\n",
    "                'examples': ['Subtle early-stage disease', 'Rare pathologies', 'Atypical presentations'],\n",
    "                'mitigation': ['High sensitivity settings', 'Multiple model ensemble', 'Human backup review']\n",
    "            },\n",
    "            \"Context Limitation\": {\n",
    "                'description': 'Models lack clinical context and patient history',\n",
    "                'examples': ['Ignoring symptoms', 'Missing prior imaging', 'No lab correlation'],\n",
    "                'mitigation': ['Integrated clinical data', 'Multimodal AI systems', 'Clinical decision support']\n",
    "            }\n",
    "        },\n",
    "        \"Regulatory and Ethical\": {\n",
    "            \"FDA Approval\": {\n",
    "                'description': 'Not all models have regulatory approval for clinical use',\n",
    "                'examples': ['Research-only models', 'Off-label usage', 'International variations'],\n",
    "                'mitigation': ['Check regulatory status', 'Use approved systems', 'Proper documentation']\n",
    "            },\n",
    "            \"Liability Concerns\": {\n",
    "                'description': 'Unclear responsibility for AI-assisted decisions',\n",
    "                'examples': ['Malpractice implications', 'Insurance coverage', 'Legal precedents'],\n",
    "                'mitigation': ['Clear policies', 'Professional guidelines', 'Legal consultation']\n",
    "            },\n",
    "            \"Patient Privacy\": {\n",
    "                'description': 'AI systems may pose privacy risks',\n",
    "                'examples': ['Data storage concerns', 'Cloud processing risks', 'Re-identification potential'],\n",
    "                'mitigation': ['Local processing', 'Encryption protocols', 'Privacy-preserving AI']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Display limitations guide\n",
    "    for category, limitations in limitations_guide.items():\n",
    "        print(f\"\\n{category}\")\n",
    "        print(\"=\" * len(category))\n",
    "        \n",
    "        for limitation, details in limitations.items():\n",
    "            print(f\"\\n{limitation}:\")\n",
    "            print(f\"   Description: {details['description']}\")\n",
    "            print(f\"   Examples: {', '.join(details['examples'])}\")\n",
    "            print(f\"   Mitigation: {', '.join(details['mitigation'])}\")\n",
    "    \n",
    "    # Best practices summary\n",
    "    print(\"\\n\\nBEST PRACTICES FOR CLINICAL AI DEPLOYMENT\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    best_practices = [\n",
    "        \"Always maintain human oversight and final decision authority\",\n",
    "        \"Regularly validate model performance on local data\",\n",
    "        \"Implement robust quality assurance protocols\",\n",
    "        \"Provide clear uncertainty quantification\",\n",
    "        \"Document all model versions and configurations\",\n",
    "        \"Train users on proper AI interpretation\",\n",
    "        \"Establish clear escalation procedures for uncertain cases\",\n",
    "        \"Monitor for distribution drift and bias\",\n",
    "        \"Maintain audit trails for all AI-assisted decisions\",\n",
    "        \"Stay updated with regulatory requirements\"\n",
    "    ]\n",
    "    \n",
    "    for i, practice in enumerate(best_practices, 1):\n",
    "        print(f\"{i:2d}. {practice}\")\n",
    "    \n",
    "    # Risk assessment matrix\n",
    "    print(\"\\n\\nRISK ASSESSMENT MATRIX\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    risk_data = {\n",
    "        'Risk Factor': ['Distribution Shift', 'Bias/Fairness', 'False Positives', 'False Negatives', \n",
    "                       'Regulatory Non-compliance', 'Privacy Breach'],\n",
    "        'Probability': ['High', 'Medium', 'High', 'Medium', 'Low', 'Low'],\n",
    "        'Impact': ['High', 'High', 'Medium', 'High', 'High', 'High'],\n",
    "        'Overall Risk': ['Critical', 'High', 'Medium', 'High', 'Medium', 'Medium'],\n",
    "        'Mitigation Strategy': ['Continuous monitoring', 'Bias testing', 'Conservative thresholds', \n",
    "                              'Human backup', 'Regulatory compliance', 'Privacy protocols']\n",
    "    }\n",
    "    \n",
    "    risk_df = pd.DataFrame(risk_data)\n",
    "    print(risk_df.to_string(index=False))\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Risk matrix heatmap\n",
    "    prob_map = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "    impact_map = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "    \n",
    "    risk_matrix_data = []\n",
    "    for _, row in risk_df.iterrows():\n",
    "        prob_score = prob_map[row['Probability']]\n",
    "        impact_score = impact_map[row['Impact']]\n",
    "        risk_matrix_data.append([prob_score, impact_score])\n",
    "    \n",
    "    scatter_data = np.array(risk_matrix_data)\n",
    "    colors = ['red' if r == 'Critical' else 'orange' if r == 'High' else 'yellow' \n",
    "              for r in risk_df['Overall Risk']]\n",
    "    \n",
    "    axes[0].scatter(scatter_data[:, 0], scatter_data[:, 1], c=colors, s=200, alpha=0.7)\n",
    "    \n",
    "    for i, risk in enumerate(risk_df['Risk Factor']):\n",
    "        axes[0].annotate(risk[:10] + '...' if len(risk) > 10 else risk, \n",
    "                        (scatter_data[i, 0], scatter_data[i, 1]),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    axes[0].set_xlabel('Probability')\n",
    "    axes[0].set_ylabel('Impact')\n",
    "    axes[0].set_title('Risk Assessment Matrix')\n",
    "    axes[0].set_xticks([1, 2, 3])\n",
    "    axes[0].set_xticklabels(['Low', 'Medium', 'High'])\n",
    "    axes[0].set_yticks([1, 2, 3])\n",
    "    axes[0].set_yticklabels(['Low', 'Medium', 'High'])\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Risk level distribution\n",
    "    risk_counts = risk_df['Overall Risk'].value_counts()\n",
    "    colors_pie = ['red', 'orange', 'yellow']\n",
    "    axes[1].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', \n",
    "               colors=colors_pie, startangle=90)\n",
    "    axes[1].set_title('Distribution of Risk Levels')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return risk_df\n",
    "\n",
    "# Create limitations guide\n",
    "risk_assessment = create_limitations_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "implementation-checklist"
   },
   "source": [
    "## Implementation Checklist and Action Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "implementation-checklist-code"
   },
   "outputs": [],
   "source": [
    "def create_implementation_checklist():\n",
    "    \"\"\"\n",
    "    Create comprehensive implementation checklist for medical AI deployment\n",
    "    \"\"\"\n",
    "    print(\"MEDICAL AI IMPLEMENTATION CHECKLIST\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    implementation_phases = {\n",
    "        \"Phase 1: Planning and Assessment\": {\n",
    "            \"timeline\": \"Weeks 1-4\",\n",
    "            \"tasks\": [\n",
    "                \"Define clinical objectives and success metrics\",\n",
    "                \"Assess current infrastructure and capabilities\",\n",
    "                \"Identify stakeholders and form implementation team\",\n",
    "                \"Review regulatory requirements and compliance needs\",\n",
    "                \"Conduct initial risk assessment\",\n",
    "                \"Develop project timeline and budget\",\n",
    "                \"Select appropriate AI model based on use case\"\n",
    "            ],\n",
    "            \"deliverables\": [\n",
    "                \"Project charter and objectives document\",\n",
    "                \"Infrastructure assessment report\",\n",
    "                \"Risk assessment matrix\",\n",
    "                \"Implementation timeline\",\n",
    "                \"Model selection rationale\"\n",
    "            ],\n",
    "            \"key_personnel\": [\"Project manager\", \"Clinical lead\", \"IT director\", \"Compliance officer\"]\n",
    "        },\n",
    "        \"Phase 2: Technical Setup\": {\n",
    "            \"timeline\": \"Weeks 5-8\",\n",
    "            \"tasks\": [\n",
    "                \"Procure and configure hardware/cloud resources\",\n",
    "                \"Install and configure AI model software\",\n",
    "                \"Integrate with existing PACS/EMR systems\",\n",
    "                \"Implement data security and privacy measures\",\n",
    "                \"Develop monitoring and logging systems\",\n",
    "                \"Create backup and disaster recovery procedures\",\n",
    "                \"Conduct initial technical testing\"\n",
    "            ],\n",
    "            \"deliverables\": [\n",
    "                \"Functional AI system\",\n",
    "                \"Integration documentation\",\n",
    "                \"Security implementation report\",\n",
    "                \"Testing protocols and results\",\n",
    "                \"Disaster recovery plan\"\n",
    "            ],\n",
    "            \"key_personnel\": [\"System administrator\", \"Integration specialist\", \"Security officer\"]\n",
    "        },\n",
    "        \"Phase 3: Validation and Testing\": {\n",
    "            \"timeline\": \"Weeks 9-12\",\n",
    "            \"tasks\": [\n",
    "                \"Validate model performance on local test dataset\",\n",
    "                \"Conduct clinical validation studies\",\n",
    "                \"Perform bias and fairness testing\",\n",
    "                \"Test integration workflows\",\n",
    "                \"Validate security and privacy measures\",\n",
    "                \"Document all validation results\",\n",
    "                \"Address any identified issues\"\n",
    "            ],\n",
    "            \"deliverables\": [\n",
    "                \"Performance validation report\",\n",
    "                \"Clinical validation study results\",\n",
    "                \"Bias testing report\",\n",
    "                \"Workflow validation documentation\",\n",
    "                \"Security audit results\"\n",
    "            ],\n",
    "            \"key_personnel\": [\"Clinical researcher\", \"Biostatistician\", \"Quality assurance lead\"]\n",
    "        },\n",
    "        \"Phase 4: Training and Deployment\": {\n",
    "            \"timeline\": \"Weeks 13-16\",\n",
    "            \"tasks\": [\n",
    "                \"Develop training materials and protocols\",\n",
    "                \"Conduct user training sessions\",\n",
    "                \"Implement gradual rollout strategy\",\n",
    "                \"Monitor initial deployment closely\",\n",
    "                \"Collect user feedback and usage data\",\n",
    "                \"Address any deployment issues\",\n",
    "                \"Finalize operational procedures\"\n",
    "            ],\n",
    "            \"deliverables\": [\n",
    "                \"Training materials and curriculum\",\n",
    "                \"User certification records\",\n",
    "                \"Deployment monitoring reports\",\n",
    "                \"User feedback analysis\",\n",
    "                \"Operational procedures manual\"\n",
    "            ],\n",
    "            \"key_personnel\": [\"Training coordinator\", \"Clinical users\", \"Support staff\"]\n",
    "        },\n",
    "        \"Phase 5: Monitoring and Optimization\": {\n",
    "            \"timeline\": \"Ongoing\",\n",
    "            \"tasks\": [\n",
    "                \"Continuously monitor model performance\",\n",
    "                \"Track clinical outcomes and metrics\",\n",
    "                \"Conduct regular quality assurance reviews\",\n",
    "                \"Update models and systems as needed\",\n",
    "                \"Maintain regulatory compliance\",\n",
    "                \"Provide ongoing user support\",\n",
    "                \"Plan for future enhancements\"\n",
    "            ],\n",
    "            \"deliverables\": [\n",
    "                \"Monthly performance reports\",\n",
    "                \"Clinical outcomes analysis\",\n",
    "                \"Quality assurance dashboards\",\n",
    "                \"Update and maintenance logs\",\n",
    "                \"Enhancement roadmap\"\n",
    "            ],\n",
    "            \"key_personnel\": [\"Operations manager\", \"Clinical quality lead\", \"Data analyst\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Display implementation phases\n",
    "    for phase, details in implementation_phases.items():\n",
    "        print(f\"\\n{phase}\")\n",
    "        print(\"=\" * len(phase))\n",
    "        print(f\"Timeline: {details['timeline']}\")\n",
    "        \n",
    "        print(f\"\\nKey Tasks:\")\n",
    "        for i, task in enumerate(details['tasks'], 1):\n",
    "            print(f\"   {i}. {task}\")\n",
    "        \n",
    "        print(f\"\\nDeliverables:\")\n",
    "        for deliverable in details['deliverables']:\n",
    "            print(f\"   • {deliverable}\")\n",
    "        \n",
    "        print(f\"\\nKey Personnel:\")\n",
    "        for person in details['key_personnel']:\n",
    "            print(f\"   • {person}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Create Gantt chart visualization\n",
    "    print(\"\\n\\nIMPLEMENTATION TIMELINE VISUALIZATION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Prepare data for Gantt chart\n",
    "    phases = list(implementation_phases.keys())\n",
    "    phase_durations = [4, 4, 4, 4, 8]  # Duration in weeks\n",
    "    phase_starts = [0, 4, 8, 12, 16]   # Start weeks\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Create Gantt chart\n",
    "    colors = ['skyblue', 'lightcoral', 'lightgreen', 'orange', 'purple']\n",
    "    \n",
    "    for i, (phase, duration, start) in enumerate(zip(phases, phase_durations, phase_starts)):\n",
    "        ax.barh(i, duration, left=start, height=0.6, \n",
    "               color=colors[i], alpha=0.7, label=phase.split(':')[0])\n",
    "        \n",
    "        # Add text in the middle of each bar\n",
    "        ax.text(start + duration/2, i, f\"Week {start+1}-{start+duration}\", \n",
    "               ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax.set_yticks(range(len(phases)))\n",
    "    ax.set_yticklabels([p.split(':')[0] for p in phases])\n",
    "    ax.set_xlabel('Timeline (Weeks)')\n",
    "    ax.set_title('AI Implementation Project Timeline', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add milestone markers\n",
    "    milestones = [\n",
    "        (4, 'Technical Setup Complete'),\n",
    "        (8, 'System Integration Done'),\n",
    "        (12, 'Validation Complete'),\n",
    "        (16, 'Initial Deployment'),\n",
    "        (20, 'Full Operation')\n",
    "    ]\n",
    "    \n",
    "    for week, milestone in milestones:\n",
    "        ax.axvline(x=week, color='red', linestyle='--', alpha=0.7)\n",
    "        ax.text(week, len(phases), milestone, rotation=90, \n",
    "               ha='right', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Implementation checklist\n",
    "    print(\"\\n\\nPRE-IMPLEMENTATION CHECKLIST\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    checklist_items = [\n",
    "        \"☐ Clinical objectives clearly defined\",\n",
    "        \"☐ Stakeholder buy-in secured\",\n",
    "        \"☐ Budget and resources approved\",\n",
    "        \"☐ Regulatory compliance verified\",\n",
    "        \"☐ Risk assessment completed\",\n",
    "        \"☐ Infrastructure requirements met\",\n",
    "        \"☐ AI model selected and validated\",\n",
    "        \"☐ Integration plan developed\",\n",
    "        \"☐ Training plan created\",\n",
    "        \"☐ Monitoring systems designed\",\n",
    "        \"☐ Support procedures established\",\n",
    "        \"☐ Contingency plans prepared\"\n",
    "    ]\n",
    "    \n",
    "    for item in checklist_items:\n",
    "        print(f\"   {item}\")\n",
    "    \n",
    "    print(\"\\n\\nSUCCESS METRICS\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    success_metrics = {\n",
    "        \"Technical Metrics\": [\n",
    "            \"Model accuracy > 85% on local validation set\",\n",
    "            \"System uptime > 99.5%\",\n",
    "            \"Average processing time < 100ms\",\n",
    "            \"Integration success rate > 95%\"\n",
    "        ],\n",
    "        \"Clinical Metrics\": [\n",
    "            \"Improved diagnostic accuracy\",\n",
    "            \"Reduced time to diagnosis\",\n",
    "            \"Decreased missed findings\",\n",
    "            \"Enhanced radiologist confidence\"\n",
    "        ],\n",
    "        \"Operational Metrics\": [\n",
    "            \"User adoption rate > 80%\",\n",
    "            \"Training completion rate 100%\",\n",
    "            \"Support ticket resolution < 24 hours\",\n",
    "            \"ROI positive within 12 months\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, metrics in success_metrics.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for metric in metrics:\n",
    "            print(f\"   • {metric}\")\n",
    "    \n",
    "    return implementation_phases\n",
    "\n",
    "# Create implementation checklist\n",
    "implementation_plan = create_implementation_checklist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial-summary"
   },
   "source": [
    "## Tutorial Summary\n",
    "\n",
    "### What You Have Learned:\n",
    "\n",
    "**Model Selection Framework:**\n",
    "- Comprehensive understanding of available medical AI models\n",
    "- Systematic approach to model selection based on clinical needs\n",
    "- Interactive decision-making tools for personalized recommendations\n",
    "\n",
    "**Performance Analysis:**\n",
    "- Deep dive into model performance metrics and comparisons\n",
    "- Understanding trade-offs between different AI approaches\n",
    "- Clinical interpretation of technical performance measures\n",
    "\n",
    "**Practical Implementation:**\n",
    "- Real-world clinical scenarios and appropriate model choices\n",
    "- Step-by-step implementation planning and execution\n",
    "- Risk assessment and mitigation strategies\n",
    "\n",
    "### Skills Acquired:\n",
    "\n",
    "- **Critical Evaluation**: Ability to assess AI models objectively for medical applications\n",
    "- **Decision Making**: Structured approach to selecting appropriate AI tools\n",
    "- **Risk Assessment**: Understanding limitations and potential pitfalls\n",
    "- **Implementation Planning**: Comprehensive project management for AI deployment\n",
    "- **Clinical Integration**: Matching AI capabilities with clinical workflows\n",
    "\n",
    "### Clinical Applications:\n",
    "\n",
    "**Emergency Medicine:**\n",
    "- Rapid AI-assisted triage and screening\n",
    "- Critical finding detection and alerting\n",
    "- Resource optimization in high-volume settings\n",
    "\n",
    "**Radiology:**\n",
    "- Enhanced diagnostic accuracy and consistency\n",
    "- Workflow optimization and efficiency gains\n",
    "- Quality assurance and error reduction\n",
    "\n",
    "**Research:**\n",
    "- Appropriate model selection for validation studies\n",
    "- Reproducible and comparable research methodologies\n",
    "- Publication-ready performance assessments\n",
    "\n",
    "### Key Decision Factors:\n",
    "\n",
    "1. **Clinical Setting**: Emergency, academic, rural, specialized\n",
    "2. **Performance Requirements**: Accuracy, speed, coverage\n",
    "3. **Resource Constraints**: Hardware, personnel, budget\n",
    "4. **Regulatory Environment**: FDA approval, local requirements\n",
    "5. **Integration Needs**: PACS, EMR, workflow compatibility\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- Always maintain human oversight and clinical correlation\n",
    "- Validate models on local patient populations\n",
    "- Implement comprehensive monitoring and quality assurance\n",
    "- Plan for continuous learning and model updates\n",
    "- Document decisions and maintain audit trails\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Apply Framework**: Use the decision tools with your specific clinical scenarios\n",
    "2. **Start Small**: Begin with pilot projects before full deployment\n",
    "3. **Build Expertise**: Develop in-house AI knowledge and capabilities\n",
    "4. **Stay Current**: Keep up with new models and regulatory developments\n",
    "5. **Collaborate**: Work with AI vendors, researchers, and other institutions\n",
    "\n",
    "You now have the knowledge and tools to make informed decisions about medical AI model selection and implementation, ensuring successful integration into clinical practice while maintaining the highest standards of patient care and safety."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",\n",
  "colab": {\n",
   "gpuType": "T4",\n",
   "provenance": []\n  },\n",
  "kernelspec": {\n",
   "display_name": "Python 3",\n",
   "name": "python3"\n  },\n",
  "language_info": {\n",
   "name": "python"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 0\n}