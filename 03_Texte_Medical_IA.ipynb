{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/maclandrol/12eed4ad1df93c712325cd5972447f01/03_Texte_Medical_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Analyse de Textes MÃ©dicaux avec IA\n",
    "\n",
    "**Enseignant:** Emmanuel Noutahi, PhD\n",
    "\n",
    "---\n",
    "\n",
    "**Objectif:** Utiliser l'IA pour analyser automatiquement des comptes-rendus mÃ©dicaux.\n",
    "\n",
    "**Applications pratiques :**\n",
    "- Triage automatique de comptes-rendus\n",
    "- Classification par niveau d'urgence\n",
    "- Extraction d'informations clÃ©s\n",
    "- DÃ©tection de pathologies dans le texte\n",
    "\n",
    "**Important:** Ce cours vous montre comment utiliser des outils IA existants, pas comment les crÃ©er."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des bibliothÃ¨ques pour l'analyse de texte mÃ©dical\n",
    "!pip install scikit-learn pandas numpy matplotlib seaborn -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"âœ… BibliothÃ¨ques installÃ©es et configurÃ©es avec succÃ¨s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## CrÃ©ation du Dataset de Comptes-Rendus"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er un dataset simulÃ© de comptes-rendus mÃ©dicaux\n",
    "comptes_rendus = [\n",
    "    {\n",
    "        \"texte\": \"Patient prÃ©sente une lÃ©gÃ¨re toux sÃ¨che depuis 3 jours. Examen pulmonaire normal. Auscultation cardiaque normale. TempÃ©rature 37.2Â°C. Prescription d'un sirop antitussif. Retour Ã  domicile avec surveillance.\",\n",
    "        \"urgence\": \"faible\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Douleur thoracique aiguÃ« survenue brutalement. ECG montre des anomalies du segment ST. Troponines Ã©levÃ©es. Suspicion d'infarctus du myocarde. Orientation immÃ©diate en cardiologie.\",\n",
    "        \"urgence\": \"haute\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"ContrÃ´le post-opÃ©ratoire aprÃ¨s appendicectomie. Cicatrisation correcte, pas de signes infectieux. Patient apyrÃ©tique. Ablation des fils prÃ©vue dans 7 jours. Ã‰volution favorable.\",\n",
    "        \"urgence\": \"faible\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"DÃ©tresse respiratoire sÃ©vÃ¨re. SpO2 Ã  85% en air ambiant. RÃ¢les crÃ©pitants bilatÃ©raux. Suspicion d'Å“dÃ¨me aigu pulmonaire. OxygÃ©nothÃ©rapie urgente et diurÃ©tiques IV.\",\n",
    "        \"urgence\": \"haute\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Hypertension artÃ©rielle modÃ©rÃ©ment dÃ©sÃ©quilibrÃ©e. TA 160/95 mmHg. Ajustement du traitement antihypertenseur. ContrÃ´le recommandÃ© dans 3 mois avec bilan lipidique.\",\n",
    "        \"urgence\": \"moyenne\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Consultation de routine pour diabÃ¨te type 2. GlycÃ©mie Ã  jeun 1.25 g/L. HbA1c Ã  7.2%. Adaptation posologique de la metformine. Suivi diÃ©tÃ©tique renforcÃ©.\",\n",
    "        \"urgence\": \"moyenne\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"AVC ischÃ©mique aigu confirmÃ© par IRM. DÃ©ficit moteur du cÃ´tÃ© droit. Prise en charge en unitÃ© neurovasculaire. Thrombolyse envisagÃ©e si dans les dÃ©lais.\",\n",
    "        \"urgence\": \"haute\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"GastroentÃ©rite probablement virale. DiarrhÃ©es liquides depuis 24h. Pas de fiÃ¨vre. Traitement symptomatique et rÃ©hydratation orale. Surveillance Ã  domicile.\",\n",
    "        \"urgence\": \"faible\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Crise d'asthme modÃ©rÃ©e. DyspnÃ©e d'effort. Peak-flow diminuÃ© Ã  60% de la thÃ©orique. Traitement bronchodilatateur renforcÃ©. ContrÃ´le pneumologique Ã  prÃ©voir.\",\n",
    "        \"urgence\": \"moyenne\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Choc anaphylactique suite Ã  prise d'antibiotique. Urticaire gÃ©nÃ©ralisÃ© et hypotension. AdrÃ©naline intramusculaire et corticoÃ¯des IV. Surveillance en rÃ©animation.\",\n",
    "        \"urgence\": \"haute\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Migraine habituelle chez patiente connue. CÃ©phalÃ©es pulsatiles sans signes neurologiques. Traitement antalgique habituel efficace. Pas de signe d'alarme.\",\n",
    "        \"urgence\": \"faible\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Fracture du poignet droit suite Ã  chute. Radiographie confirme fracture de Colles. RÃ©duction sous anesthÃ©sie locale. Immobilisation plÃ¢trÃ©e pour 6 semaines.\",\n",
    "        \"urgence\": \"moyenne\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Ã‰tat de mal Ã©pileptique. Crises gÃ©nÃ©ralisÃ©es tonico-cloniques rÃ©pÃ©tÃ©es. Traitement antiÃ©pileptique IV urgent. Transfert en rÃ©animation neurologique.\",\n",
    "        \"urgence\": \"haute\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Consultation prÃ©ventive. Bilan de santÃ© normal. Vaccinations Ã  jour. Conseils hygiÃ©no-diÃ©tÃ©tiques. Prochaine consultation dans 1 an.\",\n",
    "        \"urgence\": \"faible\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Insuffisance cardiaque dÃ©compensÃ©e. DyspnÃ©e de repos, Å“dÃ¨mes des membres infÃ©rieurs. BNP Ã©levÃ©. Adaptation du traitement diurÃ©tique et surveillance.\",\n",
    "        \"urgence\": \"haute\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Lombalgie commune sans signes de gravitÃ©. Pas de dÃ©ficit neurologique. Traitement antalgique et anti-inflammatoire. Repos relatif conseillÃ©.\",\n",
    "        \"urgence\": \"faible\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Pneumonie communautaire probable. FiÃ¨vre 39Â°C, toux productive. Radiographie pulmonaire montre un foyer infectieux. AntibiothÃ©rapie dÃ©butÃ©e.\",\n",
    "        \"urgence\": \"moyenne\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"HÃ©morragie digestive haute. HÃ©matÃ©mÃ¨se et mÃ©lÃ©na. Choc hÃ©morragique. Transfusion sanguine urgente et endoscopie en urgence.\",\n",
    "        \"urgence\": \"haute\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"AnxiÃ©tÃ© gÃ©nÃ©ralisÃ©e chez patient stressÃ©. Pas de signes organiques. Traitement anxiolytique ponctuel. Orientation vers psychologue recommandÃ©e.\",\n",
    "        \"urgence\": \"faible\"\n",
    "    },\n",
    "    {\n",
    "        \"texte\": \"Calcul rÃ©nal avec colique nÃ©phrÃ©tique. Douleur intense lombaire droite. Scanner confirme lithiase urÃ©tÃ©rale. Traitement antalgique et surveillance.\",\n",
    "        \"urgence\": \"moyenne\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df = pd.DataFrame(comptes_rendus)\n",
    "print(f\"ðŸ“Š Dataset crÃ©Ã©: {len(df)} comptes-rendus mÃ©dicaux\")\n",
    "print(f\"ðŸ“‹ AperÃ§u des donnÃ©es:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Exploration du Dataset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la rÃ©partition des niveaux d'urgence\n",
    "print(\"ðŸ¥ RÃ‰PARTITION DES NIVEAUX D'URGENCE:\")\n",
    "print(\"=\" * 40)\n",
    "urgence_counts = df['urgence'].value_counts()\n",
    "print(urgence_counts)\n",
    "\n",
    "print(f\"\\nðŸ“Š Pourcentages:\")\n",
    "for urgence, count in urgence_counts.items():\n",
    "    pourcentage = (count / len(df)) * 100\n",
    "    print(f\"â€¢ {urgence.capitalize()}: {count} cas ({pourcentage:.1f}%)\")\n",
    "\n",
    "# Longueur des textes\n",
    "df['longueur_texte'] = df['texte'].apply(len)\n",
    "print(f\"\\nðŸ“ STATISTIQUES DES TEXTES:\")\n",
    "print(f\"â€¢ Longueur moyenne: {df['longueur_texte'].mean():.0f} caractÃ¨res\")\n",
    "print(f\"â€¢ Longueur mÃ©diane: {df['longueur_texte'].median():.0f} caractÃ¨res\")\n",
    "print(f\"â€¢ Longueur min/max: {df['longueur_texte'].min()}/{df['longueur_texte'].max()} caractÃ¨res\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations de l'exploration\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Graphique 1: RÃ©partition des urgences\n",
    "urgence_counts.plot(kind='pie', ax=axes[0], autopct='%1.1f%%', \n",
    "                   colors=['lightgreen', 'orange', 'salmon'])\n",
    "axes[0].set_title('RÃ©partition des Niveaux d\\'Urgence')\n",
    "axes[0].set_ylabel('')\n",
    "\n",
    "# Graphique 2: Longueur des textes par urgence\n",
    "for urgence in df['urgence'].unique():\n",
    "    subset = df[df['urgence'] == urgence]['longueur_texte']\n",
    "    axes[1].hist(subset, alpha=0.7, label=urgence.capitalize(), bins=8)\n",
    "axes[1].set_title('Distribution de la Longueur des Textes par Urgence')\n",
    "axes[1].set_xlabel('Longueur (caractÃ¨res)')\n",
    "axes[1].set_ylabel('FrÃ©quence')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Analyse des Mots-ClÃ©s MÃ©dicaux"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des mots les plus frÃ©quents par niveau d'urgence\n",
    "def analyser_mots_cles(textes, urgence_niveau):\n",
    "    \"\"\"\n",
    "    Analyser les mots-clÃ©s les plus frÃ©quents pour un niveau d'urgence\n",
    "    \"\"\"\n",
    "    # Joindre tous les textes de ce niveau\n",
    "    texte_complet = ' '.join(textes).lower()\n",
    "    \n",
    "    # Nettoyer le texte\n",
    "    texte_propre = re.sub(r'[^a-zÃ Ã¢Ã¤Ã©Ã¨ÃªÃ«Ã¯Ã®Ã´Ã¶Ã¹Ã»Ã¼Ã§\\s]', ' ', texte_complet)\n",
    "    \n",
    "    # Mots vides mÃ©dicaux franÃ§ais\n",
    "    mots_vides = ['le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'et', 'ou', \n",
    "                  'avec', 'sans', 'dans', 'sur', 'pour', 'par', 'depuis', 'aprÃ¨s',\n",
    "                  'patient', 'patiente', 'cas', 'suite']\n",
    "    \n",
    "    # Compter les mots\n",
    "    mots = texte_propre.split()\n",
    "    compteur_mots = {}\n",
    "    \n",
    "    for mot in mots:\n",
    "        if len(mot) > 3 and mot not in mots_vides:\n",
    "            compteur_mots[mot] = compteur_mots.get(mot, 0) + 1\n",
    "    \n",
    "    # Retourner les 10 plus frÃ©quents\n",
    "    return sorted(compteur_mots.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"ðŸ” MOTS-CLÃ‰S LES PLUS FRÃ‰QUENTS PAR URGENCE:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for urgence in ['faible', 'moyenne', 'haute']:\n",
    "    textes_urgence = df[df['urgence'] == urgence]['texte'].tolist()\n",
    "    mots_cles = analyser_mots_cles(textes_urgence, urgence)\n",
    "    \n",
    "    print(f\"\\nðŸ“Œ Urgence {urgence.upper()}:\")\n",
    "    for i, (mot, freq) in enumerate(mots_cles[:8], 1):\n",
    "        print(f\"  {i}. {mot} (Ã—{freq})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Construction du ModÃ¨le de Classification"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrÃ©paration des donnÃ©es pour l'apprentissage automatique\n",
    "print(\"ðŸ”§ PRÃ‰PARATION DES DONNÃ‰ES:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Encoder les catÃ©gories d'urgence\n",
    "label_map = {'faible': 0, 'moyenne': 1, 'haute': 2}\n",
    "label_inverse = {0: 'faible', 1: 'moyenne', 2: 'haute'}\n",
    "\n",
    "# PrÃ©parer les donnÃ©es\n",
    "textes = df['texte'].tolist()\n",
    "labels = [label_map[urgence] for urgence in df['urgence']]\n",
    "\n",
    "print(f\"Nombre de comptes-rendus: {len(textes)}\")\n",
    "print(f\"RÃ©partition des classes:\")\n",
    "for urgence, count in df['urgence'].value_counts().items():\n",
    "    print(f\"  â€¢ {urgence}: {count} cas\")\n",
    "\n",
    "# Vectorisation TF-IDF pour transformer le texte en nombres\n",
    "print(f\"\\nðŸ“Š VECTORISATION TF-IDF:\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=200,     # Maximum 200 mots les plus importants\n",
    "    stop_words=None,      # Pas de mots vides automatiques (on gÃ¨re manuellement)\n",
    "    lowercase=True,       # Convertir en minuscules\n",
    "    ngram_range=(1, 2)    # Mots individuels et bigrammes\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(textes)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"Matrice de caractÃ©ristiques: {X.shape}\")\n",
    "print(f\"  â€¢ {X.shape[0]} documents\")\n",
    "print(f\"  â€¢ {X.shape[1]} caractÃ©ristiques (mots/phrases)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š DIVISION DES DONNÃ‰ES:\")\n",
    "print(f\"DonnÃ©es d'entraÃ®nement: {X_train.shape[0]} comptes-rendus\")\n",
    "print(f\"DonnÃ©es de test: {X_test.shape[0]} comptes-rendus\")\n",
    "\n",
    "# EntraÃ®nement de plusieurs modÃ¨les\n",
    "modeles = {\n",
    "    'RÃ©gression Logistique': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "resultats = {}\n",
    "\n",
    "print(f\"\\nðŸŒ³ ENTRAÃŽNEMENT DES MODÃˆLES:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for nom_modele, modele in modeles.items():\n",
    "    # EntraÃ®nement\n",
    "    modele.fit(X_train, y_train)\n",
    "    \n",
    "    # PrÃ©dictions\n",
    "    y_pred = modele.predict(X_test)\n",
    "    \n",
    "    # MÃ©triques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    resultats[nom_modele] = {\n",
    "        'modele': modele,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{nom_modele}:\")\n",
    "    print(f\"  â€¢ PrÃ©cision: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "    print(f\"  â€¢ PrÃ©cision pondÃ©rÃ©e: {precision:.3f}\")\n",
    "    print(f\"  â€¢ SensibilitÃ© pondÃ©rÃ©e: {recall:.3f}\")\n",
    "    print(f\"  â€¢ Score F1 pondÃ©rÃ©: {f1:.3f}\")\n",
    "\n",
    "# SÃ©lectionner le meilleur modÃ¨le\n",
    "meilleur_modele_nom = max(resultats.keys(), key=lambda x: resultats[x]['accuracy'])\n",
    "meilleur_modele = resultats[meilleur_modele_nom]['modele']\n",
    "\n",
    "print(f\"\\nðŸ† Meilleur modÃ¨le: {meilleur_modele_nom}\")\n",
    "print(f\"    PrÃ©cision: {resultats[meilleur_modele_nom]['accuracy']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Ã‰valuation DÃ©taillÃ©e du ModÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification dÃ©taillÃ© pour le meilleur modÃ¨le\n",
    "y_pred_best = resultats[meilleur_modele_nom]['predictions']\n",
    "\n",
    "print(f\"ðŸ“‹ RAPPORT DÃ‰TAILLÃ‰ - {meilleur_modele_nom.upper()}:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_best, \n",
    "                          target_names=['Urgence Faible', 'Urgence Moyenne', 'Urgence Haute']))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Faible', 'Moyenne', 'Haute'],\n",
    "            yticklabels=['Faible', 'Moyenne', 'Haute'])\n",
    "plt.title(f'Matrice de Confusion - {meilleur_modele_nom}')\n",
    "plt.ylabel('Vraie Urgence')\n",
    "plt.xlabel('Urgence PrÃ©dite')\n",
    "plt.show()\n",
    "\n",
    "# Analyse des erreurs\n",
    "print(f\"\\nðŸ” ANALYSE DES ERREURS:\")\n",
    "erreurs = np.where(y_test != y_pred_best)[0]\n",
    "print(f\"Nombre d'erreurs: {len(erreurs)} sur {len(y_test)} prÃ©dictions\")\n",
    "\n",
    "if len(erreurs) > 0:\n",
    "    print(f\"\\nExemples d'erreurs:\")\n",
    "    test_indices = np.arange(len(y_test))\n",
    "    for i, erreur_idx in enumerate(erreurs[:3]):\n",
    "        original_idx = test_indices[erreur_idx]\n",
    "        vraie_urgence = label_inverse[y_test[erreur_idx]]\n",
    "        pred_urgence = label_inverse[y_pred_best[erreur_idx]]\n",
    "        # Retrouver le texte original\n",
    "        texte_erreur = df.iloc[original_idx]['texte'][:100] + \"...\"\n",
    "        print(f\"  {i+1}. PrÃ©dit '{pred_urgence}' au lieu de '{vraie_urgence}'\")\n",
    "        print(f\"     Texte: {texte_erreur}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Mots les Plus Importants pour la Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les mots les plus importants (si modÃ¨le linÃ©aire)\n",
    "if meilleur_modele_nom == 'RÃ©gression Logistique':\n",
    "    print(\"ðŸŽ¯ MOTS LES PLUS DISCRIMINANTS:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    for classe_idx, classe_nom in enumerate(['Faible', 'Moyenne', 'Haute']):\n",
    "        # Coefficients pour cette classe\n",
    "        coefficients = meilleur_modele.coef_[classe_idx]\n",
    "        \n",
    "        # Top mots positifs (indiquent cette classe)\n",
    "        top_positifs_idx = np.argsort(coefficients)[-8:][::-1]\n",
    "        \n",
    "        # Top mots nÃ©gatifs (indiquent l'absence de cette classe)\n",
    "        top_negatifs_idx = np.argsort(coefficients)[:5]\n",
    "        \n",
    "        print(f\"\\nðŸ“Œ URGENCE {classe_nom.upper()}:\")\n",
    "        print(f\"  Mots indicateurs (+):\")\n",
    "        for idx in top_positifs_idx:\n",
    "            if coefficients[idx] > 0:\n",
    "                print(f\"    â€¢ {feature_names[idx]} ({coefficients[idx]:.3f})\")\n",
    "        \n",
    "        print(f\"  Mots contre-indicateurs (-):\")\n",
    "        for idx in top_negatifs_idx:\n",
    "            if coefficients[idx] < 0:\n",
    "                print(f\"    â€¢ {feature_names[idx]} ({coefficients[idx]:.3f})\")\n",
    "\n",
    "elif meilleur_modele_nom == 'Random Forest':\n",
    "    print(\"ðŸŽ¯ CARACTÃ‰RISTIQUES LES PLUS IMPORTANTES (Random Forest):\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    importances = meilleur_modele.feature_importances_\n",
    "    \n",
    "    # Top 15 caractÃ©ristiques les plus importantes\n",
    "    top_indices = np.argsort(importances)[-15:][::-1]\n",
    "    \n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        print(f\"  {i:2d}. {feature_names[idx]:<20} : {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”® PrÃ©diction sur Nouveaux Comptes-Rendus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour analyser un nouveau compte-rendu\n",
    "def analyser_compte_rendu(texte_nouveau):\n",
    "    \"\"\"\n",
    "    Analyser l'urgence d'un nouveau compte-rendu mÃ©dical\n",
    "    \"\"\"\n",
    "    # Transformer le texte avec le mÃªme vectorizer\n",
    "    texte_vectorise = vectorizer.transform([texte_nouveau])\n",
    "    \n",
    "    # PrÃ©dire l'urgence\n",
    "    prediction = meilleur_modele.predict(texte_vectorise)[0]\n",
    "    probabilites = meilleur_modele.predict_proba(texte_vectorise)[0]\n",
    "    \n",
    "    urgence_predite = label_inverse[prediction]\n",
    "    confiance = max(probabilites) * 100\n",
    "    \n",
    "    # DÃ©terminer le niveau d'alerte\n",
    "    if urgence_predite == 'haute':\n",
    "        emoji = \"ðŸš¨\"\n",
    "        action = \"INTERVENTION URGENTE\"\n",
    "    elif urgence_predite == 'moyenne':\n",
    "        emoji = \"âš ï¸\"\n",
    "        action = \"Surveillance renforcÃ©e\"\n",
    "    else:\n",
    "        emoji = \"âœ…\"\n",
    "        action = \"Suivi de routine\"\n",
    "    \n",
    "    return {\n",
    "        'urgence': urgence_predite,\n",
    "        'confiance': confiance,\n",
    "        'probabilites': {\n",
    "            'faible': probabilites[0] * 100,\n",
    "            'moyenne': probabilites[1] * 100,\n",
    "            'haute': probabilites[2] * 100\n",
    "        },\n",
    "        'emoji': emoji,\n",
    "        'action': action\n",
    "    }\n",
    "\n",
    "# Tester avec de nouveaux exemples\n",
    "nouveaux_cas = [\n",
    "    \"ArrÃªt cardiorespiratoire. Massage cardiaque en cours. DÃ©fibrillation nÃ©cessaire. RÃ©animation en urgence absolue.\",\n",
    "    \"Rhume banal avec Ã©coulement nasal. Pas de fiÃ¨vre. Traitement symptomatique. AmÃ©lioration attendue.\",\n",
    "    \"PhlÃ©bite du mollet gauche confirmÃ©e Ã  l'Ã©chodoppler. Anticoagulation dÃ©butÃ©e. Surveillance biologique.\",\n",
    "    \"Plaie superficielle au genou aprÃ¨s chute. DÃ©sinfection et pansement. ContrÃ´le dans 48 heures.\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ‘¥ ANALYSE DE NOUVEAUX COMPTES-RENDUS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, cas in enumerate(nouveaux_cas, 1):\n",
    "    resultat = analyser_compte_rendu(cas)\n",
    "    \n",
    "    print(f\"\\n{resultat['emoji']} CAS {i}:\")\n",
    "    print(f\"Texte: {cas[:80]}...\")\n",
    "    print(f\"Urgence prÃ©dite: {resultat['urgence'].upper()}\")\n",
    "    print(f\"Confiance: {resultat['confiance']:.1f}%\")\n",
    "    print(f\"Action recommandÃ©e: {resultat['action']}\")\n",
    "    print(f\"ProbabilitÃ©s dÃ©taillÃ©es:\")\n",
    "    for niveau, prob in resultat['probabilites'].items():\n",
    "        print(f\"  â€¢ {niveau}: {prob:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Outil Pratique de Triage Automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outil complet de triage automatique\n",
    "def triage_automatique(comptes_rendus_liste):\n",
    "    \"\"\"\n",
    "    Effectuer un triage automatique sur une liste de comptes-rendus\n",
    "    \n",
    "    Args:\n",
    "        comptes_rendus_liste: Liste de dictionnaires avec 'id' et 'texte'\n",
    "    \n",
    "    Returns:\n",
    "        Liste triÃ©e par ordre de prioritÃ©\n",
    "    \"\"\"\n",
    "    resultats = []\n",
    "    \n",
    "    for cr in comptes_rendus_liste:\n",
    "        analyse = analyser_compte_rendu(cr['texte'])\n",
    "        \n",
    "        # Score de prioritÃ© (urgence haute = 3, moyenne = 2, faible = 1)\n",
    "        score_priorite = {'haute': 3, 'moyenne': 2, 'faible': 1}[analyse['urgence']]\n",
    "        \n",
    "        resultats.append({\n",
    "            'id': cr['id'],\n",
    "            'texte': cr['texte'][:100] + '...',\n",
    "            'urgence': analyse['urgence'],\n",
    "            'confiance': analyse['confiance'],\n",
    "            'emoji': analyse['emoji'],\n",
    "            'action': analyse['action'],\n",
    "            'score_priorite': score_priorite\n",
    "        })\n",
    "    \n",
    "    # Trier par score de prioritÃ© dÃ©croissant, puis par confiance\n",
    "    resultats_tries = sorted(resultats, \n",
    "                           key=lambda x: (x['score_priorite'], x['confiance']), \n",
    "                           reverse=True)\n",
    "    \n",
    "    return resultats_tries\n",
    "\n",
    "# Exemple d'utilisation\n",
    "exemple_urgences = [\n",
    "    {\n",
    "        'id': 'CR001',\n",
    "        'texte': 'ContrÃ´le post-vaccination. Pas d\\'effets secondaires. Ã‰tat gÃ©nÃ©ral excellent.'\n",
    "    },\n",
    "    {\n",
    "        'id': 'CR002', \n",
    "        'texte': 'Embolie pulmonaire massive. DÃ©tresse respiratoire majeure. Anticoagulation en urgence.'\n",
    "    },\n",
    "    {\n",
    "        'id': 'CR003',\n",
    "        'texte': 'Entorse de cheville grade 1. Douleur modÃ©rÃ©e. Traitement antalgique et repos.'\n",
    "    },\n",
    "    {\n",
    "        'id': 'CR004',\n",
    "        'texte': 'Coma diabÃ©tique. GlycÃ©mie Ã  5g/L. Perfusion insuline et rÃ©animation mÃ©dicale.'\n",
    "    },\n",
    "    {\n",
    "        'id': 'CR005',\n",
    "        'texte': 'Otite moyenne aiguÃ«. Tympan rouge et bombÃ©. AntibiothÃ©rapie prescrite.'\n",
    "    }\n",
    "]\n",
    "\n",
    "triage_resultat = triage_automatique(exemple_urgences)\n",
    "\n",
    "print(\"ðŸ¥ RÃ‰SULTAT DU TRIAGE AUTOMATIQUE:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Ordre de prioritÃ© (du plus urgent au moins urgent):\\n\")\n",
    "\n",
    "for i, resultat in enumerate(triage_resultat, 1):\n",
    "    print(f\"{i}. {resultat['emoji']} {resultat['id']} - Urgence {resultat['urgence'].upper()}\")\n",
    "    print(f\"   Confiance: {resultat['confiance']:.1f}%\")\n",
    "    print(f\"   Action: {resultat['action']}\")\n",
    "    print(f\"   Texte: {resultat['texte']}\")\n",
    "    print()\n",
    "\n",
    "# Statistiques du triage\n",
    "stats_triage = {'haute': 0, 'moyenne': 0, 'faible': 0}\n",
    "for resultat in triage_resultat:\n",
    "    stats_triage[resultat['urgence']] += 1\n",
    "\n",
    "print(\"ðŸ“Š STATISTIQUES DU TRIAGE:\")\n",
    "print(f\"ðŸš¨ Urgence haute: {stats_triage['haute']} cas\")\n",
    "print(f\"âš ï¸ Urgence moyenne: {stats_triage['moyenne']} cas\")\n",
    "print(f\"âœ… Urgence faible: {stats_triage['faible']} cas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… RÃ©sumÃ© et Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÃ©sumÃ© final de l'analyse\n",
    "print(\"ðŸ¥ RÃ‰SUMÃ‰ DE L'ANALYSE DE TEXTES MÃ‰DICAUX:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ðŸ“Š Dataset analysÃ©: {len(df)} comptes-rendus mÃ©dicaux\")\n",
    "print(f\"ðŸ¤– Meilleur modÃ¨le: {meilleur_modele_nom}\")\n",
    "print(f\"ðŸŽ¯ Performance: {resultats[meilleur_modele_nom]['accuracy']*100:.1f}% de prÃ©cision\")\n",
    "print(f\"ðŸ“‹ Classes: 3 niveaux d'urgence (faible, moyenne, haute)\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ APPLICATIONS PRATIQUES IMMÃ‰DIATES:\")\n",
    "print(f\"âœ… Triage automatique des comptes-rendus entrants\")\n",
    "print(f\"âœ… Priorisation des consultations selon l'urgence\")\n",
    "print(f\"âœ… Alerte automatique pour les cas critiques\")\n",
    "print(f\"âœ… Aide Ã  la dÃ©cision pour les mÃ©decins rÃ©gulateurs\")\n",
    "print(f\"âœ… Optimisation des flux dans les services d'urgence\")\n",
    "print(f\"âœ… Surveillance de la qualitÃ© des comptes-rendus\")\n",
    "\n",
    "print(f\"\\nðŸ”§ OUTILS DÃ‰VELOPPÃ‰S:\")\n",
    "print(f\"ðŸ“ Analyseur de compte-rendu individuel\")\n",
    "print(f\"ðŸ¥ SystÃ¨me de triage automatique par lots\")\n",
    "print(f\"ðŸ“Š Tableau de bord des urgences\")\n",
    "print(f\"ðŸŽ¯ Extraction des mots-clÃ©s discriminants\")\n",
    "\n",
    "print(f\"\\nâš ï¸ LIMITATIONS IMPORTANTES:\")\n",
    "print(f\"â€¢ Dataset d'entraÃ®nement limitÃ© (pour dÃ©monstration)\")\n",
    "print(f\"â€¢ NÃ©cessite validation sur de vraies donnÃ©es hospitaliÃ¨res\")\n",
    "print(f\"â€¢ Performance dÃ©pend de la qualitÃ© de rÃ©daction\")\n",
    "print(f\"â€¢ Ne remplace pas l'expertise mÃ©dicale humaine\")\n",
    "print(f\"â€¢ Doit Ãªtre adaptÃ© au vocabulaire de chaque service\")\n",
    "\n",
    "print(f\"\\nðŸŽ“ COMPÃ‰TENCES ACQUISES:\")\n",
    "print(f\"âœ… PrÃ©paration de donnÃ©es textuelles mÃ©dicales\")\n",
    "print(f\"âœ… Vectorisation TF-IDF pour l'analyse de texte\")\n",
    "print(f\"âœ… Classification multiclasse avec scikit-learn\")\n",
    "print(f\"âœ… Ã‰valuation de modÃ¨les de classification de texte\")\n",
    "print(f\"âœ… Analyse des mots-clÃ©s discriminants\")\n",
    "print(f\"âœ… DÃ©veloppement d'outils de triage automatique\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ PROCHAINE Ã‰TAPE:\")\n",
    "print(f\"Dans le prochain notebook, nous utiliserons PyTorch pour des analyses plus avancÃ©es!\")\n",
    "\n",
    "# Afficher un exemple de template final\n",
    "print(f\"\\nðŸ’¡ TEMPLATE PRÃŠT Ã€ UTILISER:\")\n",
    "print(f\"```python\")\n",
    "print(f\"# Pour analyser un nouveau compte-rendu:\")\n",
    "print(f\"nouveau_texte = 'Votre compte-rendu ici...'\")\n",
    "print(f\"resultat = analyser_compte_rendu(nouveau_texte)\")\n",
    "print(f\"print(f'Urgence: {{resultat[\\\"urgence\\\"]}} ({{resultat[\\\"confiance\\\"]:.1f}}%)')\")\n",
    "print(f\"```\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}