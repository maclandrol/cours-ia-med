{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/maclandrol/cours-ia-med/blob/master/05_TorchXRayVision_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05. TorchXRayVision - Analyse Complète de Radiographies Thoraciques\n",
        "\n",
        "**Enseignant:** Emmanuel Noutahi, PhD\n",
        "\n",
        "---\n",
        "\n",
        "**Objectif:** Maîtriser l'analyse complète de radiographies thoraciques avec TorchXRayVision.\n",
        "\n",
        "**Applications pratiques :**\n",
        "- Classification multi-pathologies avec 18 conditions détectables\n",
        "- Comparaison de modèles pré-entraînés (DenseNet-All, CheXpert, NIH)\n",
        "- Localisation spatiale avec cartes d'activation Grad-CAM\n",
        "- Génération automatique de rapports cliniques\n",
        "- Intégration dans workflows hospitaliers\n",
        "\n",
        "**Important:** Ce cours couvre l'ensemble du pipeline d'analyse radiologique avec TorchXRayVision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation et Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation des bibliothèques pour analyse radiologique complète\n",
        "!pip install torchxrayvision torch torchvision matplotlib numpy pandas seaborn scikit-learn -q\n",
        "!pip install opencv-python pillow scipy -q\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchxrayvision as xrv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from scipy import ndimage\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration système\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"Dispositif utilisé: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Mémoire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "print(f\"Version TorchXRayVision: {xrv.__version__}\")\n",
        "print(\"Configuration TorchXRayVision terminée.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Chargement des Modèles Multi-Dataset\n",
        "\n",
        "TorchXRayVision propose plusieurs modèles spécialisés entraînés sur différents datasets hospitaliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement des modèles TorchXRayVision\n",
        "print(\"=== CHARGEMENT DES MODÈLES TORCHXRAYVISION ===\")\n",
        "\n",
        "def load_xrayvision_models(device):\n",
        "    \"\"\"\n",
        "    Charge les modèles TorchXRayVision disponibles pour comparaison\n",
        "    \"\"\"\n",
        "    models = {}\n",
        "    model_info = {}\n",
        "    \n",
        "    # Modèle universel (tous datasets combinés)\n",
        "    try:\n",
        "        print(\"Chargement modèle DenseNet-All...\")\n",
        "        models['densenet_all'] = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "        models['densenet_all'].eval().to(device)\n",
        "        \n",
        "        model_info['densenet_all'] = {\n",
        "            'name': 'DenseNet-All',\n",
        "            'description': 'Entraîné sur tous les datasets disponibles',\n",
        "            'datasets': 'CheXpert + NIH + MIMIC + PC + Padchest',\n",
        "            'pathologies': 18,\n",
        "            'specialty': 'Généraliste haute performance'\n",
        "        }\n",
        "        print(\"✓ DenseNet-All chargé\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur DenseNet-All: {e}\")\n",
        "    \n",
        "    # Modèle CheXpert (Stanford)\n",
        "    try:\n",
        "        print(\"Chargement modèle CheXpert...\")\n",
        "        models['chexpert'] = xrv.models.DenseNet(weights=\"densenet121-res224-chex\")\n",
        "        models['chexpert'].eval().to(device)\n",
        "        \n",
        "        model_info['chexpert'] = {\n",
        "            'name': 'CheXpert',\n",
        "            'description': 'Modèle Stanford CheXpert',\n",
        "            'datasets': 'CheXpert (224k images Stanford)',\n",
        "            'pathologies': 14,\n",
        "            'specialty': 'Pathologies thoraciques variées'\n",
        "        }\n",
        "        print(\"✓ CheXpert chargé\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur CheXpert: {e}\")\n",
        "    \n",
        "    # Modèle NIH\n",
        "    try:\n",
        "        print(\"Chargement modèle NIH...\")\n",
        "        models['nih'] = xrv.models.DenseNet(weights=\"densenet121-res224-nih\")\n",
        "        models['nih'].eval().to(device)\n",
        "        \n",
        "        model_info['nih'] = {\n",
        "            'name': 'NIH ChestX-ray8',\n",
        "            'description': 'Modèle NIH National Institutes of Health',\n",
        "            'datasets': 'NIH ChestX-ray8 (112k images)',\n",
        "            'pathologies': 14,\n",
        "            'specialty': '14 pathologies principales'\n",
        "        }\n",
        "        print(\"✓ NIH chargé\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur NIH: {e}\")\n",
        "    \n",
        "    return models, model_info\n",
        "\n",
        "# Chargement des modèles\n",
        "models_dict, models_info = load_xrayvision_models(device)\n",
        "\n",
        "print(f\"\\nModèles chargés: {len(models_dict)}\")\n",
        "for model_key, info in models_info.items():\n",
        "    if model_key in models_dict:\n",
        "        print(f\"• {info['name']}: {info['description']}\")\n",
        "\n",
        "# Récupération des pathologies détectables\n",
        "if models_dict:\n",
        "    primary_model = list(models_dict.values())[0]\n",
        "    pathologies = primary_model.pathologies\n",
        "    \n",
        "    print(f\"\\nPathologies détectables ({len(pathologies)}):\")\n",
        "    for i, pathology in enumerate(pathologies, 1):\n",
        "        print(f\"{i:2d}. {pathology}\")\n",
        "else:\n",
        "    print(\"Aucun modèle disponible\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Création de Cas Cliniques Réalistes\n",
        "\n",
        "Créons une bibliothèque de radiographies représentant différents cas cliniques pour évaluer les modèles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Création de radiographies synthétiques réalistes\n",
        "print(\"=== CRÉATION DE CAS CLINIQUES RÉALISTES ===\")\n",
        "\n",
        "def create_synthetic_chest_xray(pathology_type, severity='moderate', size=224):\n",
        "    \"\"\"\n",
        "    Crée des radiographies synthétiques avec pathologies spécifiques\n",
        "    \n",
        "    pathology_type: 'normal', 'pneumonia', 'cardiomegaly', 'pneumothorax', \n",
        "                   'pleural_effusion', 'atelectasis', 'nodule'\n",
        "    severity: 'mild', 'moderate', 'severe'\n",
        "    \"\"\"\n",
        "    img = np.zeros((size, size), dtype=np.float32)\n",
        "    center_x, center_y = size // 2, size // 2\n",
        "    \n",
        "    # Structure anatomique de base\n",
        "    \n",
        "    # Parenchyme pulmonaire\n",
        "    lung_intensity = 0.3\n",
        "    \n",
        "    # Poumon droit\n",
        "    right_lung_y, right_lung_x = int(0.4 * size), int(0.3 * size)\n",
        "    right_lung_h, right_lung_w = int(0.25 * size), int(0.12 * size)\n",
        "    rr1, cc1 = np.meshgrid(np.arange(size), np.arange(size), indexing='ij')\n",
        "    right_mask = ((rr1 - right_lung_y)**2 / right_lung_h**2 + \n",
        "                 (cc1 - right_lung_x)**2 / right_lung_w**2) <= 1\n",
        "    img[right_mask] = lung_intensity\n",
        "    \n",
        "    # Poumon gauche (légèrement plus petit anatomiquement)\n",
        "    left_lung_y, left_lung_x = int(0.4 * size), int(0.7 * size)\n",
        "    left_lung_h, left_lung_w = int(0.23 * size), int(0.12 * size)\n",
        "    left_mask = ((rr1 - left_lung_y)**2 / left_lung_h**2 + \n",
        "                (cc1 - left_lung_x)**2 / left_lung_w**2) <= 1\n",
        "    img[left_mask] = lung_intensity\n",
        "    \n",
        "    # Silhouette cardiaque (taille variable selon pathologie)\n",
        "    heart_size_factor = 1.0\n",
        "    if pathology_type == 'cardiomegaly':\n",
        "        heart_size_factor = {'mild': 1.3, 'moderate': 1.6, 'severe': 2.0}[severity]\n",
        "    \n",
        "    heart_y, heart_x = int(0.6 * size), int(0.48 * size)\n",
        "    heart_h = int(0.08 * size * heart_size_factor)\n",
        "    heart_w = int(0.1 * size * heart_size_factor)\n",
        "    heart_mask = ((rr1 - heart_y)**2 / heart_h**2 + \n",
        "                 (cc1 - heart_x)**2 / heart_w**2) <= 1\n",
        "    img[heart_mask] = 0.6\n",
        "    \n",
        "    # Rachis et structures médiastinales\n",
        "    spine_width = int(0.02 * size)\n",
        "    img[int(0.1*size):int(0.9*size), center_x-spine_width:center_x+spine_width] = 0.8\n",
        "    \n",
        "    # Gril costal\n",
        "    for rib_level in range(8):\n",
        "        rib_y = int(0.15 * size) + rib_level * int(0.06 * size)\n",
        "        for x in range(int(0.05 * size), int(0.95 * size)):\n",
        "            if x < center_x:\n",
        "                curve = int(0.02 * size * np.sin(np.pi * (x - 0.05 * size) / (0.45 * size)))\n",
        "            else:\n",
        "                curve = int(0.02 * size * np.sin(np.pi * (0.95 * size - x) / (0.45 * size)))\n",
        "            y_rib = rib_y + curve\n",
        "            if 0 <= y_rib < size and 0 <= x < size:\n",
        "                img[y_rib:y_rib+1, x:x+1] = 0.7\n",
        "    \n",
        "    # Pathologies spécifiques\n",
        "    \n",
        "    if pathology_type == 'pneumonia':\n",
        "        # Consolidation pneumonique avec bronchogramme aérique\n",
        "        consolidation_intensity = {'mild': 0.7, 'moderate': 0.8, 'severe': 0.9}[severity]\n",
        "        consolidation_size = {'mild': 0.06, 'moderate': 0.1, 'severe': 0.15}[severity]\n",
        "        \n",
        "        cons_y, cons_x = int(0.35 * size), int(0.25 * size)\n",
        "        cons_h = cons_w = int(consolidation_size * size)\n",
        "        consolidation_mask = ((rr1 - cons_y)**2 / cons_h**2 + \n",
        "                             (cc1 - cons_x)**2 / cons_w**2) <= 1\n",
        "        img[consolidation_mask] = consolidation_intensity\n",
        "        \n",
        "        # Bronchogramme aérique (tubulures aériennes visibles)\n",
        "        for i in range(3):\n",
        "            broncho_y = cons_y + (i-1) * 4\n",
        "            broncho_x_start, broncho_x_end = cons_x - 8, cons_x + 8\n",
        "            img[broncho_y:broncho_y+1, broncho_x_start:broncho_x_end] = 0.4\n",
        "    \n",
        "    elif pathology_type == 'pneumothorax':\n",
        "        # Ligne pleurale avec décollement\n",
        "        pleural_line_x = {'mild': int(0.18 * size), 'moderate': int(0.15 * size), \n",
        "                         'severe': int(0.12 * size)}[severity]\n",
        "        pleural_start_y, pleural_end_y = int(0.2 * size), int(0.7 * size)\n",
        "        \n",
        "        # Ligne de décollement pleural\n",
        "        img[pleural_start_y:pleural_end_y, pleural_line_x:pleural_line_x+2] = 0.95\n",
        "        \n",
        "        # Zone de décollement (hyperclarté pneumothoracique)\n",
        "        img[pleural_start_y:pleural_end_y, int(0.05*size):pleural_line_x] = 0.1\n",
        "        \n",
        "        # Rétraction pulmonaire\n",
        "        retraction_factor = {'mild': 0.8, 'moderate': 0.6, 'severe': 0.4}[severity]\n",
        "        affected_region = img[pleural_start_y:pleural_end_y, pleural_line_x:int(0.5*size)]\n",
        "        img[pleural_start_y:pleural_end_y, pleural_line_x:int(0.5*size)] = affected_region * retraction_factor\n",
        "    \n",
        "    elif pathology_type == 'pleural_effusion':\n",
        "        # Épanchement pleural avec ligne de Damoiseau\n",
        "        effusion_height = {'mild': int(0.12 * size), 'moderate': int(0.2 * size), \n",
        "                          'severe': int(0.3 * size)}[severity]\n",
        "        effusion_start_y = int(0.75 * size) - effusion_height\n",
        "        effusion_end_y = int(0.75 * size)\n",
        "        \n",
        "        # Opacité hydrique homogène\n",
        "        for y in range(effusion_start_y, effusion_end_y):\n",
        "            # Ligne concave caractéristique (signe de Damoiseau)\n",
        "            curve_offset = int(0.04 * size * np.sin(np.pi * (y - effusion_start_y) / effusion_height))\n",
        "            x_limit = int(0.5 * size) - curve_offset\n",
        "            img[y, int(0.1*size):x_limit] = 0.85\n",
        "    \n",
        "    elif pathology_type == 'atelectasis':\n",
        "        # Atélectasie avec déplacement des scissures\n",
        "        atelectasis_intensity = {'mild': 0.65, 'moderate': 0.75, 'severe': 0.85}[severity]\n",
        "        \n",
        "        # Zone atélectasiée\n",
        "        atel_y, atel_x = int(0.3 * size), int(0.3 * size)\n",
        "        atel_h, atel_w = int(0.08 * size), int(0.15 * size)\n",
        "        atelectasis_mask = ((rr1 - atel_y)**2 / atel_h**2 + \n",
        "                           (cc1 - atel_x)**2 / atel_w**2) <= 1\n",
        "        img[atelectasis_mask] = atelectasis_intensity\n",
        "        \n",
        "        # Déplacement des structures adjacentes\n",
        "        displacement = {'mild': 2, 'moderate': 4, 'severe': 6}[severity]\n",
        "        # Simulation simple du déplacement\n",
        "        shifted_region = np.roll(img[int(0.25*size):int(0.4*size), int(0.2*size):int(0.5*size)], \n",
        "                               displacement, axis=1)\n",
        "        img[int(0.25*size):int(0.4*size), int(0.2*size):int(0.5*size)] = shifted_region\n",
        "    \n",
        "    elif pathology_type == 'nodule':\n",
        "        # Nodule pulmonaire\n",
        "        nodule_size = {'mild': 3, 'moderate': 6, 'severe': 10}[severity]\n",
        "        nodule_intensity = 0.8\n",
        "        \n",
        "        # Position aléatoire dans parenchyme pulmonaire\n",
        "        nodule_y = int(0.4 * size) + np.random.randint(-int(0.1*size), int(0.1*size))\n",
        "        nodule_x = int(0.3 * size) + np.random.randint(-int(0.05*size), int(0.05*size))\n",
        "        \n",
        "        nodule_mask = ((rr1 - nodule_y)**2 + (cc1 - nodule_x)**2) <= nodule_size**2\n",
        "        img[nodule_mask] = nodule_intensity\n",
        "        \n",
        "        # Halo éventuel (inflammation périphérique)\n",
        "        if severity == 'severe':\n",
        "            halo_mask = ((rr1 - nodule_y)**2 + (cc1 - nodule_x)**2) <= (nodule_size + 3)**2\n",
        "            halo_mask &= ~nodule_mask\n",
        "            img[halo_mask] = 0.5\n",
        "    \n",
        "    # Post-traitement réaliste\n",
        "    \n",
        "    # Bruit quantique radiographique\n",
        "    noise = np.random.normal(0, 0.03, img.shape)\n",
        "    img += noise\n",
        "    \n",
        "    # Flou de mouvement léger\n",
        "    img = ndimage.gaussian_filter(img, sigma=0.6)\n",
        "    \n",
        "    # Normalisation finale\n",
        "    img = np.clip(img, 0, 1)\n",
        "    \n",
        "    return img\n",
        "\n",
        "# Création de la bibliothèque de cas cliniques\n",
        "clinical_cases = {\n",
        "    'normal': {\n",
        "        'image': create_synthetic_chest_xray('normal'),\n",
        "        'description': 'Radiographie thoracique normale',\n",
        "        'expected_pathologies': [],\n",
        "        'clinical_context': 'Bilan systématique, patient asymptomatique, 35 ans'\n",
        "    },\n",
        "    'pneumonia_lobaire': {\n",
        "        'image': create_synthetic_chest_xray('pneumonia', 'moderate'),\n",
        "        'description': 'Pneumonie lobaire inférieure droite',\n",
        "        'expected_pathologies': ['Pneumonia', 'Infiltration'],\n",
        "        'clinical_context': 'Fièvre 39°C, toux productive purulente, frissons, dyspnée'\n",
        "    },\n",
        "    'cardiomegalie_moderee': {\n",
        "        'image': create_synthetic_chest_xray('cardiomegaly', 'moderate'),\n",
        "        'description': 'Cardiomégalie modérée par insuffisance cardiaque',\n",
        "        'expected_pathologies': ['Cardiomegaly', 'Enlarged Cardiomediastinum'],\n",
        "        'clinical_context': 'Dyspnée d\\'effort NYHA II, œdèmes malléolaires, orthopnée'\n",
        "    },\n",
        "    'pneumothorax_spontane': {\n",
        "        'image': create_synthetic_chest_xray('pneumothorax', 'moderate'),\n",
        "        'description': 'Pneumothorax spontané partiel droit',\n",
        "        'expected_pathologies': ['Pneumothorax'],\n",
        "        'clinical_context': 'Douleur thoracique latérale droite brutale, dyspnée, homme jeune'\n",
        "    },\n",
        "    'epanchement_pleural': {\n",
        "        'image': create_synthetic_chest_xray('pleural_effusion', 'moderate'),\n",
        "        'description': 'Épanchement pleural liquidien abondant',\n",
        "        'expected_pathologies': ['Pleural Effusion'],\n",
        "        'clinical_context': 'Dyspnée progressive, douleur pleurale, matité à la percussion'\n",
        "    },\n",
        "    'atelectasie_lobaire': {\n",
        "        'image': create_synthetic_chest_xray('atelectasis', 'moderate'),\n",
        "        'description': 'Atélectasie lobaire par obstruction bronchique',\n",
        "        'expected_pathologies': ['Atelectasis'],\n",
        "        'clinical_context': 'Toux sèche persistante, dyspnée, antécédents tabagiques'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Bibliothèque de cas cliniques créée: {len(clinical_cases)} cas\")\n",
        "\n",
        "# Visualisation de la bibliothèque\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Bibliothèque de Cas Cliniques - TorchXRayVision', fontsize=16, fontweight='bold')\n",
        "\n",
        "axes = axes.flatten()\n",
        "for i, (case_name, case_data) in enumerate(clinical_cases.items()):\n",
        "    if i < len(axes):\n",
        "        axes[i].imshow(case_data['image'], cmap='gray')\n",
        "        axes[i].set_title(f\"{case_data['description']}\", fontweight='bold', fontsize=11)\n",
        "        axes[i].axis('off')\n",
        "        \n",
        "        # Contexte clinique\n",
        "        axes[i].text(0.02, 0.02, f\"Contexte: {case_data['clinical_context'][:50]}...\", \n",
        "                    transform=axes[i].transAxes, fontsize=8,\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.9),\n",
        "                    verticalalignment='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Cas cliniques prêts pour analyse multi-modèles.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Preprocessing et Classification Multi-Modèles\n",
        "\n",
        "Analysons nos cas cliniques avec tous les modèles disponibles et comparons leurs performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing standardisé et classification multi-modèles\n",
        "print(\"=== PREPROCESSING ET CLASSIFICATION MULTI-MODÈLES ===\")\n",
        "\n",
        "def preprocess_for_xrayvision(image_array):\n",
        "    \"\"\"\n",
        "    Preprocessing standardisé pour TorchXRayVision\n",
        "    \"\"\"\n",
        "    # Normalisation\n",
        "    if image_array.max() > 1:\n",
        "        img_norm = xrv.datasets.normalize(image_array, 255)\n",
        "    else:\n",
        "        img_norm = image_array\n",
        "    \n",
        "    # Ajout dimension canal\n",
        "    img_channel = img_norm[None, ...]\n",
        "    \n",
        "    # Transformations TorchXRayVision\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        xrv.datasets.XRayCenterCrop(),\n",
        "        xrv.datasets.XRayResizer(224)\n",
        "    ])\n",
        "    \n",
        "    img_transformed = transform(img_channel)\n",
        "    \n",
        "    # Conversion en tenseur PyTorch\n",
        "    img_tensor = torch.from_numpy(img_transformed).float()\n",
        "    img_batch = img_tensor.unsqueeze(0)\n",
        "    \n",
        "    return img_batch, img_transformed\n",
        "\n",
        "def classify_with_all_models(image_tensor, models_dict, pathologies, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Classification avec tous les modèles disponibles\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    for model_name, model in models_dict.items():\n",
        "        model.eval()\n",
        "        image_tensor_device = image_tensor.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(image_tensor_device)\n",
        "            probabilities = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
        "            \n",
        "            # Détections positives\n",
        "            positive_indices = np.where(probabilities > threshold)[0]\n",
        "            positive_findings = [(pathologies[i], probabilities[i]) for i in positive_indices]\n",
        "            \n",
        "            # Stockage des résultats\n",
        "            results[model_name] = {\n",
        "                'probabilities': probabilities,\n",
        "                'positive_findings': positive_findings,\n",
        "                'max_probability': np.max(probabilities),\n",
        "                'mean_probability': np.mean(probabilities),\n",
        "                'num_detections': len(positive_findings)\n",
        "            }\n",
        "    \n",
        "    return results\n",
        "\n",
        "def analyze_model_consensus(case_results, expected_pathologies):\n",
        "    \"\"\"\n",
        "    Analyse du consensus entre modèles\n",
        "    \"\"\"\n",
        "    # Collecte de toutes les détections\n",
        "    all_detections = {}\n",
        "    \n",
        "    for model_name, result in case_results.items():\n",
        "        for pathology, prob in result['positive_findings']:\n",
        "            if pathology not in all_detections:\n",
        "                all_detections[pathology] = []\n",
        "            all_detections[pathology].append((model_name, prob))\n",
        "    \n",
        "    # Calcul du consensus\n",
        "    consensus_findings = []\n",
        "    for pathology, detections in all_detections.items():\n",
        "        consensus_level = len(detections) / len(case_results)\n",
        "        avg_probability = np.mean([prob for _, prob in detections])\n",
        "        \n",
        "        consensus_findings.append({\n",
        "            'pathology': pathology,\n",
        "            'consensus_level': consensus_level,\n",
        "            'avg_probability': avg_probability,\n",
        "            'detecting_models': [model for model, _ in detections],\n",
        "            'num_models': len(detections)\n",
        "        })\n",
        "    \n",
        "    # Tri par niveau de consensus\n",
        "    consensus_findings.sort(key=lambda x: (x['consensus_level'], x['avg_probability']), reverse=True)\n",
        "    \n",
        "    # Évaluation par rapport aux pathologies attendues\n",
        "    evaluation = {\n",
        "        'true_positives': 0,\n",
        "        'false_positives': 0,\n",
        "        'false_negatives': len(expected_pathologies),\n",
        "        'detected_expected': [],\n",
        "        'missed_expected': expected_pathologies.copy(),\n",
        "        'unexpected_detections': []\n",
        "    }\n",
        "    \n",
        "    for finding in consensus_findings:\n",
        "        pathology = finding['pathology']\n",
        "        is_expected = any(exp.lower() in pathology.lower() or \n",
        "                         pathology.lower() in exp.lower() \n",
        "                         for exp in expected_pathologies)\n",
        "        \n",
        "        if is_expected:\n",
        "            evaluation['true_positives'] += 1\n",
        "            evaluation['false_negatives'] -= 1\n",
        "            evaluation['detected_expected'].append(pathology)\n",
        "            # Retirer de missed_expected\n",
        "            for exp in expected_pathologies:\n",
        "                if exp.lower() in pathology.lower() or pathology.lower() in exp.lower():\n",
        "                    if exp in evaluation['missed_expected']:\n",
        "                        evaluation['missed_expected'].remove(exp)\n",
        "                    break\n",
        "        else:\n",
        "            evaluation['false_positives'] += 1\n",
        "            evaluation['unexpected_detections'].append(pathology)\n",
        "    \n",
        "    return consensus_findings, evaluation\n",
        "\n",
        "# Analyse de tous les cas cliniques\n",
        "print(\"\\nAnalyse en cours de tous les cas cliniques...\")\n",
        "\n",
        "comprehensive_analysis = {}\n",
        "\n",
        "if models_dict and pathologies:\n",
        "    for case_name, case_data in clinical_cases.items():\n",
        "        print(f\"\\nAnalyse du cas: {case_name}\")\n",
        "        \n",
        "        # Preprocessing\n",
        "        processed_tensor, processed_display = preprocess_for_xrayvision(case_data['image'])\n",
        "        \n",
        "        # Classification multi-modèles\n",
        "        case_results = classify_with_all_models(processed_tensor, models_dict, pathologies)\n",
        "        \n",
        "        # Analyse du consensus\n",
        "        consensus_findings, evaluation = analyze_model_consensus(\n",
        "            case_results, case_data['expected_pathologies']\n",
        "        )\n",
        "        \n",
        "        # Stockage des résultats\n",
        "        comprehensive_analysis[case_name] = {\n",
        "            'case_info': case_data,\n",
        "            'processed_image': processed_display,\n",
        "            'model_results': case_results,\n",
        "            'consensus': consensus_findings,\n",
        "            'evaluation': evaluation\n",
        "        }\n",
        "        \n",
        "        # Affichage des résultats principaux\n",
        "        print(f\"  Description: {case_data['description']}\")\n",
        "        print(f\"  Pathologies attendues: {case_data['expected_pathologies']}\")\n",
        "        print(f\"  Consensus détections (>50% modèles):\")\n",
        "        \n",
        "        high_consensus = [f for f in consensus_findings if f['consensus_level'] > 0.5]\n",
        "        if high_consensus:\n",
        "            for finding in high_consensus[:3]:  # Top 3\n",
        "                print(f\"    • {finding['pathology']}: {finding['consensus_level']*100:.0f}% modèles, prob={finding['avg_probability']:.3f}\")\n",
        "        else:\n",
        "            print(f\"    • Aucune détection consensuelle\")\n",
        "        \n",
        "        print(f\"  Évaluation: TP={evaluation['true_positives']}, FP={evaluation['false_positives']}, FN={evaluation['false_negatives']}\")\n",
        "    \n",
        "    print(f\"\\nAnalyse complétée pour {len(comprehensive_analysis)} cas.\")\n",
        "else:\n",
        "    print(\"Erreur: Modèles ou pathologies non disponibles\")\n",
        "    comprehensive_analysis = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Localisation Spatiale avec Grad-CAM\n",
        "\n",
        "Utilisons Grad-CAM pour visualiser les régions importantes identifiées par les modèles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implémentation de Grad-CAM pour localisation spatiale\n",
        "print(\"=== LOCALISATION SPATIALE AVEC GRAD-CAM ===\")\n",
        "\n",
        "class GradCAM:\n",
        "    \"\"\"\n",
        "    Implémentation de Gradient-weighted Class Activation Mapping (Grad-CAM)\n",
        "    pour localisation des pathologies dans les radiographies\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model, target_layer_name='features'):\n",
        "        self.model = model\n",
        "        self.target_layer_name = target_layer_name\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "        \n",
        "        # Enregistrement des hooks\n",
        "        self.hook_layers()\n",
        "    \n",
        "    def hook_layers(self):\n",
        "        \"\"\"\n",
        "        Enregistre les hooks pour capturer gradients et activations\n",
        "        \"\"\"\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients = grad_output[0]\n",
        "        \n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations = output\n",
        "        \n",
        "        # Recherche de la couche cible\n",
        "        target_layer = None\n",
        "        for name, module in self.model.named_modules():\n",
        "            if self.target_layer_name in name:\n",
        "                target_layer = module\n",
        "                break\n",
        "        \n",
        "        if target_layer is None:\n",
        "            # Fallback: utiliser la dernière couche convolutionnelle\n",
        "            for name, module in reversed(list(self.model.named_modules())):\n",
        "                if isinstance(module, torch.nn.Conv2d):\n",
        "                    target_layer = module\n",
        "                    break\n",
        "        \n",
        "        if target_layer is not None:\n",
        "            target_layer.register_forward_hook(forward_hook)\n",
        "            target_layer.register_full_backward_hook(backward_hook)\n",
        "    \n",
        "    def generate_cam(self, input_image, class_idx=None):\n",
        "        \"\"\"\n",
        "        Génère la carte d'activation pour une classe spécifique\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        input_image = input_image.requires_grad_()\n",
        "        \n",
        "        # Forward pass\n",
        "        output = self.model(input_image)\n",
        "        \n",
        "        # Si classe non spécifiée, prendre celle avec probabilité max\n",
        "        if class_idx is None:\n",
        "            class_idx = torch.argmax(torch.sigmoid(output), dim=1)\n",
        "        \n",
        "        # Backward pass\n",
        "        self.model.zero_grad()\n",
        "        class_score = output[0, class_idx]\n",
        "        class_score.backward(retain_graph=True)\n",
        "        \n",
        "        # Génération de la carte Grad-CAM\n",
        "        if self.gradients is not None and self.activations is not None:\n",
        "            # Moyennage spatial des gradients\n",
        "            alpha = torch.mean(self.gradients, dim=[2, 3], keepdim=True)\n",
        "            \n",
        "            # Combinaison pondérée des cartes d'activation\n",
        "            cam = torch.sum(alpha * self.activations, dim=1, keepdim=True)\n",
        "            \n",
        "            # Application de ReLU\n",
        "            cam = torch.clamp(cam, min=0)\n",
        "            \n",
        "            # Normalisation\n",
        "            cam = cam / (torch.max(cam) + 1e-8)\n",
        "            \n",
        "            # Redimensionnement à la taille de l'image d'entrée\n",
        "            cam_resized = torch.nn.functional.interpolate(\n",
        "                cam, size=input_image.shape[2:], mode='bilinear', align_corners=False\n",
        "            )\n",
        "            \n",
        "            return cam_resized.squeeze().cpu().numpy()\n",
        "        \n",
        "        return None\n",
        "\n",
        "def generate_gradcam_visualization(model, image_tensor, pathologies, top_k=3):\n",
        "    \"\"\"\n",
        "    Génère les visualisations Grad-CAM pour les pathologies les plus probables\n",
        "    \"\"\"\n",
        "    # Prédiction pour identifier les pathologies principales\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor.to(device))\n",
        "        probabilities = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
        "    \n",
        "    # Sélection des pathologies les plus probables\n",
        "    top_indices = np.argsort(probabilities)[-top_k:][::-1]\n",
        "    \n",
        "    # Génération des cartes Grad-CAM\n",
        "    gradcam = GradCAM(model)\n",
        "    cam_results = []\n",
        "    \n",
        "    for idx in top_indices:\n",
        "        pathology = pathologies[idx]\n",
        "        probability = probabilities[idx]\n",
        "        \n",
        "        # Génération de la carte CAM\n",
        "        cam_map = gradcam.generate_cam(image_tensor.to(device), class_idx=idx)\n",
        "        \n",
        "        if cam_map is not None:\n",
        "            cam_results.append({\n",
        "                'pathology': pathology,\n",
        "                'probability': probability,\n",
        "                'cam_map': cam_map,\n",
        "                'class_idx': idx\n",
        "            })\n",
        "    \n",
        "    return cam_results\n",
        "\n",
        "def visualize_gradcam_results(image, cam_results, title=\"Localisation Grad-CAM\"):\n",
        "    \"\"\"\n",
        "    Visualise les résultats Grad-CAM\n",
        "    \"\"\"\n",
        "    num_results = len(cam_results)\n",
        "    if num_results == 0:\n",
        "        print(\"Aucun résultat Grad-CAM à afficher\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(1, num_results + 1, figsize=(4 * (num_results + 1), 4))\n",
        "    if num_results == 0:\n",
        "        axes = [axes]\n",
        "    \n",
        "    # Image originale\n",
        "    axes[0].imshow(image, cmap='gray')\n",
        "    axes[0].set_title('Image Originale', fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Cartes Grad-CAM\n",
        "    for i, result in enumerate(cam_results):\n",
        "        # Superposition de la carte CAM sur l'image\n",
        "        axes[i + 1].imshow(image, cmap='gray', alpha=0.7)\n",
        "        \n",
        "        # Carte de chaleur\n",
        "        im = axes[i + 1].imshow(result['cam_map'], cmap='jet', alpha=0.6, \n",
        "                               vmin=0, vmax=1)\n",
        "        \n",
        "        # Titre avec pathologie et probabilité\n",
        "        prob_percent = result['probability'] * 100\n",
        "        status = \"DÉTECTÉ\" if result['probability'] > 0.5 else \"Faible prob.\"\n",
        "        color = 'red' if result['probability'] > 0.5 else 'orange'\n",
        "        \n",
        "        axes[i + 1].set_title(\n",
        "            f\"{result['pathology']}\\n{prob_percent:.1f}% - {status}\", \n",
        "            fontweight='bold', color=color, fontsize=10\n",
        "        )\n",
        "        axes[i + 1].axis('off')\n",
        "        \n",
        "        # Colorbar pour la première carte\n",
        "        if i == 0:\n",
        "            plt.colorbar(im, ax=axes[i + 1], fraction=0.046, pad=0.04, label='Importance')\n",
        "    \n",
        "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Génération des visualisations Grad-CAM pour les cas cliniques\n",
        "print(\"\\nGénération des cartes de localisation Grad-CAM...\")\n",
        "\n",
        "if comprehensive_analysis and models_dict:\n",
        "    # Sélection de quelques cas représentatifs\n",
        "    selected_cases = ['pneumonia_lobaire', 'cardiomegalie_moderee', 'pneumothorax_spontane']\n",
        "    \n",
        "    for case_name in selected_cases:\n",
        "        if case_name in comprehensive_analysis:\n",
        "            case_data = comprehensive_analysis[case_name]\n",
        "            processed_image = case_data['processed_image'][0]  # Premier canal\n",
        "            \n",
        "            print(f\"\\nGrad-CAM pour le cas: {case_data['case_info']['description']}\")\n",
        "            \n",
        "            # Utilisation du premier modèle disponible pour Grad-CAM\n",
        "            model_name = list(models_dict.keys())[0]\n",
        "            model = models_dict[model_name]\n",
        "            \n",
        "            # Reconstruction du tenseur pour Grad-CAM\n",
        "            image_tensor = torch.from_numpy(case_data['processed_image']).float().unsqueeze(0)\n",
        "            \n",
        "            try:\n",
        "                # Génération Grad-CAM\n",
        "                cam_results = generate_gradcam_visualization(\n",
        "                    model, image_tensor, pathologies, top_k=3\n",
        "                )\n",
        "                \n",
        "                if cam_results:\n",
        "                    # Visualisation\n",
        "                    visualize_gradcam_results(\n",
        "                        processed_image, cam_results, \n",
        "                        f\"Localisation - {case_data['case_info']['description']}\"\n",
        "                    )\n",
        "                    \n",
        "                    print(f\"  Régions d'intérêt détectées:\")\n",
        "                    for result in cam_results:\n",
        "                        if result['probability'] > 0.3:\n",
        "                            print(f\"    • {result['pathology']}: {result['probability']*100:.1f}%\")\n",
        "                else:\n",
        "                    print(f\"  Aucune localisation générée\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  Erreur Grad-CAM: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"Données d'analyse ou modèles non disponibles pour Grad-CAM\")\n",
        "\n",
        "print(\"\\nLocalisation spatiale terminée.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Métriques de Performance et Comparaison de Modèles\n",
        "\n",
        "Analysons en détail les performances des différents modèles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcul des métriques de performance détaillées\n",
        "print(\"=== MÉTRIQUES DE PERFORMANCE ET COMPARAISON ===\")\n",
        "\n",
        "def calculate_model_performance(comprehensive_analysis, models_info):\n",
        "    \"\"\"\n",
        "    Calcule les métriques de performance pour chaque modèle\n",
        "    \"\"\"\n",
        "    performance_metrics = {}\n",
        "    \n",
        "    # Initialisation des métriques par modèle\n",
        "    for model_name in models_info.keys():\n",
        "        performance_metrics[model_name] = {\n",
        "            'true_positives': 0,\n",
        "            'false_positives': 0,\n",
        "            'false_negatives': 0,\n",
        "            'total_detections': 0,\n",
        "            'total_cases': 0,\n",
        "            'probability_stats': {\n",
        "                'max_probs': [],\n",
        "                'mean_probs': [],\n",
        "                'all_probs': []\n",
        "            },\n",
        "            'case_performances': []\n",
        "        }\n",
        "    \n",
        "    # Calcul pour chaque cas\n",
        "    for case_name, analysis in comprehensive_analysis.items():\n",
        "        expected = analysis['case_info']['expected_pathologies']\n",
        "        evaluation = analysis['evaluation']\n",
        "        model_results = analysis['model_results']\n",
        "        \n",
        "        for model_name, result in model_results.items():\n",
        "            if model_name in performance_metrics:\n",
        "                metrics = performance_metrics[model_name]\n",
        "                \n",
        "                # Métriques de classification\n",
        "                detected_pathologies = [p[0] for p in result['positive_findings']]\n",
        "                \n",
        "                # Calcul TP, FP, FN pour ce cas\n",
        "                case_tp = 0\n",
        "                case_fp = len(detected_pathologies)\n",
        "                case_fn = len(expected)\n",
        "                \n",
        "                for exp_path in expected:\n",
        "                    for det_path in detected_pathologies:\n",
        "                        if (exp_path.lower() in det_path.lower() or \n",
        "                            det_path.lower() in exp_path.lower()):\n",
        "                            case_tp += 1\n",
        "                            case_fp -= 1\n",
        "                            case_fn -= 1\n",
        "                            break\n",
        "                \n",
        "                # Accumulation des métriques\n",
        "                metrics['true_positives'] += case_tp\n",
        "                metrics['false_positives'] += max(0, case_fp)\n",
        "                metrics['false_negatives'] += max(0, case_fn)\n",
        "                metrics['total_detections'] += result['num_detections']\n",
        "                metrics['total_cases'] += 1\n",
        "                \n",
        "                # Statistiques de probabilité\n",
        "                metrics['probability_stats']['max_probs'].append(result['max_probability'])\n",
        "                metrics['probability_stats']['mean_probs'].append(result['mean_probability'])\n",
        "                metrics['probability_stats']['all_probs'].extend(result['probabilities'])\n",
        "                \n",
        "                # Performance par cas\n",
        "                metrics['case_performances'].append({\n",
        "                    'case_name': case_name,\n",
        "                    'tp': case_tp,\n",
        "                    'fp': max(0, case_fp),\n",
        "                    'fn': max(0, case_fn),\n",
        "                    'detections': result['num_detections'],\n",
        "                    'max_prob': result['max_probability']\n",
        "                })\n",
        "    \n",
        "    # Calcul des métriques finales\n",
        "    final_metrics = {}\n",
        "    \n",
        "    for model_name, metrics in performance_metrics.items():\n",
        "        tp = metrics['true_positives']\n",
        "        fp = metrics['false_positives']\n",
        "        fn = metrics['false_negatives']\n",
        "        \n",
        "        # Métriques de classification\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        \n",
        "        # Statistiques de probabilité\n",
        "        prob_stats = metrics['probability_stats']\n",
        "        \n",
        "        final_metrics[model_name] = {\n",
        "            'model_info': models_info[model_name],\n",
        "            'classification_metrics': {\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1_score': f1_score,\n",
        "                'true_positives': tp,\n",
        "                'false_positives': fp,\n",
        "                'false_negatives': fn\n",
        "            },\n",
        "            'detection_stats': {\n",
        "                'avg_detections_per_case': metrics['total_detections'] / metrics['total_cases'],\n",
        "                'total_detections': metrics['total_detections'],\n",
        "                'total_cases': metrics['total_cases']\n",
        "            },\n",
        "            'probability_statistics': {\n",
        "                'max_prob_mean': np.mean(prob_stats['max_probs']),\n",
        "                'max_prob_std': np.std(prob_stats['max_probs']),\n",
        "                'mean_prob_overall': np.mean(prob_stats['all_probs']),\n",
        "                'prob_above_threshold': np.sum(np.array(prob_stats['all_probs']) > 0.5) / len(prob_stats['all_probs'])\n",
        "            },\n",
        "            'case_performances': metrics['case_performances']\n",
        "        }\n",
        "    \n",
        "    return final_metrics\n",
        "\n",
        "def create_performance_comparison_visualizations(final_metrics):\n",
        "    \"\"\"\n",
        "    Crée des visualisations de comparaison de performance\n",
        "    \"\"\"\n",
        "    if not final_metrics:\n",
        "        print(\"Aucune métrique disponible pour visualisation\")\n",
        "        return\n",
        "    \n",
        "    model_names = list(final_metrics.keys())\n",
        "    model_labels = [final_metrics[name]['model_info']['name'] for name in model_names]\n",
        "    \n",
        "    # Extraction des métriques\n",
        "    precisions = [final_metrics[name]['classification_metrics']['precision'] for name in model_names]\n",
        "    recalls = [final_metrics[name]['classification_metrics']['recall'] for name in model_names]\n",
        "    f1_scores = [final_metrics[name]['classification_metrics']['f1_score'] for name in model_names]\n",
        "    avg_detections = [final_metrics[name]['detection_stats']['avg_detections_per_case'] for name in model_names]\n",
        "    \n",
        "    # Création de la figure comparative\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Comparaison de Performance - Modèles TorchXRayVision', \n",
        "                fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Métriques de classification\n",
        "    x_pos = np.arange(len(model_labels))\n",
        "    width = 0.25\n",
        "    \n",
        "    axes[0, 0].bar(x_pos - width, precisions, width, label='Précision', alpha=0.8, color='lightblue')\n",
        "    axes[0, 0].bar(x_pos, recalls, width, label='Rappel', alpha=0.8, color='lightgreen')\n",
        "    axes[0, 0].bar(x_pos + width, f1_scores, width, label='F1-Score', alpha=0.8, color='lightcoral')\n",
        "    \n",
        "    axes[0, 0].set_xticks(x_pos)\n",
        "    axes[0, 0].set_xticklabels(model_labels, rotation=45, ha='right')\n",
        "    axes[0, 0].set_ylabel('Score')\n",
        "    axes[0, 0].set_title('Métriques de Classification')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].set_ylim(0, 1)\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Détections moyennes par cas\n",
        "    axes[0, 1].bar(model_labels, avg_detections, alpha=0.8, color='gold')\n",
        "    axes[0, 1].set_title('Détections Moyennes par Cas')\n",
        "    axes[0, 1].set_ylabel('Nombre de Détections')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Ajout des valeurs sur les barres\n",
        "    for i, v in enumerate(avg_detections):\n",
        "        axes[0, 1].text(i, v + 0.1, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    # 3. Matrice de confusion agrégée\n",
        "    confusion_data = []\n",
        "    for model_name in model_names:\n",
        "        metrics = final_metrics[model_name]['classification_metrics']\n",
        "        tp = metrics['true_positives']\n",
        "        fp = metrics['false_positives']\n",
        "        fn = metrics['false_negatives']\n",
        "        confusion_data.append([tp, fp, fn])\n",
        "    \n",
        "    confusion_array = np.array(confusion_data)\n",
        "    \n",
        "    im = axes[1, 0].imshow(confusion_array.T, cmap='Blues', aspect='auto')\n",
        "    axes[1, 0].set_xticks(range(len(model_labels)))\n",
        "    axes[1, 0].set_xticklabels(model_labels, rotation=45, ha='right')\n",
        "    axes[1, 0].set_yticks(range(3))\n",
        "    axes[1, 0].set_yticklabels(['Vrais Positifs', 'Faux Positifs', 'Faux Négatifs'])\n",
        "    axes[1, 0].set_title('Matrice de Confusion Agrégée')\n",
        "    \n",
        "    # Valeurs dans la matrice\n",
        "    for i in range(len(model_labels)):\n",
        "        for j in range(3):\n",
        "            axes[1, 0].text(i, j, int(confusion_array[i, j]), ha=\"center\", va=\"center\", \n",
        "                           color=\"white\", fontweight='bold')\n",
        "    \n",
        "    # 4. Radar plot des performances\n",
        "    categories = ['Précision', 'Rappel', 'F1-Score']\n",
        "    \n",
        "    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)\n",
        "    angles = np.concatenate((angles, [angles[0]]))  # Fermer le radar\n",
        "    \n",
        "    ax_radar = plt.subplot(2, 2, 4, projection='polar')\n",
        "    \n",
        "    colors = ['blue', 'red', 'green', 'orange'][:len(model_names)]\n",
        "    \n",
        "    for i, model_name in enumerate(model_names):\n",
        "        values = [precisions[i], recalls[i], f1_scores[i]]\n",
        "        values += values[:1]  # Fermer le radar\n",
        "        \n",
        "        ax_radar.plot(angles, values, 'o-', linewidth=2, label=model_labels[i], color=colors[i])\n",
        "        ax_radar.fill(angles, values, alpha=0.25, color=colors[i])\n",
        "    \n",
        "    ax_radar.set_xticks(angles[:-1])\n",
        "    ax_radar.set_xticklabels(categories)\n",
        "    ax_radar.set_ylim(0, 1)\n",
        "    ax_radar.set_title('Profil de Performance', y=1.08)\n",
        "    ax_radar.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
        "    ax_radar.grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Calcul des métriques de performance\n",
        "if comprehensive_analysis:\n",
        "    print(\"\\nCalcul des métriques de performance...\")\n",
        "    \n",
        "    final_metrics = calculate_model_performance(comprehensive_analysis, models_info)\n",
        "    \n",
        "    # Affichage des résultats textuels\n",
        "    print(\"\\nRésumé des performances:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for model_name, metrics in final_metrics.items():\n",
        "        model_info = metrics['model_info']\n",
        "        class_metrics = metrics['classification_metrics']\n",
        "        detection_stats = metrics['detection_stats']\n",
        "        prob_stats = metrics['probability_statistics']\n",
        "        \n",
        "        print(f\"\\n{model_info['name']} ({model_info['description']}):\")\n",
        "        print(f\"  Classification:\")\n",
        "        print(f\"    • Précision: {class_metrics['precision']:.3f}\")\n",
        "        print(f\"    • Rappel: {class_metrics['recall']:.3f}\")\n",
        "        print(f\"    • F1-Score: {class_metrics['f1_score']:.3f}\")\n",
        "        print(f\"  Détections:\")\n",
        "        print(f\"    • Moyenne par cas: {detection_stats['avg_detections_per_case']:.1f}\")\n",
        "        print(f\"    • Probabilité max moyenne: {prob_stats['max_prob_mean']:.3f}\")\n",
        "        print(f\"    • % probabilités > 50%: {prob_stats['prob_above_threshold']*100:.1f}%\")\n",
        "    \n",
        "    # Identification du meilleur modèle\n",
        "    best_f1 = max(final_metrics.items(), key=lambda x: x[1]['classification_metrics']['f1_score'])\n",
        "    best_precision = max(final_metrics.items(), key=lambda x: x[1]['classification_metrics']['precision'])\n",
        "    best_recall = max(final_metrics.items(), key=lambda x: x[1]['classification_metrics']['recall'])\n",
        "    \n",
        "    print(f\"\\n=== RECOMMANDATIONS CLINIQUES ===\")\n",
        "    print(f\"Meilleur F1-Score (équilibré): {final_metrics[best_f1[0]]['model_info']['name']}\")\n",
        "    print(f\"Meilleure précision (éviter faux positifs): {final_metrics[best_precision[0]]['model_info']['name']}\")\n",
        "    print(f\"Meilleur rappel (dépistage sensible): {final_metrics[best_recall[0]]['model_info']['name']}\")\n",
        "    \n",
        "    # Création des visualisations\n",
        "    create_performance_comparison_visualizations(final_metrics)\n",
        "    \n",
        "else:\n",
        "    print(\"Aucune analyse disponible pour le calcul de métriques\")\n",
        "\n",
        "print(\"\\nAnalyse de performance terminée.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Génération Automatique de Rapports Cliniques\n",
        "\n",
        "Créons un système de génération automatique de rapports radiologiques structurés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Système de génération automatique de rapports cliniques\n",
        "print(\"=== GÉNÉRATION AUTOMATIQUE DE RAPPORTS CLINIQUES ===\")\n",
        "\n",
        "class ClinicalReportGenerator:\n",
        "    \"\"\"\n",
        "    Générateur de rapports radiologiques automatisés\n",
        "    basé sur les résultats de classification TorchXRayVision\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, pathology_descriptions=None):\n",
        "        self.pathology_descriptions = pathology_descriptions or self._default_descriptions()\n",
        "        self.clinical_recommendations = self._default_recommendations()\n",
        "    \n",
        "    def _default_descriptions(self):\n",
        "        \"\"\"\n",
        "        Descriptions standardisées des pathologies\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'Atelectasis': 'Atélectasie - Collapsus alvéolaire avec perte de volume pulmonaire',\n",
        "            'Cardiomegaly': 'Cardiomégalie - Augmentation de la silhouette cardiaque',\n",
        "            'Effusion': 'Épanchement pleural - Collection liquidienne dans l\\'espace pleural',\n",
        "            'Infiltration': 'Infiltrat pulmonaire - Opacités parenchymateuses diffuses',\n",
        "            'Mass': 'Masse pulmonaire - Lésion focale de grande taille',\n",
        "            'Nodule': 'Nodule pulmonaire - Lésion arrondie bien délimitée',\n",
        "            'Pneumonia': 'Pneumonie - Consolidation alvéolaire d\\'origine infectieuse',\n",
        "            'Pneumothorax': 'Pneumothorax - Présence d\\'air dans l\\'espace pleural',\n",
        "            'Consolidation': 'Consolidation - Comblement alvéolaire avec bronchogramme aérique',\n",
        "            'Edema': 'Œdème pulmonaire - Accumulation de liquide dans les alvéoles',\n",
        "            'Emphysema': 'Emphysème - Destruction des parois alvéolaires',\n",
        "            'Fibrosis': 'Fibrose pulmonaire - Épaississement cicatriciel du parenchyme',\n",
        "            'Pleural Thickening': 'Épaississement pleural - Fibrose de la plèvre pariétale',\n",
        "            'Hernia': 'Hernie - Déplacement d\\'organes à travers un orifice'\n",
        "        }\n",
        "    \n",
        "    def _default_recommendations(self):\n",
        "        \"\"\"\n",
        "        Recommandations cliniques par pathologie\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'Pneumonia': {\n",
        "                'urgency': 'Modérée à élevée',\n",
        "                'follow_up': 'Contrôle radiologique à 48-72h sous traitement',\n",
        "                'specialty': 'Pneumologie si évolution défavorable',\n",
        "                'additional_tests': 'Hémocultures, ECBU si fièvre, CRP, PCT'\n",
        "            },\n",
        "            'Pneumothorax': {\n",
        "                'urgency': 'Élevée',\n",
        "                'follow_up': 'Surveillance clinique rapprochée, contrôle radiologique',\n",
        "                'specialty': 'Pneumologie en urgence si > 20%',\n",
        "                'additional_tests': 'Gazométrie artérielle si détresse respiratoire'\n",
        "            },\n",
        "            'Cardiomegaly': {\n",
        "                'urgency': 'Modérée',\n",
        "                'follow_up': 'Échocardiographie, contrôle à 3 mois',\n",
        "                'specialty': 'Cardiologie pour bilan étiologique',\n",
        "                'additional_tests': 'ECG, BNP, bilan biologique cardiaque'\n",
        "            },\n",
        "            'Mass': {\n",
        "                'urgency': 'Élevée',\n",
        "                'follow_up': 'Scanner thoracique avec injection urgente',\n",
        "                'specialty': 'Pneumologie/Oncologie pour RCP',\n",
        "                'additional_tests': 'Marqueurs tumoraux, fibroscopie bronchique'\n",
        "            },\n",
        "            'Nodule': {\n",
        "                'urgency': 'Modérée',\n",
        "                'follow_up': 'Scanner thoracique, contrôle selon taille',\n",
        "                'specialty': 'Pneumologie pour caractérisation',\n",
        "                'additional_tests': 'TEP-scan si nodule > 8mm'\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def generate_structured_report(self, case_analysis, patient_info=None):\n",
        "        \"\"\"\n",
        "        Génère un rapport radiologique structuré\n",
        "        \"\"\"\n",
        "        case_info = case_analysis['case_info']\n",
        "        consensus = case_analysis['consensus']\n",
        "        evaluation = case_analysis['evaluation']\n",
        "        \n",
        "        # En-tête du rapport\n",
        "        report = self._generate_header(patient_info)\n",
        "        \n",
        "        # Technique d'examen\n",
        "        report += self._generate_technique_section()\n",
        "        \n",
        "        # Résultats\n",
        "        report += self._generate_findings_section(consensus, evaluation)\n",
        "        \n",
        "        # Impression\n",
        "        report += self._generate_impression_section(consensus)\n",
        "        \n",
        "        # Recommandations\n",
        "        report += self._generate_recommendations_section(consensus)\n",
        "        \n",
        "        # Signature\n",
        "        report += self._generate_signature_section()\n",
        "        \n",
        "        return report\n",
        "    \n",
        "    def _generate_header(self, patient_info):\n",
        "        \"\"\"\n",
        "        Génère l'en-tête du rapport\n",
        "        \"\"\"\n",
        "        from datetime import datetime\n",
        "        \n",
        "        patient_id = patient_info.get('id', 'DEMO-001') if patient_info else 'DEMO-001'\n",
        "        patient_name = patient_info.get('name', 'Patient Démonstration') if patient_info else 'Patient Démonstration'\n",
        "        \n",
        "        return f\"\"\"\n",
        "RAPPORT RADIOLOGIQUE\n",
        "====================================\n",
        "\n",
        "Patient: {patient_name}\n",
        "ID: {patient_id}\n",
        "Examen: Radiographie thoracique de face\n",
        "Date: {datetime.now().strftime('%d/%m/%Y')}\n",
        "Heure: {datetime.now().strftime('%H:%M')}\n",
        "\n",
        "Système d'analyse: TorchXRayVision (IA)\n",
        "Statut: RAPPORT AUTOMATISÉ - Validation médicale requise\n",
        "\n",
        "\"\"\"\n",
        "    \n",
        "    def _generate_technique_section(self):\n",
        "        \"\"\"\n",
        "        Section technique\n",
        "        \"\"\"\n",
        "        return \"\"\"\n",
        "TECHNIQUE:\n",
        "Radiographie thoracique numérique de face en position debout.\n",
        "Inspiration correcte, positionnement satisfaisant.\n",
        "Analyse par intelligence artificielle avec modèles DenseNet.\n",
        "\n",
        "\"\"\"\n",
        "    \n",
        "    def _generate_findings_section(self, consensus, evaluation):\n",
        "        \"\"\"\n",
        "        Section des résultats\n",
        "        \"\"\"\n",
        "        findings = \"RÉSULTATS:\\n\"\n",
        "        \n",
        "        if not consensus or len(consensus) == 0:\n",
        "            findings += \"Examen dans les limites de la normale.\\n\"\n",
        "            findings += \"Aucune anomalie significative détectée par l'analyse IA.\\n\"\n",
        "        else:\n",
        "            findings += \"Anomalies détectées par analyse IA:\\n\\n\"\n",
        "            \n",
        "            for i, finding in enumerate(consensus[:5], 1):  # Top 5 findings\n",
        "                pathology = finding['pathology']\n",
        "                consensus_level = finding['consensus_level']\n",
        "                avg_prob = finding['avg_probability']\n",
        "                \n",
        "                # Description de la pathologie\n",
        "                description = self.pathology_descriptions.get(\n",
        "                    pathology, f\"Anomalie détectée: {pathology}\"\n",
        "                )\n",
        "                \n",
        "                # Niveau de confiance\n",
        "                if consensus_level >= 0.8:\n",
        "                    confidence = \"Confiance élevée\"\n",
        "                elif consensus_level >= 0.5:\n",
        "                    confidence = \"Confiance modérée\"\n",
        "                else:\n",
        "                    confidence = \"Confiance limitée\"\n",
        "                \n",
        "                findings += f\"{i}. {description}\\n\"\n",
        "                findings += f\"   - Probabilité: {avg_prob:.1%}\\n\"\n",
        "                findings += f\"   - Consensus inter-modèles: {consensus_level:.1%}\\n\"\n",
        "                findings += f\"   - {confidence}\\n\\n\"\n",
        "        \n",
        "        # Évaluation de performance\n",
        "        if evaluation['detected_expected']:\n",
        "            findings += \"Concordance avec attentes cliniques:\\n\"\n",
        "            for detected in evaluation['detected_expected']:\n",
        "                findings += f\"✓ {detected}\\n\"\n",
        "        \n",
        "        if evaluation['missed_expected']:\n",
        "            findings += \"\\nPathologies attendues non détectées:\\n\"\n",
        "            for missed in evaluation['missed_expected']:\n",
        "                findings += f\"? {missed} (possibilité de faux négatif)\\n\"\n",
        "        \n",
        "        return findings + \"\\n\"\n",
        "    \n",
        "    def _generate_impression_section(self, consensus):\n",
        "        \"\"\"\n",
        "        Section impression diagnostique\n",
        "        \"\"\"\n",
        "        impression = \"IMPRESSION:\\n\"\n",
        "        \n",
        "        if not consensus or len(consensus) == 0:\n",
        "            impression += \"Radiographie thoracique normale.\\n\"\n",
        "        else:\n",
        "            # Pathologies principales (consensus > 50%)\n",
        "            main_findings = [f for f in consensus if f['consensus_level'] > 0.5]\n",
        "            \n",
        "            if main_findings:\n",
        "                impression += \"Anomalies principales détectées:\\n\"\n",
        "                for finding in main_findings:\n",
        "                    pathology = finding['pathology']\n",
        "                    probability = finding['avg_probability']\n",
        "                    \n",
        "                    # Classification de sévérité basée sur probabilité\n",
        "                    if probability > 0.8:\n",
        "                        severity = \"probable\"\n",
        "                    elif probability > 0.6:\n",
        "                        severity = \"possible\"\n",
        "                    else:\n",
        "                        severity = \"à confirmer\"\n",
        "                    \n",
        "                    impression += f\"- {pathology} {severity} ({probability:.1%})\\n\"\n",
        "            \n",
        "            # Pathologies secondaires\n",
        "            secondary_findings = [f for f in consensus if f['consensus_level'] <= 0.5]\n",
        "            if secondary_findings:\n",
        "                impression += \"\\nAnomalies mineures ou incertaines:\\n\"\n",
        "                for finding in secondary_findings[:3]:\n",
        "                    pathology = finding['pathology']\n",
        "                    impression += f\"- {pathology} (incertain)\\n\"\n",
        "        \n",
        "        return impression + \"\\n\"\n",
        "    \n",
        "    def _generate_recommendations_section(self, consensus):\n",
        "        \"\"\"\n",
        "        Section recommandations\n",
        "        \"\"\"\n",
        "        recommendations = \"RECOMMANDATIONS:\\n\"\n",
        "        \n",
        "        if not consensus or len(consensus) == 0:\n",
        "            recommendations += \"Aucune recommandation spécifique.\\n\"\n",
        "            recommendations += \"Contrôle selon indication clinique.\\n\"\n",
        "        else:\n",
        "            # Recommandations spécifiques par pathologie\n",
        "            high_priority = []\n",
        "            \n",
        "            for finding in consensus:\n",
        "                if finding['consensus_level'] > 0.5:\n",
        "                    pathology = finding['pathology']\n",
        "                    \n",
        "                    # Recherche de recommandations spécifiques\n",
        "                    for key, rec in self.clinical_recommendations.items():\n",
        "                        if key.lower() in pathology.lower():\n",
        "                            recommendations += f\"\\n{pathology}:\\n\"\n",
        "                            recommendations += f\"- Urgence: {rec['urgency']}\\n\"\n",
        "                            recommendations += f\"- Suivi: {rec['follow_up']}\\n\"\n",
        "                            recommendations += f\"- Spécialiste: {rec['specialty']}\\n\"\n",
        "                            recommendations += f\"- Examens complémentaires: {rec['additional_tests']}\\n\"\n",
        "                            \n",
        "                            if rec['urgency'] == 'Élevée':\n",
        "                                high_priority.append(pathology)\n",
        "                            break\n",
        "            \n",
        "            # Recommandations générales\n",
        "            recommendations += \"\\nRecommandations générales:\\n\"\n",
        "            if high_priority:\n",
        "                recommendations += \"⚠️ PRISE EN CHARGE URGENTE recommandée\\n\"\n",
        "                recommendations += \"📞 Contacter le spécialiste en priorité\\n\"\n",
        "            \n",
        "            recommendations += \"🔬 Corrélation avec l'examen clinique indispensable\\n\"\n",
        "            recommendations += \"👨‍⚕️ Validation par radiologue senior recommandée\\n\"\n",
        "        \n",
        "        return recommendations + \"\\n\"\n",
        "    \n",
        "    def _generate_signature_section(self):\n",
        "        \"\"\"\n",
        "        Section signature\n",
        "        \"\"\"\n",
        "        from datetime import datetime\n",
        "        \n",
        "        return f\"\"\"\n",
        "VALIDATION:\n",
        "Rapport généré automatiquement par système d'IA TorchXRayVision\n",
        "Date de génération: {datetime.now().strftime('%d/%m/%Y à %H:%M')}\n",
        "\n",
        "⚠️  IMPORTANT: Ce rapport automatisé doit être validé par un radiologue.\n",
        "⚠️  L'IA est un outil d'aide au diagnostic, non substitutif à l'expertise médicale.\n",
        "⚠️  En cas de doute clinique, privilégier l'avis du radiologue senior.\n",
        "\n",
        "Système: TorchXRayVision Clinical Assistant\n",
        "Version: Démonstration pédagogique\n",
        "Statut: NON VALIDÉ - RAPPORT ÉDUCATIF\n",
        "\"\"\"\n",
        "\n",
        "# Démonstration de génération de rapports\n",
        "print(\"\\nGénération de rapports cliniques automatisés...\")\n",
        "\n",
        "if comprehensive_analysis:\n",
        "    # Initialisation du générateur\n",
        "    report_generator = ClinicalReportGenerator()\n",
        "    \n",
        "    # Génération de rapports pour quelques cas sélectionnés\n",
        "    selected_cases = ['pneumonia_lobaire', 'cardiomegalie_moderee', 'normal']\n",
        "    \n",
        "    for case_name in selected_cases:\n",
        "        if case_name in comprehensive_analysis:\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(f\"RAPPORT AUTOMATISÉ - CAS: {case_name.upper()}\")\n",
        "            print(f\"{'='*80}\")\n",
        "            \n",
        "            # Informations patient fictives\n",
        "            patient_info = {\n",
        "                'id': f'DEMO-{case_name[:3].upper()}-001',\n",
        "                'name': f'Patient {case_name.replace(\"_\", \" \").title()}'\n",
        "            }\n",
        "            \n",
        "            # Génération du rapport\n",
        "            case_analysis = comprehensive_analysis[case_name]\n",
        "            clinical_report = report_generator.generate_structured_report(\n",
        "                case_analysis, patient_info\n",
        "            )\n",
        "            \n",
        "            print(clinical_report)\n",
        "    \n",
        "    print(f\"\\nRapports cliniques générés pour {len(selected_cases)} cas.\")\n",
        "    print(\"Ces rapports démontrent l'intégration possible de TorchXRayVision\")\n",
        "    print(\"dans des workflows cliniques automatisés.\")\n",
        "\n",
        "else:\n",
        "    print(\"Aucune analyse disponible pour génération de rapports\")\n",
        "\n",
        "print(\"\\nGénération de rapports terminée.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Résumé et Applications Cliniques\n",
        "\n",
        "### Compétences Acquises\n",
        "\n",
        "Dans ce notebook complet, vous avez maîtrisé:\n",
        "\n",
        "1. **Analyse Multi-Modèles avec TorchXRayVision**\n",
        "   - Chargement et comparaison de modèles DenseNet-All, CheXpert, NIH\n",
        "   - Classification de 18 pathologies thoraciques principales\n",
        "   - Analyse de consensus inter-modèles pour robustesse diagnostique\n",
        "\n",
        "2. **Création de Cas Cliniques Réalistes**\n",
        "   - Génération de radiographies synthétiques pathologiques\n",
        "   - Simulation de conditions cliniques variées\n",
        "   - Intégration de contextes médicaux authentiques\n",
        "\n",
        "3. **Localisation Spatiale avec Grad-CAM**\n",
        "   - Implémentation de cartes d'activation pour localisation\n",
        "   - Visualisation des régions d'intérêt pathologiques\n",
        "   - Explicabilité des décisions d'IA pour validation clinique\n",
        "\n",
        "4. **Métriques de Performance Avancées**\n",
        "   - Calcul de précision, rappel, F1-Score par modèle\n",
        "   - Analyse comparative des performances diagnostiques\n",
        "   - Recommandations d'usage selon contexte clinique\n",
        "\n",
        "5. **Génération Automatique de Rapports**\n",
        "   - Rapports radiologiques structurés automatisés\n",
        "   - Recommandations cliniques spécialisées par pathologie\n",
        "   - Intégration dans workflows hospitaliers\n",
        "\n",
        "### Applications Médicales Directes\n",
        "\n",
        "Ces compétences vous permettront de:\n",
        "- **Déployer TorchXRayVision** dans des environnements cliniques réels\n",
        "- **Optimiser la sélection de modèles** selon vos besoins spécifiques\n",
        "- **Intégrer l'IA radiologique** dans les systèmes PACS existants\n",
        "- **Générer des rapports automatisés** pour améliorer l'efficacité\n",
        "- **Localiser précisément** les pathologies pour guidage interventionnel\n",
        "\n",
        "### Recommandations Cliniques\n",
        "\n",
        "1. **Sélection de Modèles**:\n",
        "   - **DenseNet-All**: Usage général, meilleur équilibre performance\n",
        "   - **CheXpert**: Pathologies thoraciques variées, haute spécificité\n",
        "   - **NIH**: Conditions spécialisées, recherche clinique\n",
        "\n",
        "2. **Intégration Workflow**:\n",
        "   - Utiliser le consensus inter-modèles pour validation\n",
        "   - Implémenter des seuils adaptatifs selon urgence\n",
        "   - Maintenir la supervision médicale obligatoire\n",
        "\n",
        "3. **Assurance Qualité**:\n",
        "   - Validation continue sur données locales\n",
        "   - Surveillance des performances en temps réel\n",
        "   - Formation continue des équipes médicales\n",
        "\n",
        "### Limitations et Considérations Éthiques\n",
        "\n",
        "- **Validation Médicale**: L'IA reste un outil d'aide, jamais substitutif\n",
        "- **Biais des Données**: Performance variable selon populations\n",
        "- **Évolution Technologique**: Mise à jour régulière nécessaire\n",
        "- **Responsabilité Clinique**: Décision finale toujours médicale\n",
        "\n",
        "### Prochaine Étape\n",
        "\n",
        "Le prochain notebook vous enseignera la **segmentation d'images médicales**, combinant méthodes manuelles et automatiques avec MedSAM pour délimitation précise des structures anatomiques."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}