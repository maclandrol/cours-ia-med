{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/maclandrol/03ac6c1f4cbb02f923787c628c201921/09_TorchXRayVision_Pathologie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": "**Enseignant:** Emmanuel Noutahi, PhD",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pathology_header"
      },
      "source": [
        "# Tutorial 4 : DÃ©tection et Localisation de Pathologies\n",
        "# Tutorial 4: Pathology Detection and Localization\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“š Contexte MÃ©dical / Medical Context\n",
        "\n",
        "### Pour les Ã‰tudiants en MÃ©decine / For Medical Students\n",
        "La **dÃ©tection automatique de pathologies** reprÃ©sente une application cruciale de l'IA en radiologie :\n",
        "- **Anatomie pathologique** : Reconnaissance des anomalies structurelles\n",
        "- **Physiologie** : ComprÃ©hension de l'impact fonctionnel des lÃ©sions\n",
        "- **Radiologie** : Aide au diagnostic et Ã  la localisation prÃ©cise\n",
        "\n",
        "### Pour les Praticiens / For Practitioners\n",
        "- **Chirurgiens** : Localisation prÃ©-opÃ©ratoire des lÃ©sions et planification\n",
        "- **MÃ©decins GÃ©nÃ©ralistes** : Aide au dÃ©pistage et triage des urgences\n",
        "- **Enseignants** : Outil pÃ©dagogique pour l'apprentissage des pathologies\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Objectifs d'Apprentissage / Learning Objectives\n",
        "\n",
        "Ã€ la fin de ce tutoriel, vous serez capable de :\n",
        "1. Utiliser les modÃ¨les TorchXRayVision pour dÃ©tecter 18 pathologies courantes\n",
        "2. Localiser les zones pathologiques sur l'image\n",
        "3. InterprÃ©ter les scores de probabilitÃ© et seuils de dÃ©cision\n",
        "4. GÃ©nÃ©rer des cartes de chaleur (heatmaps) pour la localisation\n",
        "5. CrÃ©er un rapport diagnostique automatique\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ¥ Pathologies DÃ©tectables / Detectable Pathologies\n",
        "\n",
        "TorchXRayVision peut dÃ©tecter **18 pathologies** principales :\n",
        "\n",
        "### Pathologies Pulmonaires / Lung Pathologies\n",
        "- **Atelectasis** (AtÃ©lectasie) - Collapsus pulmonaire\n",
        "- **Consolidation** - Condensation parenchymateuse\n",
        "- **Infiltration** - Infiltrats pulmonaires\n",
        "- **Pneumothorax** - Air dans l'espace pleural\n",
        "- **Edema** (Å’dÃ¨me) - Å’dÃ¨me pulmonaire\n",
        "- **Emphysema** (EmphysÃ¨me) - Destruction alvÃ©olaire\n",
        "- **Fibrosis** (Fibrose) - Fibrose pulmonaire\n",
        "- **Pleural_Thickening** - Ã‰paississement pleural\n",
        "\n",
        "### Pathologies Cardiaques / Cardiac Pathologies\n",
        "- **Cardiomegaly** (CardiomÃ©galie) - Augmentation cardiaque\n",
        "\n",
        "### Autres Pathologies / Other Pathologies\n",
        "- **Nodule** - Nodules pulmonaires\n",
        "- **Mass** (Masse) - Masses thoraciques\n",
        "- **Pneumonia** (Pneumonie) - Infection pulmonaire\n",
        "- **Hernia** (Hernie) - Hernie diaphragmatique\n",
        "- **Lung Lesion** - LÃ©sions pulmonaires\n",
        "- **Fracture** - Fractures costales\n",
        "- **Lung Opacity** - OpacitÃ©s pulmonaires\n",
        "- **Enlarged Cardiomediastinum** - Ã‰largissement mÃ©diastinal\n",
        "- **Support Devices** - Dispositifs mÃ©dicaux\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“‹ PrÃ©requis / Prerequisites\n",
        "\n",
        "Ce tutoriel fait suite aux **Tutoriels 1, 2 et 3**. Vous devriez maÃ®triser :\n",
        "- Chargement et prÃ©paration d'images\n",
        "- Classification avec TorchXRayVision\n",
        "- Segmentation anatomique\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”§ Installation et Configuration / Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "# Installation des bibliothÃ¨ques nÃ©cessaires / Install required libraries\n",
        "!pip install torchxrayvision\n",
        "!pip install torch torchvision\n",
        "!pip install matplotlib seaborn\n",
        "!pip install numpy pandas\n",
        "!pip install scikit-image opencv-python\n",
        "!pip install grad-cam  # Pour les cartes d'activation\n",
        "\n",
        "print(\"âœ… Installation terminÃ©e / Installation completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "# Import des bibliothÃ¨ques / Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchxrayvision as xrv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab import files\n",
        "import io\n",
        "import warnings\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration de l'affichage / Display configuration\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "plt.rcParams['font.size'] = 12\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "print(\"ðŸ“š BibliothÃ¨ques importÃ©es avec succÃ¨s / Libraries imported successfully\")\n",
        "print(f\"ðŸ”¥ PyTorch version: {torch.__version__}\")\n",
        "print(f\"ðŸ¥ TorchXRayVision version: {xrv.__version__}\")\n",
        "\n",
        "# VÃ©rification du GPU / GPU check\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸ’» Device utilisÃ© / Device used: {device}\")\n",
        "\n",
        "# Liste des pathologies dÃ©tectables\n",
        "PATHOLOGIES = [\n",
        "    'Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', \n",
        "    'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Cardiomegaly', 'Nodule',\n",
        "    'Mass', 'Pneumonia', 'Hernia', 'Lung Lesion', 'Fracture', 'Lung Opacity',\n",
        "    'Enlarged Cardiomediastinum', 'Support Devices'\n",
        "]\n",
        "\n",
        "print(f\"ðŸ¥ Pathologies dÃ©tectables: {len(PATHOLOGIES)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_loading"
      },
      "source": [
        "## ðŸ¤– Chargement des ModÃ¨les de DÃ©tection / Loading Detection Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_models"
      },
      "outputs": [],
      "source": [
        "# Chargement des modÃ¨les spÃ©cialisÃ©s / Load specialized models\n",
        "print(\"ðŸ”„ Chargement des modÃ¨les de dÃ©tection de pathologies...\")\n",
        "print(\"ðŸ”„ Loading pathology detection models...\")\n",
        "\n",
        "# 1. ModÃ¨le DenseNet pour classification gÃ©nÃ©rale\n",
        "try:\n",
        "    model_densenet = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "    model_densenet.to(device)\n",
        "    model_densenet.eval()\n",
        "    print(\"âœ… DenseNet121 chargÃ© / loaded\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erreur DenseNet: {e}\")\n",
        "    model_densenet = None\n",
        "\n",
        "# 2. ModÃ¨le CheXpert pour pathologies spÃ©cifiques\n",
        "try:\n",
        "    model_chexpert = xrv.models.DenseNet(weights=\"densenet121-res224-chexpert\")\n",
        "    model_chexpert.to(device)\n",
        "    model_chexpert.eval()\n",
        "    print(\"âœ… CheXpert DenseNet chargÃ© / loaded\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erreur CheXpert: {e}\")\n",
        "    model_chexpert = None\n",
        "\n",
        "# 3. ModÃ¨le NIH pour comparaison\n",
        "try:\n",
        "    model_nih = xrv.models.DenseNet(weights=\"densenet121-res224-nih\")\n",
        "    model_nih.to(device)\n",
        "    model_nih.eval()\n",
        "    print(\"âœ… NIH DenseNet chargÃ© / loaded\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erreur NIH: {e}\")\n",
        "    model_nih = None\n",
        "\n",
        "# SÃ©lectionner le modÃ¨le principal\n",
        "if model_densenet is not None:\n",
        "    main_model = model_densenet\n",
        "    model_name = \"DenseNet121-All\"\n",
        "elif model_chexpert is not None:\n",
        "    main_model = model_chexpert\n",
        "    model_name = \"CheXpert\"\n",
        "elif model_nih is not None:\n",
        "    main_model = model_nih\n",
        "    model_name = \"NIH\"\n",
        "else:\n",
        "    raise Exception(\"Aucun modÃ¨le n'a pu Ãªtre chargÃ©\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ ModÃ¨le principal: {model_name}\")\n",
        "print(f\"ðŸ“Š Nombre de classes dÃ©tectÃ©es: {len(main_model.pathologies)}\")\n",
        "print(f\"ðŸ“‹ Classes disponibles: {main_model.pathologies}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "image_upload"
      },
      "source": [
        "## ðŸ“¤ Chargement d'Image / Image Upload\n",
        "\n",
        "### Option 1 : Charger depuis le Tutorial 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_from_tutorial3"
      },
      "outputs": [],
      "source": [
        "# Tentative de chargement des rÃ©sultats du Tutorial 3\n",
        "try:\n",
        "    with open('segmentation_results_tutorial3.pkl', 'rb') as f:\n",
        "        segmentation_data = pickle.load(f)\n",
        "    \n",
        "    original_image = segmentation_data['original_image']\n",
        "    lung_mask = segmentation_data['lung_mask']\n",
        "    cardiac_mask = segmentation_data['cardiac_mask']\n",
        "    \n",
        "    print(\"âœ… DonnÃ©es du Tutorial 3 chargÃ©es / Tutorial 3 data loaded\")\n",
        "    print(f\"ðŸ“ Taille de l'image / Image size: {original_image.shape}\")\n",
        "    \n",
        "    use_tutorial3_data = True\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"â„¹ï¸ DonnÃ©es du Tutorial 3 non trouvÃ©es, crÃ©ation d'une nouvelle image\")\n",
        "    print(\"â„¹ï¸ Tutorial 3 data not found, creating new image\")\n",
        "    use_tutorial3_data = False\n",
        "    \n",
        "    # CrÃ©er une image d'exemple avec pathologies simulÃ©es\n",
        "    img_array = np.random.rand(224, 224) * 0.3 + 0.4\n",
        "    \n",
        "    # Simuler des structures normales\n",
        "    img_array[50:180, 30:100] *= 0.7  # Poumon gauche\n",
        "    img_array[50:180, 124:194] *= 0.7  # Poumon droit\n",
        "    img_array[120:180, 90:134] *= 1.3  # CÅ“ur\n",
        "    \n",
        "    # Simuler quelques pathologies\n",
        "    # Nodule dans le poumon droit\n",
        "    img_array[80:90, 150:160] *= 1.8\n",
        "    \n",
        "    # Infiltration dans le poumon gauche\n",
        "    img_array[100:130, 60:80] *= 1.4\n",
        "    \n",
        "    # LÃ©gÃ¨re cardiomÃ©galie\n",
        "    img_array[110:190, 85:139] *= 1.2\n",
        "    \n",
        "    original_image = img_array\n",
        "    lung_mask = None\n",
        "    cardiac_mask = None\n",
        "\n",
        "# Affichage de l'image\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(original_image, cmap='gray')\n",
        "plt.title(\"Image pour DÃ©tection de Pathologies\\nImage for Pathology Detection\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_new_image"
      },
      "source": [
        "### Option 2 : Charger une Nouvelle Image / Upload New Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_new_image_code"
      },
      "outputs": [],
      "source": [
        "# Option pour charger une nouvelle image\n",
        "print(\"ðŸ“¤ Voulez-vous charger une nouvelle image avec des pathologies ?\")\n",
        "print(\"ðŸ“¤ Would you like to upload a new image with pathologies?\")\n",
        "print(\"\")\n",
        "print(\"Cliquez 'Choisir des fichiers' pour charger une radiographie avec pathologies\")\n",
        "print(\"Click 'Choose Files' to upload an X-ray with pathologies\")\n",
        "\n",
        "# Interface de chargement\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Traitement de l'image chargÃ©e\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    print(f\"ðŸ“ Nouveau fichier chargÃ© / New file uploaded: {filename}\")\n",
        "    \n",
        "    # Charger et traiter l'image\n",
        "    uploaded_image = Image.open(io.BytesIO(uploaded[filename]))\n",
        "    \n",
        "    # Convertir en niveaux de gris\n",
        "    if uploaded_image.mode != 'L':\n",
        "        uploaded_image = uploaded_image.convert('L')\n",
        "    \n",
        "    # Redimensionner et normaliser\n",
        "    uploaded_array = np.array(uploaded_image)\n",
        "    if uploaded_array.shape != (224, 224):\n",
        "        uploaded_array = cv2.resize(uploaded_array, (224, 224))\n",
        "    \n",
        "    original_image = uploaded_array.astype(np.float32) / 255.0\n",
        "    lung_mask = None  # Reset des masques pour la nouvelle image\n",
        "    cardiac_mask = None\n",
        "    \n",
        "    print(\"âœ… Nouvelle image prÃ©parÃ©e / New image prepared\")\n",
        "    \n",
        "    # Affichage de la nouvelle image\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(original_image, cmap='gray')\n",
        "    plt.title(f\"Image ChargÃ©e: {filename}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"â„¹ï¸ Utilisation de l'image prÃ©cÃ©dente / Using previous image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing_pathology"
      },
      "source": [
        "## ðŸ”§ PrÃ©paration pour DÃ©tection / Preprocessing for Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocess_for_detection"
      },
      "outputs": [],
      "source": [
        "def preprocess_for_pathology_detection(image):\n",
        "    \"\"\"\n",
        "    PrÃ©paration spÃ©cifique pour la dÃ©tection de pathologies\n",
        "    Specific preprocessing for pathology detection\n",
        "    \"\"\"\n",
        "    print(\"ðŸ”§ PrÃ©paration pour la dÃ©tection de pathologies...\")\n",
        "    print(\"ðŸ”§ Preprocessing for pathology detection...\")\n",
        "    \n",
        "    # Si l'image est dÃ©jÃ  un array numpy\n",
        "    if isinstance(image, np.ndarray):\n",
        "        img_array = image.copy()\n",
        "    else:\n",
        "        img_array = np.array(image)\n",
        "    \n",
        "    # S'assurer que l'image est en 224x224\n",
        "    if img_array.shape != (224, 224):\n",
        "        img_array = cv2.resize(img_array, (224, 224))\n",
        "    \n",
        "    # Normalisation spÃ©cifique Ã  TorchXRayVision\n",
        "    if img_array.max() > 1:\n",
        "        img_array = img_array.astype(np.float32) / 255.0\n",
        "    \n",
        "    # Normalisation Z-score\n",
        "    mean = np.mean(img_array)\n",
        "    std = np.std(img_array)\n",
        "    img_normalized = (img_array - mean) / (std + 1e-8)\n",
        "    \n",
        "    # Convertir en tensor PyTorch avec la forme attendue [1, 1, 224, 224]\n",
        "    img_tensor = torch.FloatTensor(img_normalized)\n",
        "    img_tensor = img_tensor.unsqueeze(0).unsqueeze(0)  # Ajouter dimensions batch et canal\n",
        "    img_tensor = img_tensor.to(device)\n",
        "    \n",
        "    print(f\"ðŸ“ Forme finale du tensor / Final tensor shape: {img_tensor.shape}\")\n",
        "    print(f\"ðŸ“Š Valeurs min/max / Min/max values: {img_tensor.min():.3f} / {img_tensor.max():.3f}\")\n",
        "    \n",
        "    return img_tensor, img_normalized\n",
        "\n",
        "# PrÃ©parer l'image pour la dÃ©tection\n",
        "img_tensor, img_preprocessed = preprocess_for_pathology_detection(original_image)\n",
        "\n",
        "print(\"âœ… Image prÃ©parÃ©e pour la dÃ©tection / Image prepared for detection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pathology_detection"
      },
      "source": [
        "## ðŸ” DÃ©tection de Pathologies / Pathology Detection\n",
        "\n",
        "### Analyse avec ModÃ¨le Principal / Analysis with Main Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "detect_pathologies"
      },
      "outputs": [],
      "source": [
        "def detect_pathologies(model, img_tensor, threshold=0.5):\n",
        "    \"\"\"\n",
        "    DÃ©tection des pathologies avec le modÃ¨le\n",
        "    Pathology detection with the model\n",
        "    \"\"\"\n",
        "    print(\"ðŸ” DÃ©tection des pathologies en cours...\")\n",
        "    print(\"ðŸ” Pathology detection in progress...\")\n",
        "    \n",
        "    # InfÃ©rence avec le modÃ¨le\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img_tensor)\n",
        "        \n",
        "        # Appliquer la fonction sigmoÃ¯de pour obtenir des probabilitÃ©s\n",
        "        probabilities = torch.sigmoid(outputs)\n",
        "        probabilities_np = probabilities.cpu().numpy().flatten()\n",
        "    \n",
        "    # CrÃ©er un DataFrame avec les rÃ©sultats\n",
        "    pathologies_list = model.pathologies\n",
        "    \n",
        "    results_df = pd.DataFrame({\n",
        "        'Pathologie': pathologies_list,\n",
        "        'ProbabilitÃ©': probabilities_np,\n",
        "        'DÃ©tectÃ©e': probabilities_np > threshold\n",
        "    })\n",
        "    \n",
        "    # Trier par probabilitÃ© dÃ©croissante\n",
        "    results_df = results_df.sort_values('ProbabilitÃ©', ascending=False).reset_index(drop=True)\n",
        "    \n",
        "    print(f\"ðŸ“Š Analyse terminÃ©e pour {len(pathologies_list)} pathologies\")\n",
        "    print(f\"ðŸŽ¯ Seuil de dÃ©tection: {threshold}\")\n",
        "    \n",
        "    detected_count = sum(probabilities_np > threshold)\n",
        "    print(f\"ðŸ”´ Pathologies dÃ©tectÃ©es: {detected_count}/{len(pathologies_list)}\")\n",
        "    \n",
        "    return results_df, probabilities_np, outputs\n",
        "\n",
        "# Effectuer la dÃ©tection\n",
        "results, probabilities, raw_outputs = detect_pathologies(main_model, img_tensor, threshold=0.3)\n",
        "\n",
        "# Afficher les rÃ©sultats\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ¥ RÃ‰SULTATS DE DÃ‰TECTION DE PATHOLOGIES\")\n",
        "print(\"ðŸ¥ PATHOLOGY DETECTION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Top 10 des pathologies les plus probables\n",
        "print(\"\\nðŸ” TOP 10 - PATHOLOGIES LES PLUS PROBABLES:\")\n",
        "for i, row in results.head(10).iterrows():\n",
        "    status = \"ðŸ”´ DÃ‰TECTÃ‰E\" if row['DÃ©tectÃ©e'] else \"ðŸŸ¢ Non dÃ©tectÃ©e\"\n",
        "    print(f\"   {i+1:2d}. {row['Pathologie']:20s} : {row['ProbabilitÃ©']:.3f} ({row['ProbabilitÃ©']*100:.1f}%) - {status}\")\n",
        "\n",
        "# Pathologies dÃ©tectÃ©es (seuil > 0.3)\n",
        "detected_pathologies = results[results['DÃ©tectÃ©e']]\n",
        "if len(detected_pathologies) > 0:\n",
        "    print(f\"\\nðŸš¨ PATHOLOGIES DÃ‰TECTÃ‰ES (ProbabilitÃ© > 30%):\")\n",
        "    for i, row in detected_pathologies.iterrows():\n",
        "        confidence = \"Ã‰LEVÃ‰E\" if row['ProbabilitÃ©'] > 0.7 else \"MOYENNE\" if row['ProbabilitÃ©'] > 0.5 else \"FAIBLE\"\n",
        "        print(f\"   â€¢ {row['Pathologie']:20s} : {row['ProbabilitÃ©']:.3f} ({row['ProbabilitÃ©']*100:.1f}%) - Confiance {confidence}\")\nelse:\n",
        "    print(\"\\nâœ… AUCUNE PATHOLOGIE DÃ‰TECTÃ‰E avec le seuil actuel\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_results"
      },
      "source": [
        "## ðŸ“Š Visualisation des RÃ©sultats / Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualize_detection_results"
      },
      "outputs": [],
      "source": [
        "def visualize_pathology_results(image, results_df, probabilities):\n",
        "    \"\"\"\n",
        "    Visualisation complÃ¨te des rÃ©sultats de dÃ©tection\n",
        "    Comprehensive visualization of detection results\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "    fig.suptitle('ANALYSE COMPLÃˆTE DE DÃ‰TECTION DE PATHOLOGIES\\nCOMPREHENSIVE PATHOLOGY DETECTION ANALYSIS', \n",
        "                fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Image originale\n",
        "    axes[0, 0].imshow(image, cmap='gray')\n",
        "    axes[0, 0].set_title('Image AnalysÃ©e\\nAnalyzed Image', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].axis('off')\n",
        "    \n",
        "    # 2. Graphique en barres des probabilitÃ©s (Top 10)\n",
        "    top_10 = results_df.head(10)\n",
        "    colors = ['red' if detected else 'lightblue' for detected in top_10['DÃ©tectÃ©e']]\n",
        "    \n",
        "    bars = axes[0, 1].barh(range(len(top_10)), top_10['ProbabilitÃ©'], color=colors, alpha=0.7)\n",
        "    axes[0, 1].set_yticks(range(len(top_10)))\n",
        "    axes[0, 1].set_yticklabels([p[:15] for p in top_10['Pathologie']], fontsize=10)\n",
        "    axes[0, 1].set_xlabel('ProbabilitÃ©')\n",
        "    axes[0, 1].set_title('Top 10 Pathologies\\n(Rouge = DÃ©tectÃ©e)', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].axvline(x=0.3, color='orange', linestyle='--', alpha=0.7, label='Seuil (0.3)')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Ajouter les valeurs sur les barres\n",
        "    for i, (bar, prob) in enumerate(zip(bars, top_10['ProbabilitÃ©'])):\n",
        "        width = bar.get_width()\n",
        "        axes[0, 1].text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
        "                       f'{prob:.3f}', ha='left', va='center', fontweight='bold')\n",
        "    \n",
        "    # 3. Distribution des probabilitÃ©s\n",
        "    axes[0, 2].hist(probabilities, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    axes[0, 2].axvline(x=0.3, color='orange', linestyle='--', linewidth=2, label='Seuil (0.3)')\n",
        "    axes[0, 2].axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Seuil (0.5)')\n",
        "    axes[0, 2].set_xlabel('ProbabilitÃ©')\n",
        "    axes[0, 2].set_ylabel('Nombre de Pathologies')\n",
        "    axes[0, 2].set_title('Distribution des\\nProbabilitÃ©s', fontsize=12, fontweight='bold')\n",
        "    axes[0, 2].legend()\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Pathologies dÃ©tectÃ©es (seulement si il y en a)\n",
        "    detected = results_df[results_df['DÃ©tectÃ©e']]\n",
        "    if len(detected) > 0:\n",
        "        # Graphique en secteurs des pathologies dÃ©tectÃ©es\n",
        "        sizes = detected['ProbabilitÃ©']\n",
        "        labels = [f\"{path[:12]}\\n{prob:.3f}\" for path, prob in zip(detected['Pathologie'], detected['ProbabilitÃ©'])]\n",
        "        colors_pie = plt.cm.Reds(np.linspace(0.4, 0.9, len(detected)))\n",
        "        \n",
        "        wedges, texts, autotexts = axes[1, 0].pie(sizes, labels=labels, colors=colors_pie, \n",
        "                                                 autopct='%1.1f%%', startangle=90)\n",
        "        axes[1, 0].set_title(f'Pathologies DÃ©tectÃ©es\\n({len(detected)} trouvÃ©es)', \n",
        "                           fontsize=12, fontweight='bold')\n",
        "    else:\n",
        "        axes[1, 0].text(0.5, 0.5, 'AUCUNE\\nPATHOLOGIE\\nDÃ‰TECTÃ‰E', \n",
        "                       ha='center', va='center', transform=axes[1, 0].transAxes,\n",
        "                       fontsize=14, fontweight='bold', color='green')\n",
        "        axes[1, 0].set_title('Statut de DÃ©tection', fontsize=12, fontweight='bold')\n",
        "    \n",
        "    # 5. Comparaison par catÃ©gories de pathologies\n",
        "    # CatÃ©goriser les pathologies\n",
        "    lung_pathologies = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', \n",
        "                       'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Pneumonia',\n",
        "                       'Lung Lesion', 'Lung Opacity', 'Nodule', 'Mass']\n",
        "    cardiac_pathologies = ['Cardiomegaly', 'Enlarged Cardiomediastinum']\n",
        "    other_pathologies = ['Hernia', 'Fracture', 'Support Devices']\n",
        "    \n",
        "    # Calculer moyennes par catÃ©gorie\n",
        "    lung_probs = [prob for path, prob in zip(results_df['Pathologie'], results_df['ProbabilitÃ©']) \n",
        "                  if path in lung_pathologies]\n",
        "    cardiac_probs = [prob for path, prob in zip(results_df['Pathologie'], results_df['ProbabilitÃ©']) \n",
        "                     if path in cardiac_pathologies]\n",
        "    other_probs = [prob for path, prob in zip(results_df['Pathologie'], results_df['ProbabilitÃ©']) \n",
        "                   if path in other_pathologies]\n",
        "    \n",
        "    categories = []\n",
        "    avg_probs = []\n",
        "    \n",
        "    if lung_probs:\n",
        "        categories.append('Pulmonaires')\n",
        "        avg_probs.append(np.mean(lung_probs))\n",
        "    if cardiac_probs:\n",
        "        categories.append('Cardiaques')\n",
        "        avg_probs.append(np.mean(cardiac_probs))\n",
        "    if other_probs:\n",
        "        categories.append('Autres')\n",
        "        avg_probs.append(np.mean(other_probs))\n",
        "    \n",
        "    if categories:\n",
        "        bars_cat = axes[1, 1].bar(categories, avg_probs, \n",
        "                                 color=['lightcoral', 'lightblue', 'lightgreen'][:len(categories)], \n",
        "                                 alpha=0.7, edgecolor='black')\n",
        "        axes[1, 1].set_ylabel('ProbabilitÃ© Moyenne')\n",
        "        axes[1, 1].set_title('Analyse par CatÃ©gorie\\nde Pathologies', fontsize=12, fontweight='bold')\n",
        "        axes[1, 1].set_ylim(0, max(avg_probs) * 1.2 if avg_probs else 1)\n",
        "        \n",
        "        # Ajouter les valeurs sur les barres\n",
        "        for bar, prob in zip(bars_cat, avg_probs):\n",
        "            height = bar.get_height()\n",
        "            axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "                           f'{prob:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "        \n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 6. Matrice de confiance/seuils\n",
        "    thresholds = np.arange(0.1, 0.9, 0.1)\n",
        "    detection_counts = []\n",
        "    \n",
        "    for thresh in thresholds:\n",
        "        count = sum(probabilities > thresh)\n",
        "        detection_counts.append(count)\n",
        "    \n",
        "    axes[1, 2].plot(thresholds, detection_counts, 'bo-', linewidth=2, markersize=8)\n",
        "    axes[1, 2].set_xlabel('Seuil de ProbabilitÃ©')\n",
        "    axes[1, 2].set_ylabel('Nombre de DÃ©tections')\n",
        "    axes[1, 2].set_title('SensibilitÃ© au Seuil\\nde DÃ©tection', fontsize=12, fontweight='bold')\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Marquer le seuil actuel\n",
        "    current_count = sum(probabilities > 0.3)\n",
        "    axes[1, 2].scatter([0.3], [current_count], color='red', s=100, zorder=5)\n",
        "    axes[1, 2].annotate(f'Seuil actuel\\n({current_count} dÃ©tections)', \n",
        "                       xy=(0.3, current_count), xytext=(0.5, current_count + 2),\n",
        "                       arrowprops=dict(arrowstyle='->', color='red'))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# CrÃ©er la visualisation\n",
        "visualize_pathology_results(img_preprocessed, results, probabilities)\n",
        "\n",
        "print(\"âœ… Visualisation des rÃ©sultats gÃ©nÃ©rÃ©e / Results visualization generated\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heatmap_section"
      },
      "source": [
        "## ðŸ”¥ Cartes de Chaleur pour Localisation / Heatmaps for Localization\n",
        "\n",
        "Les **cartes de chaleur** (heatmaps) permettent de visualiser oÃ¹ le modÃ¨le \"regarde\" pour dÃ©tecter les pathologies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_heatmaps"
      },
      "outputs": [],
      "source": [
        "def generate_grad_cam_heatmap(model, img_tensor, target_class_idx):\n",
        "    \"\"\"\n",
        "    GÃ©nÃ©ration de cartes de chaleur Grad-CAM pour localisation\n",
        "    Generate Grad-CAM heatmaps for localization\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Hook pour capturer les gradients\n",
        "    gradients = []\n",
        "    activations = []\n",
        "    \n",
        "    def backward_hook(module, grad_input, grad_output):\n",
        "        gradients.append(grad_output[0])\n",
        "    \n",
        "    def forward_hook(module, input, output):\n",
        "        activations.append(output)\n",
        "    \n",
        "    # Trouver la derniÃ¨re couche de convolution\n",
        "    target_layer = None\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            target_layer = module\n",
        "    \n",
        "    if target_layer is None:\n",
        "        print(\"âŒ Aucune couche de convolution trouvÃ©e\")\n",
        "        return None\n",
        "    \n",
        "    # Enregistrer les hooks\n",
        "    h1 = target_layer.register_forward_hook(forward_hook)\n",
        "    h2 = target_layer.register_backward_hook(backward_hook)\n",
        "    \n",
        "    # Forward pass\n",
        "    img_tensor.requires_grad_()\n",
        "    output = model(img_tensor)\n",
        "    \n",
        "    # Backward pass pour la classe cible\n",
        "    model.zero_grad()\n",
        "    class_output = output[0, target_class_idx]\n",
        "    class_output.backward()\n",
        "    \n",
        "    # Supprimer les hooks\n",
        "    h1.remove()\n",
        "    h2.remove()\n",
        "    \n",
        "    if gradients and activations:\n",
        "        # Calculer la carte de chaleur\n",
        "        grad = gradients[0].cpu().data.numpy()[0]\n",
        "        activation = activations[0].cpu().data.numpy()[0]\n",
        "        \n",
        "        # Moyenne des gradients pour chaque canal\n",
        "        weights = np.mean(grad, axis=(1, 2))\n",
        "        \n",
        "        # Combinaison pondÃ©rÃ©e des cartes d'activation\n",
        "        heatmap = np.zeros(activation.shape[1:])\n",
        "        for i, weight in enumerate(weights):\n",
        "            heatmap += weight * activation[i]\n",
        "        \n",
        "        # ReLU et normalisation\n",
        "        heatmap = np.maximum(heatmap, 0)\n",
        "        if heatmap.max() > 0:\n",
        "            heatmap = heatmap / heatmap.max()\n",
        "        \n",
        "        # Redimensionner Ã  la taille de l'image\n",
        "        heatmap_resized = cv2.resize(heatmap, (224, 224))\n",
        "        \n",
        "        return heatmap_resized\n",
        "    \n",
        "    return None\n",
        "\n",
        "def create_heatmap_visualization(image, results_df, model, img_tensor):\n",
        "    \"\"\"\n",
        "    CrÃ©ation de visualisations avec cartes de chaleur pour les pathologies dÃ©tectÃ©es\n",
        "    Create heatmap visualizations for detected pathologies\n",
        "    \"\"\"\n",
        "    print(\"ðŸ”¥ GÃ©nÃ©ration des cartes de chaleur...\")\n",
        "    print(\"ðŸ”¥ Generating heatmaps...\")\n",
        "    \n",
        "    # SÃ©lectionner les pathologies les plus probables\n",
        "    top_pathologies = results_df.head(6)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('CARTES DE CHALEUR - LOCALISATION DES PATHOLOGIES\\nHEATMAPS - PATHOLOGY LOCALIZATION', \n",
        "                fontsize=16, fontweight='bold')\n",
        "    \n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, (_, row) in enumerate(top_pathologies.iterrows()):\n",
        "        pathology = row['Pathologie']\n",
        "        probability = row['ProbabilitÃ©']\n",
        "        detected = row['DÃ©tectÃ©e']\n",
        "        \n",
        "        # Trouver l'index de la pathologie dans le modÃ¨le\n",
        "        if pathology in model.pathologies:\n",
        "            class_idx = model.pathologies.index(pathology)\n",
        "            \n",
        "            try:\n",
        "                # GÃ©nÃ©rer la carte de chaleur\n",
        "                heatmap = generate_grad_cam_heatmap(model, img_tensor, class_idx)\n",
        "                \n",
        "                if heatmap is not None:\n",
        "                    # Afficher l'image avec superposition de la carte de chaleur\n",
        "                    axes[idx].imshow(image, cmap='gray', alpha=0.7)\n",
        "                    axes[idx].imshow(heatmap, cmap='jet', alpha=0.4)\n",
        "                    \n",
        "                    # Titre avec informations\n",
        "                    status_color = 'red' if detected else 'green'\n",
        "                    status_text = 'DÃ‰TECTÃ‰E' if detected else 'Non dÃ©tectÃ©e'\n",
        "                    axes[idx].set_title(f'{pathology}\\nProb: {probability:.3f} - {status_text}', \n",
        "                                       fontsize=10, fontweight='bold', color=status_color)\n",
        "                    \n",
        "                    # Ajouter une barre de couleur\n",
        "                    if probability > 0.3:  # Seulement pour les pathologies significatives\n",
        "                        axes[idx].contour(heatmap, levels=[0.5, 0.7], colors=['yellow', 'red'], \n",
        "                                        linewidths=[1, 2], alpha=0.8)\n",
        "                \n",
        "                else:\n",
        "                    # Si la carte de chaleur n'a pas pu Ãªtre gÃ©nÃ©rÃ©e\n",
        "                    axes[idx].imshow(image, cmap='gray')\n",
        "                    axes[idx].set_title(f'{pathology}\\nProb: {probability:.3f}\\n(Carte non gÃ©nÃ©rÃ©e)', \n",
        "                                       fontsize=10, fontweight='bold')\n",
        "            \n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Erreur gÃ©nÃ©ration heatmap pour {pathology}: {e}\")\n",
        "                axes[idx].imshow(image, cmap='gray')\n",
        "                axes[idx].set_title(f'{pathology}\\nProb: {probability:.3f}\\n(Erreur gÃ©nÃ©ration)', \n",
        "                                   fontsize=10, fontweight='bold')\n",
        "        \n",
        "        else:\n",
        "            # Pathologie non trouvÃ©e dans le modÃ¨le\n",
        "            axes[idx].imshow(image, cmap='gray')\n",
        "            axes[idx].set_title(f'{pathology}\\nProb: {probability:.3f}\\n(Non supportÃ©e)', \n",
        "                               fontsize=10, fontweight='bold')\n",
        "        \n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"âœ… Cartes de chaleur gÃ©nÃ©rÃ©es / Heatmaps generated\")\n",
        "\n",
        "# MÃ©thode alternative simplifiÃ©e pour la localisation\n",
        "def simple_localization_heatmaps(image, results_df):\n",
        "    \"\"\"\n",
        "    MÃ©thode alternative pour montrer les zones d'attention\n",
        "    Alternative method to show attention areas\n",
        "    \"\"\"\n",
        "    print(\"ðŸŽ¯ GÃ©nÃ©ration de cartes de localisation simplifiÃ©es...\")\n",
        "    print(\"ðŸŽ¯ Generating simplified localization maps...\")\n",
        "    \n",
        "    # SÃ©lectionner les pathologies les plus probables\n",
        "    top_pathologies = results_df[results_df['ProbabilitÃ©'] > 0.2].head(4)\n",
        "    \n",
        "    if len(top_pathologies) == 0:\n",
        "        print(\"â„¹ï¸ Aucune pathologie avec probabilitÃ© > 0.2 pour la localisation\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(1, len(top_pathologies), figsize=(5*len(top_pathologies), 5))\n",
        "    \n",
        "    if len(top_pathologies) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for idx, (_, row) in enumerate(top_pathologies.iterrows()):\n",
        "        pathology = row['Pathologie']\n",
        "        probability = row['ProbabilitÃ©']\n",
        "        \n",
        "        # CrÃ©er une carte de chaleur simulÃ©e basÃ©e sur des zones anatomiques connues\n",
        "        heatmap = np.zeros((224, 224))\n",
        "        \n",
        "        # Zones d'attention basÃ©es sur la pathologie\n",
        "        if 'Lung' in pathology or pathology in ['Atelectasis', 'Consolidation', 'Infiltration', \n",
        "                                                'Pneumothorax', 'Edema', 'Emphysema', \n",
        "                                                'Fibrosis', 'Pneumonia', 'Nodule']:\n",
        "            # Zone pulmonaire\n",
        "            heatmap[50:180, 30:100] = probability * 0.8  # Poumon gauche\n",
        "            heatmap[50:180, 124:194] = probability * 0.8  # Poumon droit\n",
        "        \n",
        "        elif pathology in ['Cardiomegaly', 'Enlarged Cardiomediastinum']:\n",
        "            # Zone cardiaque\n",
        "            heatmap[120:180, 90:134] = probability\n",
        "        \n",
        "        elif pathology in ['Fracture']:\n",
        "            # Zone costale\n",
        "            heatmap[60:160, 20:40] = probability * 0.6  # CÃ´tes gauches\n",
        "            heatmap[60:160, 184:204] = probability * 0.6  # CÃ´tes droites\n",
        "        \n",
        "        else:\n",
        "            # Zone gÃ©nÃ©rale thoracique\n",
        "            heatmap[50:180, 50:174] = probability * 0.5\n",
        "        \n",
        "        # Appliquer un flou gaussien pour un aspect plus rÃ©aliste\n",
        "        heatmap = cv2.GaussianBlur(heatmap, (15, 15), 0)\n",
        "        \n",
        "        # Affichage\n",
        "        axes[idx].imshow(image, cmap='gray', alpha=0.8)\n",
        "        im = axes[idx].imshow(heatmap, cmap='hot', alpha=0.5, vmin=0, vmax=probability)\n",
        "        \n",
        "        # Titre et formatage\n",
        "        status = 'DÃ‰TECTÃ‰E' if row['DÃ©tectÃ©e'] else 'SuspectÃ©e'\n",
        "        color = 'red' if row['DÃ©tectÃ©e'] else 'orange'\n",
        "        axes[idx].set_title(f'{pathology}\\n{probability:.3f} ({probability*100:.1f}%)\\n{status}', \n",
        "                           fontsize=12, fontweight='bold', color=color)\n",
        "        axes[idx].axis('off')\n",
        "        \n",
        "        # Barre de couleur\n",
        "        cbar = plt.colorbar(im, ax=axes[idx], fraction=0.046, pad=0.04)\n",
        "        cbar.set_label('IntensitÃ© de DÃ©tection', rotation=270, labelpad=15)\n",
        "    \n",
        "    plt.suptitle('LOCALISATION APPROXIMATIVE DES PATHOLOGIES\\nAPPROXIMATE PATHOLOGY LOCALIZATION', \n",
        "                fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Essayer la gÃ©nÃ©ration de cartes de chaleur avancÃ©es\n",
        "try:\n",
        "    create_heatmap_visualization(img_preprocessed, results, main_model, img_tensor)\nexcept Exception as e:\n",
        "    print(f\"âš ï¸ Cartes de chaleur avancÃ©es non disponibles: {e}\")\n",
        "    print(\"ðŸŽ¯ Utilisation de la mÃ©thode de localisation simplifiÃ©e...\")\n",
        "    \n",
        "    # Utiliser la mÃ©thode simplifiÃ©e\n",
        "    simple_localization_heatmaps(img_preprocessed, results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clinical_report_section"
      },
      "source": [
        "## ðŸ“‹ Rapport Clinique Automatique / Automatic Clinical Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_clinical_report"
      },
      "outputs": [],
      "source": [
        "def generate_comprehensive_clinical_report(results_df, model_name, threshold=0.3):\n",
        "    \"\"\"\n",
        "    GÃ©nÃ©ration d'un rapport clinique complet pour la dÃ©tection de pathologies\n",
        "    Generate comprehensive clinical report for pathology detection\n",
        "    \"\"\"\n",
        "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ¥ RAPPORT CLINIQUE DE DÃ‰TECTION RADIOLOGIQUE\")\n",
        "    print(\"ðŸ¥ RADIOLOGICAL DETECTION CLINICAL REPORT\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    print(f\"ðŸ“… Date et heure d'analyse: {current_time}\")\n",
        "    print(f\"ðŸ¤– ModÃ¨le utilisÃ©: {model_name}\")\n",
        "    print(f\"ðŸŽ¯ Seuil de dÃ©tection: {threshold}\")\n",
        "    print(f\"ðŸ“Š Nombre total de pathologies analysÃ©es: {len(results_df)}\")\n",
        "    \n",
        "    # RÃ©sumÃ© exÃ©cutif\n",
        "    detected_pathologies = results_df[results_df['DÃ©tectÃ©e']]\n",
        "    high_confidence = results_df[results_df['ProbabilitÃ©'] > 0.7]\n",
        "    medium_confidence = results_df[(results_df['ProbabilitÃ©'] > 0.5) & (results_df['ProbabilitÃ©'] <= 0.7)]\n",
        "    low_confidence = results_df[(results_df['ProbabilitÃ©'] > threshold) & (results_df['ProbabilitÃ©'] <= 0.5)]\n",
        "    \n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"ðŸ“Š RÃ‰SUMÃ‰ EXÃ‰CUTIF / EXECUTIVE SUMMARY\")\n",
        "    print(\"-\"*50)\n",
        "    \n",
        "    if len(detected_pathologies) == 0:\n",
        "        print(\"âœ… CONCLUSION PRINCIPALE: EXAMEN NORMAL\")\n",
        "        print(\"   â€¢ Aucune pathologie dÃ©tectÃ©e avec le seuil de confiance actuel\")\n",
        "        print(\"   â€¢ Image compatible avec un aspect radiologique normal\")\n",
        "    else:\n",
        "        print(f\"ðŸ”´ CONCLUSION PRINCIPALE: {len(detected_pathologies)} PATHOLOGIE(S) DÃ‰TECTÃ‰E(S)\")\n",
        "        print(f\"   â€¢ Confiance Ã©levÃ©e (>70%): {len(high_confidence)} pathologie(s)\")\n",
        "        print(f\"   â€¢ Confiance moyenne (50-70%): {len(medium_confidence)} pathologie(s)\")\n",
        "        print(f\"   â€¢ Confiance faible ({threshold*100:.0f}-50%): {len(low_confidence)} pathologie(s)\")\n",
        "    \n",
        "    # DÃ©tail des pathologies dÃ©tectÃ©es\n",
        "    if len(detected_pathologies) > 0:\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "        print(\"ðŸš¨ PATHOLOGIES DÃ‰TECTÃ‰ES - DÃ‰TAIL\")\n",
        "        print(\"-\"*50)\n",
        "        \n",
        "        for i, row in detected_pathologies.iterrows():\n",
        "            pathology = row['Pathologie']\n",
        "            probability = row['ProbabilitÃ©']\n",
        "            \n",
        "            # Niveau de confiance\n",
        "            if probability > 0.7:\n",
        "                confidence_level = \"ðŸ”´ Ã‰LEVÃ‰E\"\n",
        "                urgency = \"NÃ©cessite une Ã©valuation clinique prioritaire\"\n",
        "            elif probability > 0.5:\n",
        "                confidence_level = \"ðŸŸ¡ MOYENNE\"\n",
        "                urgency = \"CorrÃ©lation clinique recommandÃ©e\"\n",
        "            else:\n",
        "                confidence_level = \"ðŸŸ  FAIBLE\"\n",
        "                urgency = \"Surveillance ou examens complÃ©mentaires\"\n",
        "            \n",
        "            print(f\"\\n   {i+1}. {pathology.upper()}\")\n",
        "            print(f\"      â€¢ ProbabilitÃ©: {probability:.3f} ({probability*100:.1f}%)\")\n",
        "            print(f\"      â€¢ Niveau de confiance: {confidence_level}\")\n",
        "            print(f\"      â€¢ Recommandation: {urgency}\")\n",
        "            \n",
        "            # Informations cliniques spÃ©cifiques\n",
        "            clinical_info = get_clinical_information(pathology)\n",
        "            if clinical_info:\n",
        "                print(f\"      â€¢ Contexte clinique: {clinical_info}\")\n",
        "    \n",
        "    # Recommandations par spÃ©cialitÃ©\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"ðŸ‘¥ RECOMMANDATIONS PAR SPÃ‰CIALITÃ‰\")\n",
        "    print(\"-\"*50)\n",
        "    \n",
        "    # Pour les mÃ©decins gÃ©nÃ©ralistes\n",
        "    print(\"\\nðŸ‘¨â€âš•ï¸ POUR LES MÃ‰DECINS GÃ‰NÃ‰RALISTES:\")\n",
        "    if len(detected_pathologies) == 0:\n",
        "        print(\"   âœ… Pas d'action urgente requise\")\n",
        "        print(\"   â€¢ Suivi clinique de routine\")\n",
        "        print(\"   â€¢ Surveillance des symptÃ´mes\")\n",
        "    else:\n",
        "        urgent_findings = results_df[results_df['ProbabilitÃ©'] > 0.7]\n",
        "        if len(urgent_findings) > 0:\n",
        "            print(\"   ðŸš¨ ACTIONS URGENTES REQUISES:\")\n",
        "            for _, row in urgent_findings.iterrows():\n",
        "                print(f\"      â€¢ {row['Pathologie']}: Consultation spÃ©cialisÃ©e urgente\")\n",
        "                if 'Pneumothorax' in row['Pathologie']:\n",
        "                    print(\"        â†’ URGENCE: DÃ©compression immÃ©diate si symptÃ´mes\")\n",
        "                elif 'Cardiomegaly' in row['Pathologie']:\n",
        "                    print(\"        â†’ Ã‰chocardiographie et consultation cardiologique\")\n",
        "                elif 'Mass' in row['Pathologie'] or 'Nodule' in row['Pathologie']:\n",
        "                    print(\"        â†’ TDM thoracique et consultation oncologique\")\n",
        "        \n",
        "        moderate_findings = results_df[(results_df['ProbabilitÃ©'] > 0.3) & (results_df['ProbabilitÃ©'] <= 0.7)]\n",
        "        if len(moderate_findings) > 0:\n",
        "            print(\"   ðŸ“‹ SURVEILLANCE ET Ã‰VALUATIONS:\")\n",
        "            for _, row in moderate_findings.iterrows():\n",
        "                print(f\"      â€¢ {row['Pathologie']}: CorrÃ©lation clinique et suivi\")\n",
        "    \n",
        "    # Pour les chirurgiens\n",
        "    print(\"\\nðŸ¥ POUR LES CHIRURGIENS:\")\n",
        "    surgical_relevant = results_df[results_df['Pathologie'].isin([\n",
        "        'Pneumothorax', 'Mass', 'Nodule', 'Fracture', 'Hernia'\n",
        "    ]) & results_df['DÃ©tectÃ©e']]\n",
        "    \n",
        "    if len(surgical_relevant) > 0:\n",
        "        print(\"   ðŸ”ª Ã‰VALUATIONS CHIRURGICALES NÃ‰CESSAIRES:\")\n",
        "        for _, row in surgical_relevant.iterrows():\n",
        "            print(f\"      â€¢ {row['Pathologie']} (Prob: {row['ProbabilitÃ©']:.3f})\")\n",
        "            if 'Pneumothorax' in row['Pathologie']:\n",
        "                print(\"        â†’ ConsidÃ©rer drainage thoracique\")\n",
        "            elif 'Mass' in row['Pathologie'] or 'Nodule' in row['Pathologie']:\n",
        "                print(\"        â†’ Ã‰valuation pour biopsie/rÃ©section\")\n",
        "            elif 'Fracture' in row['Pathologie']:\n",
        "                print(\"        â†’ Ã‰valuation orthopÃ©dique\")\n",
        "    else:\n",
        "        print(\"   âœ… Pas d'indication chirurgicale immÃ©diate dÃ©tectÃ©e\")\n",
        "    \n",
        "    # Pour les enseignants\n",
        "    print(\"\\nðŸ“š POUR LES ENSEIGNANTS D'ANATOMIE/RADIOLOGIE:\")\n",
        "    print(\"   ðŸŽ“ POINTS PÃ‰DAGOGIQUES:\")\n",
        "    print(f\"      â€¢ Analyse de {len(results_df)} pathologies diffÃ©rentes\")\n",
        "    print(f\"      â€¢ SensibilitÃ© du modÃ¨le au seuil de dÃ©tection\")\n",
        "    print(f\"      â€¢ CorrÃ©lation entre probabilitÃ©s IA et signes radiologiques\")\n",
        "    \n",
        "    if len(detected_pathologies) > 0:\n",
        "        print(\"   ðŸ“– CAS D'Ã‰TUDE:\")\n",
        "        for _, row in detected_pathologies.head(3).iterrows():\n",
        "            print(f\"      â€¢ {row['Pathologie']}: Exemple d'apprentissage de reconnaissance\")\n",
        "    \n",
        "    # Limitations et considÃ©rations\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"âš ï¸ LIMITATIONS ET CONSIDÃ‰RATIONS IMPORTANTES\")\n",
        "    print(\"-\"*50)\n",
        "    print(\"   â€¢ Ce rapport est gÃ©nÃ©rÃ© automatiquement par IA\")\n",
        "    print(\"   â€¢ TOUJOURS corrÃ©ler avec l'examen clinique du patient\")\n",
        "    print(\"   â€¢ Les probabilitÃ©s ne remplacent pas le jugement mÃ©dical\")\n",
        "    print(\"   â€¢ Faux positifs et faux nÃ©gatifs possibles\")\n",
        "    print(\"   â€¢ Validation par radiologue recommandÃ©e pour cas complexes\")\n",
        "    \n",
        "    # MÃ©triques techniques\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"ðŸ”¬ MÃ‰TRIQUES TECHNIQUES\")\n",
        "    print(\"-\"*50)\n",
        "    print(f\"   â€¢ ProbabilitÃ© moyenne: {results_df['ProbabilitÃ©'].mean():.3f}\")\n",
        "    print(f\"   â€¢ ProbabilitÃ© maximale: {results_df['ProbabilitÃ©'].max():.3f}\")\n",
        "    print(f\"   â€¢ Ã‰cart-type des probabilitÃ©s: {results_df['ProbabilitÃ©'].std():.3f}\")\n",
        "    print(f\"   â€¢ Pathologies > 10%: {len(results_df[results_df['ProbabilitÃ©'] > 0.1])}\")\n",
        "    print(f\"   â€¢ Pathologies > 50%: {len(results_df[results_df['ProbabilitÃ©'] > 0.5])}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“‹ Rapport gÃ©nÃ©rÃ© automatiquement par TorchXRayVision\")\n",
        "    print(\"ðŸ“‹ Report automatically generated by TorchXRayVision\")\n",
        "    print(f\"â° {current_time}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "def get_clinical_information(pathology):\n",
        "    \"\"\"\n",
        "    Informations cliniques pour chaque pathologie\n",
        "    Clinical information for each pathology\n",
        "    \"\"\"\n",
        "    clinical_info = {\n",
        "        'Atelectasis': 'Collapsus alvÃ©olaire, souvent post-opÃ©ratoire',\n",
        "        'Consolidation': 'Remplissage alvÃ©olaire, Ã©voque une pneumonie',\n",
        "        'Infiltration': 'Processus inflammatoire ou infectieux diffus',\n",
        "        'Pneumothorax': 'Urgence potentielle, dÃ©compression si symptomatique',\n",
        "        'Edema': 'Å’dÃ¨me pulmonaire, Ã©valuer fonction cardiaque',\n",
        "        'Emphysema': 'BPCO, Ã©valuation de la fonction respiratoire',\n",
        "        'Fibrosis': 'Fibrose pulmonaire, bilan Ã©tiologique nÃ©cessaire',\n",
        "        'Pleural_Thickening': 'Ã‰paississement pleural, rechercher cause',\n",
        "        'Cardiomegaly': 'CardiomÃ©galie, Ã©chocardiographie recommandÃ©e',\n",
        "        'Nodule': 'Nodule pulmonaire, surveillance ou biopsie selon taille',\n",
        "        'Mass': 'Masse thoracique, investigation oncologique urgente',\n",
        "        'Pneumonia': 'Pneumonie, antibiothÃ©rapie et surveillance',\n",
        "        'Hernia': 'Hernie diaphragmatique, Ã©valuation chirurgicale',\n",
        "        'Fracture': 'Fracture costale, analgÃ©sie et surveillance complications'\n",
        "    }\n",
        "    \n",
        "    return clinical_info.get(pathology, 'Consulter la littÃ©rature mÃ©dicale')\n",
        "\n",
        "# GÃ©nÃ©rer le rapport clinique complet\n",
        "generate_comprehensive_clinical_report(results, model_name, threshold=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison_models"
      },
      "source": [
        "## ðŸ”„ Comparaison Multi-ModÃ¨les / Multi-Model Comparison\n",
        "\n",
        "Comparons les rÃ©sultats de diffÃ©rents modÃ¨les TorchXRayVision :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "compare_models"
      },
      "outputs": [],
      "source": [
        "def compare_multiple_models(img_tensor):\n",
        "    \"\"\"\n",
        "    Comparaison des rÃ©sultats entre diffÃ©rents modÃ¨les\n",
        "    Comparison of results between different models\n",
        "    \"\"\"\n",
        "    print(\"ðŸ”„ Comparaison multi-modÃ¨les en cours...\")\n",
        "    print(\"ðŸ”„ Multi-model comparison in progress...\")\n",
        "    \n",
        "    models_to_compare = []\n",
        "    model_names = []\n",
        "    \n",
        "    # Ajouter les modÃ¨les disponibles\n",
        "    if model_densenet is not None:\n",
        "        models_to_compare.append(model_densenet)\n",
        "        model_names.append(\"DenseNet-All\")\n",
        "    \n",
        "    if model_chexpert is not None:\n",
        "        models_to_compare.append(model_chexpert)\n",
        "        model_names.append(\"CheXpert\")\n",
        "    \n",
        "    if model_nih is not None:\n",
        "        models_to_compare.append(model_nih)\n",
        "        model_names.append(\"NIH\")\n",
        "    \n",
        "    if len(models_to_compare) < 2:\n",
        "        print(\"âš ï¸ Moins de 2 modÃ¨les disponibles pour la comparaison\")\n",
        "        return\n",
        "    \n",
        "    # Collecter les rÃ©sultats de tous les modÃ¨les\n",
        "    all_results = {}\n",
        "    common_pathologies = None\n",
        "    \n",
        "    for model, name in zip(models_to_compare, model_names):\n",
        "        print(f\"   ðŸ“Š Analyse avec {name}...\")\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(img_tensor)\n",
        "            probabilities = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
        "        \n",
        "        # CrÃ©er un dictionnaire pathologie -> probabilitÃ©\n",
        "        model_results = {}\n",
        "        for pathology, prob in zip(model.pathologies, probabilities):\n",
        "            model_results[pathology] = prob\n",
        "        \n",
        "        all_results[name] = model_results\n",
        "        \n",
        "        # Trouver les pathologies communes\n",
        "        if common_pathologies is None:\n",
        "            common_pathologies = set(model.pathologies)\n",
        "        else:\n",
        "            common_pathologies = common_pathologies.intersection(set(model.pathologies))\n",
        "    \n",
        "    # CrÃ©er une visualisation comparative\n",
        "    common_pathologies = sorted(list(common_pathologies))\n",
        "    \n",
        "    if len(common_pathologies) == 0:\n",
        "        print(\"âš ï¸ Aucune pathologie commune entre les modÃ¨les\")\n",
        "        return\n",
        "    \n",
        "    # PrÃ©parer les donnÃ©es pour la visualisation\n",
        "    comparison_data = []\n",
        "    \n",
        "    for pathology in common_pathologies[:15]:  # Top 15 pour la lisibilitÃ©\n",
        "        for model_name in model_names:\n",
        "            if pathology in all_results[model_name]:\n",
        "                comparison_data.append({\n",
        "                    'Pathologie': pathology,\n",
        "                    'ModÃ¨le': model_name,\n",
        "                    'ProbabilitÃ©': all_results[model_name][pathology]\n",
        "                })\n",
        "    \n",
        "    df_comparison = pd.DataFrame(comparison_data)\n",
        "    \n",
        "    # Visualisation\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
        "    fig.suptitle('COMPARAISON MULTI-MODÃˆLES\\nMULTI-MODEL COMPARISON', \n",
        "                fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Heatmap comparative\n",
        "    pivot_data = df_comparison.pivot(index='Pathologie', columns='ModÃ¨le', values='ProbabilitÃ©')\n",
        "    sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='Reds', ax=axes[0, 0], cbar_kws={'label': 'ProbabilitÃ©'})\n",
        "    axes[0, 0].set_title('Matrice Comparative des ProbabilitÃ©s', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('ModÃ¨le')\n",
        "    axes[0, 0].set_ylabel('Pathologie')\n",
        "    \n",
        "    # 2. Graphique en barres groupÃ©es pour le top 8\n",
        "    top_pathologies = df_comparison.groupby('Pathologie')['ProbabilitÃ©'].max().nlargest(8).index\n",
        "    df_top = df_comparison[df_comparison['Pathologie'].isin(top_pathologies)]\n",
        "    \n",
        "    pathology_positions = {path: i for i, path in enumerate(top_pathologies)}\n",
        "    x_positions = []\n",
        "    heights = []\n",
        "    colors = []\n",
        "    labels = []\n",
        "    \n",
        "    bar_width = 0.25\n",
        "    model_colors = ['skyblue', 'lightcoral', 'lightgreen', 'orange'][:len(model_names)]\n",
        "    \n",
        "    for i, model_name in enumerate(model_names):\n",
        "        model_data = df_top[df_top['ModÃ¨le'] == model_name]\n",
        "        for _, row in model_data.iterrows():\n",
        "            path_pos = pathology_positions[row['Pathologie']]\n",
        "            x_positions.append(path_pos + i * bar_width)\n",
        "            heights.append(row['ProbabilitÃ©'])\n",
        "            colors.append(model_colors[i])\n",
        "            if i == 0:  # Ajouter le label seulement une fois par modÃ¨le\n",
        "                labels.append(model_name)\n",
        "    \n",
        "    for i, model_name in enumerate(model_names):\n",
        "        model_data = df_top[df_top['ModÃ¨le'] == model_name]\n",
        "        x_vals = [pathology_positions[row['Pathologie']] + i * bar_width for _, row in model_data.iterrows()]\n",
        "        y_vals = [row['ProbabilitÃ©'] for _, row in model_data.iterrows()]\n",
        "        axes[0, 1].bar(x_vals, y_vals, bar_width, label=model_name, color=model_colors[i], alpha=0.7)\n",
        "    \n",
        "    axes[0, 1].set_xlabel('Pathologies')\n",
        "    axes[0, 1].set_ylabel('ProbabilitÃ©')\n",
        "    axes[0, 1].set_title('Top 8 Pathologies - Comparaison par ModÃ¨le', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].set_xticks([i + bar_width for i in range(len(top_pathologies))])\n",
        "    axes[0, 1].set_xticklabels([p[:12] for p in top_pathologies], rotation=45, ha='right')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. CorrÃ©lation entre modÃ¨les\n",
        "    if len(model_names) >= 2:\n",
        "        model1_data = [all_results[model_names[0]][path] for path in common_pathologies \n",
        "                      if path in all_results[model_names[0]]]\n",
        "        model2_data = [all_results[model_names[1]][path] for path in common_pathologies \n",
        "                      if path in all_results[model_names[1]]]\n",
        "        \n",
        "        axes[1, 0].scatter(model1_data, model2_data, alpha=0.6, s=60)\n",
        "        axes[1, 0].plot([0, 1], [0, 1], 'r--', alpha=0.8, label='CorrÃ©lation parfaite')\n",
        "        axes[1, 0].set_xlabel(f'ProbabilitÃ©s {model_names[0]}')\n",
        "        axes[1, 0].set_ylabel(f'ProbabilitÃ©s {model_names[1]}')\n",
        "        axes[1, 0].set_title(f'CorrÃ©lation {model_names[0]} vs {model_names[1]}', \n",
        "                           fontsize=12, fontweight='bold')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Calculer et afficher le coefficient de corrÃ©lation\n",
        "        correlation = np.corrcoef(model1_data, model2_data)[0, 1]\n",
        "        axes[1, 0].text(0.05, 0.95, f'CorrÃ©lation: {correlation:.3f}', \n",
        "                       transform=axes[1, 0].transAxes, fontsize=12, \n",
        "                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "    \n",
        "    # 4. Tableau de consensus\n",
        "    axes[1, 1].axis('off')\n",
        "    \n",
        "    # Trouver les pathologies avec consensus (accord entre modÃ¨les)\n",
        "    consensus_data = []\n",
        "    for pathology in common_pathologies:\n",
        "        probs = [all_results[name][pathology] for name in model_names if pathology in all_results[name]]\n",
        "        if len(probs) >= 2:\n",
        "            avg_prob = np.mean(probs)\n",
        "            std_prob = np.std(probs)\n",
        "            consensus = \"Ã‰levÃ©\" if std_prob < 0.1 else \"Moyen\" if std_prob < 0.2 else \"Faible\"\n",
        "            \n",
        "            if avg_prob > 0.2:  # Seulement les pathologies avec probabilitÃ© significative\n",
        "                consensus_data.append([pathology[:20], f\"{avg_prob:.3f}\", f\"{std_prob:.3f}\", consensus])\n",
        "    \n",
        "    # Trier par probabilitÃ© moyenne dÃ©croissante et prendre le top 10\n",
        "    consensus_data = sorted(consensus_data, key=lambda x: float(x[1]), reverse=True)[:10]\n",
        "    \n",
        "    if consensus_data:\n",
        "        headers = ['Pathologie', 'Moy.', 'Ã‰cart', 'Consensus']\n",
        "        table = axes[1, 1].table(cellText=consensus_data, colLabels=headers, \n",
        "                               cellLoc='center', loc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(9)\n",
        "        table.scale(1, 2)\n",
        "        \n",
        "        # Styliser l'en-tÃªte\n",
        "        for i in range(4):\n",
        "            table[(0, i)].set_facecolor('#4CAF50')\n",
        "            table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "        \n",
        "        axes[1, 1].set_title('Consensus Multi-ModÃ¨les (Top 10)', \n",
        "                           fontsize=12, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nâœ… Comparaison terminÃ©e entre {len(models_to_compare)} modÃ¨les\")\n",
        "    print(f\"ðŸ“Š {len(common_pathologies)} pathologies communes analysÃ©es\")\n",
        "    \n",
        "    return df_comparison\n",
        "\n",
        "# Effectuer la comparaison si plusieurs modÃ¨les sont disponibles\n",
        "try:\n",
        "    comparison_results = compare_multiple_models(img_tensor)\nexcept Exception as e:\n",
        "    print(f\"âš ï¸ Comparaison multi-modÃ¨les non disponible: {e}\")\n",
        "    print(\"â„¹ï¸ Un seul modÃ¨le disponible pour l'analyse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save_results_tutorial4"
      },
      "source": [
        "## ðŸ’¾ Sauvegarde des RÃ©sultats / Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_pathology_results"
      },
      "outputs": [],
      "source": [
        "# Sauvegarder tous les rÃ©sultats du Tutorial 4\n",
        "pathology_results = {\n",
        "    'original_image': img_preprocessed,\n",
        "    'detection_results': results,\n",
        "    'probabilities': probabilities,\n",
        "    'model_used': model_name,\n",
        "    'threshold': 0.3,\n",
        "    'detected_pathologies': results[results['DÃ©tectÃ©e']],\n",
        "    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "}\n",
        "\n",
        "# Ajouter les rÃ©sultats de segmentation si disponibles\n",
        "if use_tutorial3_data:\n",
        "    pathology_results['lung_mask'] = lung_mask\n",
        "    pathology_results['cardiac_mask'] = cardiac_mask\n",
        "\n",
        "# Sauvegarder en format pickle\n",
        "with open('pathology_results_tutorial4.pkl', 'wb') as f:\n",
        "    pickle.dump(pathology_results, f)\n",
        "\n",
        "print(\"ðŸ’¾ RÃ©sultats sauvegardÃ©s dans 'pathology_results_tutorial4.pkl'\")\n",
        "print(\"ðŸ’¾ Results saved to 'pathology_results_tutorial4.pkl'\")\n",
        "\n",
        "# CrÃ©er un rÃ©sumÃ© visuel final\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Image originale\n",
        "axes[0].imshow(img_preprocessed, cmap='gray')\n",
        "axes[0].set_title('Image AnalysÃ©e\\nAnalyzed Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Top pathologies dÃ©tectÃ©es\n",
        "top_detected = results[results['DÃ©tectÃ©e']].head(5)\n",
        "if len(top_detected) > 0:\n",
        "    y_pos = np.arange(len(top_detected))\n",
        "    axes[1].barh(y_pos, top_detected['ProbabilitÃ©'], color='red', alpha=0.7)\n",
        "    axes[1].set_yticks(y_pos)\n",
        "    axes[1].set_yticklabels([p[:15] for p in top_detected['Pathologie']])\n",
        "    axes[1].set_xlabel('ProbabilitÃ©')\n",
        "    axes[1].set_title(f'Pathologies DÃ©tectÃ©es\\n({len(top_detected)} trouvÃ©es)')\n",
        "    axes[1].grid(True, alpha=0.3)\nelse:\n",
        "    axes[1].text(0.5, 0.5, 'AUCUNE\\nPATHOLOGIE\\nDÃ‰TECTÃ‰E', \n",
        "                ha='center', va='center', transform=axes[1].transAxes,\n",
        "                fontsize=16, fontweight='bold', color='green')\n",
        "    axes[1].set_title('Statut de DÃ©tection')\n",
        "\n",
        "# Distribution gÃ©nÃ©rale des probabilitÃ©s\n",
        "axes[2].hist(probabilities, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[2].axvline(x=0.3, color='red', linestyle='--', linewidth=2, label='Seuil (0.3)')\n",
        "axes[2].set_xlabel('ProbabilitÃ©')\n",
        "axes[2].set_ylabel('Nombre de Pathologies')\n",
        "axes[2].set_title('Distribution des\\nProbabilitÃ©s')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('RÃ‰SUMÃ‰ DU TUTORIAL 4 - DÃ‰TECTION DE PATHOLOGIES\\nTUTORIAL 4 SUMMARY - PATHOLOGY DETECTION', \n",
        "            fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('pathology_detection_summary_tutorial4.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸŽ‰ TUTORIAL 4 TERMINÃ‰ AVEC SUCCÃˆS!\")\n",
        "print(\"ðŸŽ‰ TUTORIAL 4 COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nðŸ“Š RÃ‰SUMÃ‰ DES ACCOMPLISSEMENTS:\")\n",
        "print(f\"   âœ… Analyse de {len(results)} pathologies\")\n",
        "print(f\"   âœ… DÃ©tection de {len(results[results['DÃ©tectÃ©e']])} pathologies avec seuil 0.3\")\n",
        "print(f\"   âœ… GÃ©nÃ©ration de cartes de localisation\")\n",
        "print(f\"   âœ… Rapport clinique complet gÃ©nÃ©rÃ©\")\n",
        "print(f\"   âœ… Recommandations par spÃ©cialitÃ© mÃ©dicale\")\n",
        "\n",
        "if use_tutorial3_data:\n",
        "    print(f\"   âœ… IntÃ©gration avec les rÃ©sultats de segmentation du Tutorial 3\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ COMPÃ‰TENCES ACQUISES:\")\n",
        "print(f\"   â€¢ DÃ©tection automatique de pathologies thoraciques\")\n",
        "print(f\"   â€¢ InterprÃ©tation des scores de probabilitÃ©\")\n",
        "print(f\"   â€¢ Localisation approximative des anomalies\")\n",
        "print(f\"   â€¢ GÃ©nÃ©ration de rapports cliniques automatiques\")\n",
        "print(f\"   â€¢ Recommandations par spÃ©cialitÃ© mÃ©dicale\")\n",
        "\n",
        "print(f\"\\nðŸš€ PROCHAINES Ã‰TAPES:\")\n",
        "print(f\"   ðŸ“š Tutorial 5: Multi-Model Comparison (Comparaison approfondie)\")\n",
        "print(f\"   ðŸ“š Tutorial 6: Custom Dataset Integration (DonnÃ©es personnalisÃ©es)\")\n",
        "print(f\"   ðŸ“š Applications cliniques avancÃ©es\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}