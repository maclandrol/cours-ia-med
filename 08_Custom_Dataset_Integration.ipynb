{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/maclandrol/cours-ia-med/blob/master/08_Custom_Dataset_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "instructor-info"
   },
   "source": [
    "**Enseignant:** Emmanuel Noutahi, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title-section"
   },
   "source": [
    "# Tutorial 8: Custom Dataset Integration\n",
    "\n",
    "## Medical Context\n",
    "\n",
    "### For Medical Students\n",
    "Custom dataset integration is essential for:\n",
    "- **Medical research**: Analyzing your own clinical data\n",
    "- **Specialized studies**: Focus on specific pathologies\n",
    "- **Local validation**: Adapting AI to your patient population\n",
    "- **Student projects**: Conducting original research\n",
    "\n",
    "### For Practitioners\n",
    "- **Surgeons**: Validation on specific surgical cases\n",
    "- **General practitioners**: Adaptation to local population characteristics\n",
    "- **Medical educators**: Creating personalized teaching cases\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "1. **Efficiently load** your own radiological images\n",
    "2. **Organize** a custom dataset for analysis\n",
    "3. **Apply** TorchXRayVision models to your data\n",
    "4. **Perform batch analysis** of multiple images\n",
    "5. **Generate** comparative reports for your dataset\n",
    "6. **Export** results for clinical or research use\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This tutorial builds on **Tutorials 1-7**. You should be familiar with:\n",
    "- Basic TorchXRayVision usage\n",
    "- Pathology classification and detection\n",
    "- Results interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-libraries"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install torchxrayvision\n",
    "!pip install torch torchvision\n",
    "!pip install matplotlib seaborn\n",
    "!pip install numpy pandas\n",
    "!pip install scikit-image opencv-python\n",
    "!pip install tqdm\n",
    "\n",
    "print(\"Installation completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchxrayvision as xrv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import io\n",
    "import json\n",
    "from google.colab import files\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display configuration\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"Libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TorchXRayVision version: {xrv.__version__}\")\n",
    "\n",
    "# GPU check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device used: {device}\")\n",
    "\n",
    "# Create working directories\n",
    "os.makedirs('custom_dataset', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "print(\"Working directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-loading"
   },
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-models"
   },
   "outputs": [],
   "source": [
    "# Load TorchXRayVision models for custom dataset analysis\n",
    "print(\"Loading models for custom dataset analysis...\")\n",
    "\n",
    "models = {}\n",
    "model_info = {}\n",
    "\n",
    "# 1. Main model for classification\n",
    "try:\n",
    "    models['densenet'] = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
    "    models['densenet'].to(device)\n",
    "    models['densenet'].eval()\n",
    "    model_info['densenet'] = {\n",
    "        'name': 'DenseNet121-All',\n",
    "        'pathologies': models['densenet'].pathologies,\n",
    "        'description': 'General model for all pathologies'\n",
    "    }\n",
    "    print(\"DenseNet121-All loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading DenseNet: {e}\")\n",
    "\n",
    "# 2. CheXpert model\n",
    "try:\n",
    "    models['chexpert'] = xrv.models.DenseNet(weights=\"densenet121-res224-chexpert\")\n",
    "    models['chexpert'].to(device)\n",
    "    models['chexpert'].eval()\n",
    "    model_info['chexpert'] = {\n",
    "        'name': 'CheXpert',\n",
    "        'pathologies': models['chexpert'].pathologies,\n",
    "        'description': 'Specialized for CheXpert data'\n",
    "    }\n",
    "    print(\"CheXpert loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CheXpert: {e}\")\n",
    "\n",
    "if not models:\n",
    "    raise Exception(\"No models could be loaded\")\n",
    "\n",
    "# Select main model\n",
    "main_model_key = list(models.keys())[0]\n",
    "main_model = models[main_model_key]\n",
    "\n",
    "print(f\"\\nAvailable models: {list(models.keys())}\")\n",
    "print(f\"Main model: {model_info[main_model_key]['name']}\")\n",
    "print(f\"Detectable pathologies: {len(main_model.pathologies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-upload"
   },
   "source": [
    "## Dataset Upload Methods\n",
    "\n",
    "Choose your preferred method for uploading your dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch-upload"
   },
   "source": [
    "### Method 1: Batch Upload (Recommended)\n",
    "Upload multiple images at once or use a ZIP archive for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch-upload-code"
   },
   "outputs": [],
   "source": [
    "def upload_dataset():\n",
    "    \"\"\"\n",
    "    Unified dataset upload function supporting multiple formats\n",
    "    \"\"\"\n",
    "    print(\"BATCH DATASET UPLOAD\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Supported formats: .jpg, .jpeg, .png, .tiff, .zip\")\n",
    "    print(\"You can select multiple images or a single ZIP archive\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Upload interface\n",
    "    uploaded_files = files.upload()\n",
    "    \n",
    "    images = []\n",
    "    filenames = []\n",
    "    \n",
    "    if not uploaded_files:\n",
    "        print(\"No files uploaded\")\n",
    "        return images, filenames\n",
    "    \n",
    "    print(f\"\\n{len(uploaded_files)} file(s) uploaded\")\n",
    "    \n",
    "    for filename, file_content in uploaded_files.items():\n",
    "        try:\n",
    "            # Handle ZIP archives\n",
    "            if filename.lower().endswith('.zip'):\n",
    "                print(f\"Extracting ZIP archive: {filename}...\")\n",
    "                \n",
    "                # Save and extract ZIP\n",
    "                with open('temp_dataset.zip', 'wb') as f:\n",
    "                    f.write(file_content)\n",
    "                \n",
    "                with zipfile.ZipFile('temp_dataset.zip', 'r') as zip_ref:\n",
    "                    zip_ref.extractall('custom_dataset')\n",
    "                \n",
    "                # Find all images in extracted content\n",
    "                image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.tiff', '*.tif']\n",
    "                image_files = []\n",
    "                \n",
    "                for ext in image_extensions:\n",
    "                    image_files.extend(glob.glob(os.path.join('custom_dataset', '**', ext), recursive=True))\n",
    "                    image_files.extend(glob.glob(os.path.join('custom_dataset', '**', ext.upper()), recursive=True))\n",
    "                \n",
    "                print(f\"Found {len(image_files)} image(s) in archive\")\n",
    "                \n",
    "                # Load images from archive\n",
    "                for img_path in tqdm(image_files, desc=\"Loading images from archive\"):\n",
    "                    try:\n",
    "                        image = Image.open(img_path)\n",
    "                        if image.mode != 'L':\n",
    "                            image = image.convert('L')\n",
    "                        \n",
    "                        img_array = np.array(image)\n",
    "                        images.append(img_array)\n",
    "                        filenames.append(os.path.basename(img_path))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {img_path}: {e}\")\n",
    "                \n",
    "                # Cleanup\n",
    "                os.remove('temp_dataset.zip')\n",
    "                \n",
    "            # Handle individual image files\n",
    "            elif filename.lower().endswith(('.jpg', '.jpeg', '.png', '.tiff', '.tif')):\n",
    "                image = Image.open(io.BytesIO(file_content))\n",
    "                \n",
    "                # Convert to grayscale\n",
    "                if image.mode != 'L':\n",
    "                    image = image.convert('L')\n",
    "                \n",
    "                img_array = np.array(image)\n",
    "                images.append(img_array)\n",
    "                filenames.append(filename)\n",
    "                \n",
    "                print(f\"Loaded: {filename} - {img_array.shape}\")\n",
    "            else:\n",
    "                print(f\"Unsupported format: {filename}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal: {len(images)} image(s) loaded successfully\")\n",
    "    \n",
    "    # Display preview\n",
    "    if images:\n",
    "        n_preview = min(6, len(images))\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        sample_indices = np.random.choice(len(images), n_preview, replace=False) if len(images) > n_preview else range(len(images))\n",
    "        \n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            if i < len(axes):\n",
    "                axes[i].imshow(images[idx], cmap='gray')\n",
    "                axes[i].set_title(f'{filenames[idx][:20]}...\\n{images[idx].shape}')\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for i in range(len(sample_indices), len(axes)):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Dataset Preview - {len(images)} Images Loaded')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return images, filenames\n",
    "\n",
    "# Upload dataset\n",
    "dataset_images, dataset_filenames = upload_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sample-dataset"
   },
   "source": [
    "### Method 2: Sample Dataset (For Testing)\n",
    "Generate synthetic X-ray images for testing without your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample-dataset-code"
   },
   "outputs": [],
   "source": [
    "def create_sample_dataset(n_images=6):\n",
    "    \"\"\"\n",
    "    Create sample dataset with simulated pathology patterns\n",
    "    \"\"\"\n",
    "    sample_images = []\n",
    "    sample_filenames = []\n",
    "    \n",
    "    case_types = [\n",
    "        (\"normal\", \"Normal chest X-ray\"),\n",
    "        (\"cardiomegaly\", \"Simulated cardiomegaly\"),\n",
    "        (\"pneumonia\", \"Simulated pneumonia\"),\n",
    "        (\"pneumothorax\", \"Simulated pneumothorax\"),\n",
    "        (\"infiltration\", \"Simulated infiltration\"),\n",
    "        (\"atelectasis\", \"Simulated atelectasis\")\n",
    "    ]\n",
    "    \n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    for i in range(n_images):\n",
    "        case_type, description = case_types[i % len(case_types)]\n",
    "        \n",
    "        # Base chest X-ray structure\n",
    "        img = np.random.rand(224, 224) * 0.3 + 0.4\n",
    "        \n",
    "        # Basic anatomical structures\n",
    "        img[50:180, 30:100] *= 0.7   # Left lung\n",
    "        img[50:180, 124:194] *= 0.7  # Right lung\n",
    "        img[120:180, 90:134] *= 1.2  # Heart\n",
    "        \n",
    "        # Add pathology-specific patterns\n",
    "        if case_type == \"cardiomegaly\":\n",
    "            img[110:190, 80:144] *= 1.4  # Enlarged heart\n",
    "        elif case_type == \"pneumonia\":\n",
    "            img[80:140, 140:180] *= 1.6  # Consolidation\n",
    "        elif case_type == \"pneumothorax\":\n",
    "            img[60:120, 150:190] *= 0.3  # Hyperlucent area\n",
    "        elif case_type == \"infiltration\":\n",
    "            img[70:150, 40:90] *= 1.3    # Left infiltrate\n",
    "            img[90:160, 130:170] *= 1.2  # Right infiltrate\n",
    "        elif case_type == \"atelectasis\":\n",
    "            img[80:130, 35:85] *= 1.7    # Partial collapse\n",
    "        \n",
    "        # Normalize and smooth\n",
    "        img = np.clip(img, 0, 1)\n",
    "        img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "        \n",
    "        sample_images.append(img)\n",
    "        sample_filenames.append(f\"sample_{i+1:02d}_{case_type}.png\")\n",
    "    \n",
    "    return sample_images, sample_filenames\n",
    "\n",
    "# Option to create sample dataset\n",
    "use_sample = input(\"Create sample dataset for testing? (y/n): \").lower().strip()\n",
    "\n",
    "if use_sample in ['y', 'yes']:\n",
    "    print(\"\\nCreating sample dataset...\")\n",
    "    sample_images, sample_filenames = create_sample_dataset(6)\n",
    "    \n",
    "    # Add to main dataset if empty, otherwise offer to replace\n",
    "    if not dataset_images:\n",
    "        dataset_images = sample_images\n",
    "        dataset_filenames = sample_filenames\n",
    "        print(f\"Sample dataset created: {len(sample_images)} images\")\n",
    "    else:\n",
    "        choice = input(f\"Add to existing {len(dataset_images)} images? (y/n): \").lower().strip()\n",
    "        if choice in ['y', 'yes']:\n",
    "            dataset_images.extend(sample_images)\n",
    "            dataset_filenames.extend(sample_filenames)\n",
    "            print(f\"Added {len(sample_images)} sample images to dataset\")\n",
    "    \n",
    "    # Display sample dataset\n",
    "    if sample_images:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (img, filename) in enumerate(zip(sample_images, sample_filenames)):\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].set_title(filename.replace('_', ' '))\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle('Sample Dataset Generated')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Sample dataset not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-consolidation"
   },
   "source": [
    "## Dataset Consolidation and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "consolidate-dataset"
   },
   "outputs": [],
   "source": [
    "# Validate and consolidate dataset\n",
    "print(\"DATASET CONSOLIDATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if not dataset_images:\n",
    "    print(\"No images available for analysis!\")\n",
    "    print(\"Please upload images using one of the methods above\")\n",
    "else:\n",
    "    print(f\"Total dataset: {len(dataset_images)} images\")\n",
    "    \n",
    "    # Create dataset information DataFrame\n",
    "    dataset_info = pd.DataFrame({\n",
    "        'ID': range(len(dataset_images)),\n",
    "        'Filename': dataset_filenames,\n",
    "        'Shape': [img.shape for img in dataset_images],\n",
    "        'Size_MB': [img.nbytes / (1024*1024) for img in dataset_images],\n",
    "        'Min_Pixel': [img.min() for img in dataset_images],\n",
    "        'Max_Pixel': [img.max() for img in dataset_images],\n",
    "        'Mean_Pixel': [img.mean() for img in dataset_images]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nDATASET INFORMATION:\")\n",
    "    print(dataset_info.to_string(index=False))\n",
    "    \n",
    "    # Dataset statistics\n",
    "    print(f\"\\nDATASET STATISTICS:\")\n",
    "    print(f\"   Total images: {len(dataset_images)}\")\n",
    "    print(f\"   Unique image shapes: {len(set([img.shape for img in dataset_images]))}\")\n",
    "    print(f\"   Total dataset size: {sum(dataset_info['Size_MB']):.2f} MB\")\n",
    "    print(f\"   Average image size: {np.mean(dataset_info['Size_MB']):.2f} MB\")\n",
    "    \n",
    "    # Validation checks\n",
    "    print(f\"\\nVALIDATION CHECKS:\")\n",
    "    \n",
    "    # Check for very small images\n",
    "    small_images = [i for i, img in enumerate(dataset_images) if min(img.shape) < 64]\n",
    "    if small_images:\n",
    "        print(f\"   Warning: {len(small_images)} image(s) very small (< 64px)\")\n",
    "    else:\n",
    "        print(f\"   Image sizes: OK\")\n",
    "    \n",
    "    # Check pixel value ranges\n",
    "    unusual_ranges = [i for i, img in enumerate(dataset_images) if img.max() > 255 or img.min() < 0]\n",
    "    if unusual_ranges:\n",
    "        print(f\"   Warning: {len(unusual_ranges)} image(s) with unusual pixel ranges\")\n",
    "    else:\n",
    "        print(f\"   Pixel ranges: OK\")\n",
    "    \n",
    "    # Summary visualization\n",
    "    if len(dataset_images) > 1:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # Image size distribution\n",
    "        image_sizes = [img.shape[0] * img.shape[1] for img in dataset_images]\n",
    "        axes[0].hist(image_sizes, bins=min(10, len(set(image_sizes))), alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0].set_xlabel('Number of Pixels')\n",
    "        axes[0].set_ylabel('Number of Images')\n",
    "        axes[0].set_title('Image Size Distribution')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Pixel intensity distribution\n",
    "        mean_intensities = [img.mean() for img in dataset_images]\n",
    "        axes[1].hist(mean_intensities, bins=15, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "        axes[1].set_xlabel('Mean Pixel Intensity')\n",
    "        axes[1].set_ylabel('Number of Images')\n",
    "        axes[1].set_title('Mean Intensity Distribution')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Contrast distribution (std dev)\n",
    "        contrasts = [img.std() for img in dataset_images]\n",
    "        axes[2].hist(contrasts, bins=15, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        axes[2].set_xlabel('Pixel Standard Deviation')\n",
    "        axes[2].set_ylabel('Number of Images')\n",
    "        axes[2].set_title('Contrast Distribution')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('Dataset Quality Analysis', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\nDataset validated and ready for analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocessing"
   },
   "source": [
    "## Batch Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preprocess-batch"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset_batch(images, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Batch preprocessing of all images in the dataset\n",
    "    \"\"\"\n",
    "    print(\"BATCH PREPROCESSING\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    processed_images = []\n",
    "    processed_tensors = []\n",
    "    preprocessing_stats = []\n",
    "    \n",
    "    print(f\"Target size: {target_size}\")\n",
    "    print(f\"Images to process: {len(images)}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    for i, img in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "        try:\n",
    "            # Store original info\n",
    "            original_shape = img.shape\n",
    "            original_range = (img.min(), img.max())\n",
    "            \n",
    "            # Resize if necessary\n",
    "            if img.shape != target_size:\n",
    "                img_resized = cv2.resize(img, target_size)\n",
    "            else:\n",
    "                img_resized = img.copy()\n",
    "            \n",
    "            # Normalize to [0, 1]\n",
    "            if img_resized.max() > 1:\n",
    "                img_normalized = img_resized.astype(np.float32) / 255.0\n",
    "            else:\n",
    "                img_normalized = img_resized.astype(np.float32)\n",
    "            \n",
    "            # Z-score normalization for TorchXRayVision\n",
    "            mean_val = np.mean(img_normalized)\n",
    "            std_val = np.std(img_normalized)\n",
    "            \n",
    "            if std_val > 0:\n",
    "                img_standardized = (img_normalized - mean_val) / std_val\n",
    "            else:\n",
    "                img_standardized = img_normalized - mean_val\n",
    "            \n",
    "            # Convert to PyTorch tensor\n",
    "            img_tensor = torch.FloatTensor(img_standardized)\n",
    "            img_tensor = img_tensor.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]\n",
    "            img_tensor = img_tensor.to(device)\n",
    "            \n",
    "            # Store results\n",
    "            processed_images.append(img_normalized)\n",
    "            processed_tensors.append(img_tensor)\n",
    "            \n",
    "            # Store stats\n",
    "            stats = {\n",
    "                'original_shape': original_shape,\n",
    "                'original_range': original_range,\n",
    "                'processed_shape': img_normalized.shape,\n",
    "                'mean': mean_val,\n",
    "                'std': std_val,\n",
    "                'final_range': (img_standardized.min(), img_standardized.max())\n",
    "            }\n",
    "            preprocessing_stats.append(stats)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{len(processed_images)}/{len(images)} images processed successfully\")\n",
    "    \n",
    "    # Display preprocessing statistics\n",
    "    if preprocessing_stats:\n",
    "        stats_df = pd.DataFrame(preprocessing_stats)\n",
    "        \n",
    "        print(f\"\\nPREPROCESSING STATISTICS:\")\n",
    "        print(f\"   Final shape: {target_size}\")\n",
    "        print(f\"   Average mean: {stats_df['mean'].mean():.3f}\")\n",
    "        print(f\"   Average std: {stats_df['std'].mean():.3f}\")\n",
    "        print(f\"   Standardized range: [{stats_df['final_range'].apply(lambda x: x[0]).mean():.3f}, {stats_df['final_range'].apply(lambda x: x[1]).mean():.3f}]\")\n",
    "    \n",
    "    return processed_images, processed_tensors, preprocessing_stats\n",
    "\n",
    "# Apply preprocessing if we have images\n",
    "if dataset_images:\n",
    "    processed_images, processed_tensors, prep_stats = preprocess_dataset_batch(dataset_images)\n",
    "    print(\"\\nDataset ready for TorchXRayVision analysis!\")\n",
    "else:\n",
    "    print(\"No images to preprocess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch-analysis"
   },
   "source": [
    "## Batch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze-batch"
   },
   "outputs": [],
   "source": [
    "def analyze_dataset_batch(tensors, filenames, models_dict, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Batch analysis of entire dataset with available models\n",
    "    \"\"\"\n",
    "    print(\"BATCH DATASET ANALYSIS\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    print(f\"Images to analyze: {len(tensors)}\")\n",
    "    print(f\"Models available: {list(models_dict.keys())}\")\n",
    "    print(f\"Detection threshold: {threshold}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    all_results = {}\n",
    "    analysis_summary = []\n",
    "    \n",
    "    # Analyze with each model\n",
    "    for model_name, model in models_dict.items():\n",
    "        print(f\"Analyzing with {model_name} model...\")\n",
    "        \n",
    "        model_results = []\n",
    "        pathologies = model.pathologies\n",
    "        \n",
    "        # Analyze each image\n",
    "        for i, (tensor, filename) in enumerate(tqdm(zip(tensors, filenames), \n",
    "                                                   desc=f\"Analysis {model_name}\",\n",
    "                                                   total=len(tensors))):\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(tensor)\n",
    "                    probabilities = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "                \n",
    "                # Create result for this image\n",
    "                image_result = {\n",
    "                    'image_id': i,\n",
    "                    'filename': filename,\n",
    "                    'model': model_name\n",
    "                }\n",
    "                \n",
    "                # Add probabilities for each pathology\n",
    "                for pathology, prob in zip(pathologies, probabilities):\n",
    "                    image_result[pathology] = prob\n",
    "                    image_result[f'{pathology}_detected'] = prob > threshold\n",
    "                \n",
    "                # Summary statistics\n",
    "                image_result['total_detections'] = sum(prob > threshold for prob in probabilities)\n",
    "                image_result['max_probability'] = max(probabilities)\n",
    "                image_result['avg_probability'] = np.mean(probabilities)\n",
    "                \n",
    "                model_results.append(image_result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error with {filename} on {model_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        all_results[model_name] = model_results\n",
    "        \n",
    "        # Model summary\n",
    "        if model_results:\n",
    "            total_detections = sum(result['total_detections'] for result in model_results)\n",
    "            images_with_findings = sum(1 for result in model_results if result['total_detections'] > 0)\n",
    "            \n",
    "            summary = {\n",
    "                'model': model_name,\n",
    "                'images_analyzed': len(model_results),\n",
    "                'total_detections': total_detections,\n",
    "                'avg_detections_per_image': total_detections / len(model_results),\n",
    "                'images_with_findings': images_with_findings,\n",
    "                'percentage_with_findings': (images_with_findings / len(model_results)) * 100\n",
    "            }\n",
    "            analysis_summary.append(summary)\n",
    "    \n",
    "    print(f\"\\nAnalysis completed for {len(tensors)} images\")\n",
    "    \n",
    "    # Display summary\n",
    "    if analysis_summary:\n",
    "        summary_df = pd.DataFrame(analysis_summary)\n",
    "        \n",
    "        print(\"\\nANALYSIS SUMMARY:\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "        \n",
    "        # Summary visualization\n",
    "        if len(analysis_summary) > 1:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # Total detections by model\n",
    "            axes[0].bar(summary_df['model'], summary_df['total_detections'], alpha=0.7)\n",
    "            axes[0].set_title('Total Detections by Model')\n",
    "            axes[0].set_ylabel('Number of Detections')\n",
    "            axes[0].tick_params(axis='x', rotation=45)\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Percentage of images with findings\n",
    "            axes[1].bar(summary_df['model'], summary_df['percentage_with_findings'], \n",
    "                       alpha=0.7, color='orange')\n",
    "            axes[1].set_title('Percentage of Images with Findings')\n",
    "            axes[1].set_ylabel('Percentage (%)')\n",
    "            axes[1].tick_params(axis='x', rotation=45)\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.suptitle('Model Comparison Summary')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return all_results, analysis_summary\n",
    "\n",
    "# Perform analysis if we have processed tensors\n",
    "if 'processed_tensors' in locals() and processed_tensors:\n",
    "    batch_results, batch_summary = analyze_dataset_batch(processed_tensors, dataset_filenames, models)\n",
    "    print(\"\\nBatch analysis completed successfully!\")\n",
    "else:\n",
    "    print(\"No processed tensors available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "detailed-analysis"
   },
   "source": [
    "## Detailed Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "detailed-analysis-code"
   },
   "outputs": [],
   "source": [
    "def create_detailed_analysis(batch_results, filenames, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Detailed analysis with comprehensive visualizations\n",
    "    \"\"\"\n",
    "    print(\"DETAILED RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    if not batch_results:\n",
    "        print(\"No results available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Use first model for main analysis\n",
    "    main_model = list(batch_results.keys())[0]\n",
    "    main_results = batch_results[main_model]\n",
    "    \n",
    "    print(f\"Main analysis based on: {main_model}\")\n",
    "    print(f\"Images analyzed: {len(main_results)}\")\n",
    "    \n",
    "    # Extract pathologies\n",
    "    pathologies = [col for col in main_results[0].keys() \n",
    "                  if col not in ['image_id', 'filename', 'model', 'total_detections', \n",
    "                               'max_probability', 'avg_probability'] \n",
    "                  and not col.endswith('_detected')]\n",
    "    \n",
    "    # Pathology frequency analysis\n",
    "    pathology_counts = {}\n",
    "    pathology_avg_probs = {}\n",
    "    \n",
    "    for pathology in pathologies:\n",
    "        detections = sum(1 for result in main_results if result.get(f'{pathology}_detected', False))\n",
    "        avg_prob = np.mean([result.get(pathology, 0) for result in main_results])\n",
    "        \n",
    "        pathology_counts[pathology] = detections\n",
    "        pathology_avg_probs[pathology] = avg_prob\n",
    "    \n",
    "    # Sort by frequency\n",
    "    sorted_pathologies = sorted(pathology_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nTOP 10 DETECTED PATHOLOGIES:\")\n",
    "    for i, (pathology, count) in enumerate(sorted_pathologies[:10]):\n",
    "        percentage = (count / len(main_results)) * 100\n",
    "        avg_prob = pathology_avg_probs[pathology]\n",
    "        print(f\"   {i+1:2d}. {pathology:25s}: {count:3d}/{len(main_results)} ({percentage:5.1f}%) - Avg prob: {avg_prob:.3f}\")\n",
    "    \n",
    "    # Images with most findings\n",
    "    print(f\"\\nIMAGES WITH MOST PATHOLOGIES:\")\n",
    "    sorted_images = sorted(main_results, key=lambda x: x['total_detections'], reverse=True)\n",
    "    \n",
    "    for i, result in enumerate(sorted_images[:5]):\n",
    "        detected_paths = [path for path in pathologies \n",
    "                         if result.get(f'{path}_detected', False)]\n",
    "        print(f\"   {i+1}. {result['filename']:30s}: {result['total_detections']} detections\")\n",
    "        if detected_paths:\n",
    "            print(f\"      â†’ {', '.join(detected_paths[:3])}{'...' if len(detected_paths) > 3 else ''}\")\n",
    "    \n",
    "    # Comprehensive visualization\n",
    "    create_analysis_visualizations(batch_results, pathologies, threshold)\n",
    "    \n",
    "    return sorted_pathologies, sorted_images\n",
    "\n",
    "def create_analysis_visualizations(batch_results, pathologies, threshold):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations for the analysis\n",
    "    \"\"\"\n",
    "    main_model = list(batch_results.keys())[0]\n",
    "    results = batch_results[main_model]\n",
    "    \n",
    "    # Main analysis dashboard\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    \n",
    "    # 1. Detection frequency by pathology\n",
    "    top_pathologies = sorted(pathologies, \n",
    "                           key=lambda p: sum(1 for r in results if r.get(f'{p}_detected', False)), \n",
    "                           reverse=True)[:10]\n",
    "    \n",
    "    counts = [sum(1 for r in results if r.get(f'{path}_detected', False)) for path in top_pathologies]\n",
    "    \n",
    "    axes[0, 0].barh(range(len(top_pathologies)), counts, alpha=0.7)\n",
    "    axes[0, 0].set_yticks(range(len(top_pathologies)))\n",
    "    axes[0, 0].set_yticklabels([p[:15] for p in top_pathologies])\n",
    "    axes[0, 0].set_xlabel('Number of Detections')\n",
    "    axes[0, 0].set_title('Top 10 Most Frequent Pathologies')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Distribution of detections per image\n",
    "    detections_per_image = [result['total_detections'] for result in results]\n",
    "    axes[0, 1].hist(detections_per_image, bins=range(max(detections_per_image)+2), \n",
    "                   alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 1].set_xlabel('Number of Detections')\n",
    "    axes[0, 1].set_ylabel('Number of Images')\n",
    "    axes[0, 1].set_title('Distribution of Detections per Image')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Average probability distribution\n",
    "    avg_probs = [result['avg_probability'] for result in results]\n",
    "    axes[0, 2].hist(avg_probs, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[0, 2].axvline(x=threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({threshold})')\n",
    "    axes[0, 2].set_xlabel('Average Probability')\n",
    "    axes[0, 2].set_ylabel('Number of Images')\n",
    "    axes[0, 2].set_title('Average Probability Distribution')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Severity categorization\n",
    "    normal_count = sum(1 for r in results if r['total_detections'] == 0)\n",
    "    mild_count = sum(1 for r in results if 1 <= r['total_detections'] <= 2)\n",
    "    moderate_count = sum(1 for r in results if 3 <= r['total_detections'] <= 5)\n",
    "    severe_count = sum(1 for r in results if r['total_detections'] > 5)\n",
    "    \n",
    "    categories = ['Normal\\n(0)', 'Mild\\n(1-2)', 'Moderate\\n(3-5)', 'Severe\\n(6+)']\n",
    "    counts_sev = [normal_count, mild_count, moderate_count, severe_count]\n",
    "    colors_sev = ['green', 'yellow', 'orange', 'red']\n",
    "    \n",
    "    axes[1, 0].pie(counts_sev, labels=categories, colors=colors_sev,\n",
    "                  autopct='%1.1f%%', startangle=90)\n",
    "    axes[1, 0].set_title('Severity Distribution')\n",
    "    \n",
    "    # 5. Correlation: detections vs max probability\n",
    "    max_probs = [result['max_probability'] for result in results]\n",
    "    axes[1, 1].scatter(detections_per_image, max_probs, alpha=0.6, s=50)\n",
    "    axes[1, 1].set_xlabel('Number of Detections')\n",
    "    axes[1, 1].set_ylabel('Maximum Probability')\n",
    "    axes[1, 1].set_title('Detections vs Maximum Probability')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Pathology probability vs frequency scatter\n",
    "    path_freq = []\n",
    "    path_avg_prob = []\n",
    "    \n",
    "    for pathology in top_pathologies:\n",
    "        freq = sum(1 for r in results if r.get(f'{pathology}_detected', False))\n",
    "        avg_prob = np.mean([r.get(pathology, 0) for r in results])\n",
    "        path_freq.append(freq)\n",
    "        path_avg_prob.append(avg_prob)\n",
    "    \n",
    "    axes[1, 2].scatter(path_freq, path_avg_prob, s=100, alpha=0.7)\n",
    "    axes[1, 2].set_xlabel('Detection Frequency')\n",
    "    axes[1, 2].set_ylabel('Average Probability')\n",
    "    axes[1, 2].set_title('Pathology: Frequency vs Probability')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'COMPREHENSIVE DATASET ANALYSIS - {len(results)} Images', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Perform detailed analysis if we have results\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    detailed_pathologies, detailed_images = create_detailed_analysis(batch_results, dataset_filenames)\n",
    "else:\n",
    "    print(\"No results available for detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export-results"
   },
   "source": [
    "## Export and Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export-results-code"
   },
   "outputs": [],
   "source": [
    "def export_analysis_results(batch_results, filenames, analysis_summary):\n",
    "    \"\"\"\n",
    "    Export analysis results in multiple formats for clinical and research use\n",
    "    \"\"\"\n",
    "    print(\"EXPORTING RESULTS\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    exported_files = []\n",
    "    \n",
    "    # 1. Export detailed results as CSV\n",
    "    print(\"Exporting detailed results (CSV)...\")\n",
    "    \n",
    "    for model_name, results in batch_results.items():\n",
    "        df = pd.DataFrame(results)\n",
    "        csv_filename = f'results/analysis_{model_name}_{timestamp}.csv'\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        exported_files.append(csv_filename)\n",
    "        print(f\"   {csv_filename}\")\n",
    "    \n",
    "    # 2. Export summary report\n",
    "    print(\"\\nExporting summary report (CSV)...\")\n",
    "    \n",
    "    summary_df = pd.DataFrame(analysis_summary)\n",
    "    summary_filename = f'results/summary_{timestamp}.csv'\n",
    "    summary_df.to_csv(summary_filename, index=False)\n",
    "    exported_files.append(summary_filename)\n",
    "    print(f\"   {summary_filename}\")\n",
    "    \n",
    "    # 3. Export complete data as JSON\n",
    "    print(\"\\nExporting complete data (JSON)...\")\n",
    "    \n",
    "    json_data = {\n",
    "        'metadata': {\n",
    "            'timestamp': timestamp,\n",
    "            'total_images': len(filenames),\n",
    "            'models_used': list(batch_results.keys()),\n",
    "            'analysis_date': datetime.now().isoformat()\n",
    "        },\n",
    "        'results': batch_results,\n",
    "        'summary': analysis_summary,\n",
    "        'filenames': filenames\n",
    "    }\n",
    "    \n",
    "    json_filename = f'results/complete_analysis_{timestamp}.json'\n",
    "    with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, indent=2, ensure_ascii=False, default=str)\n",
    "    exported_files.append(json_filename)\n",
    "    print(f\"   {json_filename}\")\n",
    "    \n",
    "    # 4. Generate clinical report\n",
    "    print(\"\\nGenerating clinical report (TXT)...\")\n",
    "    \n",
    "    report_filename = f'results/clinical_report_{timestamp}.txt'\n",
    "    generate_clinical_report(batch_results, analysis_summary, report_filename, timestamp)\n",
    "    exported_files.append(report_filename)\n",
    "    print(f\"   {report_filename}\")\n",
    "    \n",
    "    # 5. Create download package\n",
    "    print(\"\\nCreating download package (ZIP)...\")\n",
    "    \n",
    "    zip_filename = f'analysis_package_{timestamp}.zip'\n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "        for filepath in exported_files:\n",
    "            zipf.write(filepath, os.path.basename(filepath))\n",
    "    \n",
    "    print(f\"   {zip_filename}\")\n",
    "    \n",
    "    # 6. Download interface\n",
    "    print(\"\\nDOWNLOAD OPTIONS:\")\n",
    "    print(\"1. Complete package (ZIP)\")\n",
    "    print(\"2. Summary report only (CSV)\")\n",
    "    print(\"3. Clinical report only (TXT)\")\n",
    "    print(\"4. Raw data (JSON)\")\n",
    "    \n",
    "    choice = input(\"\\nSelect download option (1-4) or 'all': \").strip()\n",
    "    \n",
    "    if choice == '1' or choice.lower() == 'all':\n",
    "        try:\n",
    "            files.download(zip_filename)\n",
    "            print(f\"Downloaded: {zip_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Download error: {e}\")\n",
    "    elif choice == '2':\n",
    "        try:\n",
    "            files.download(summary_filename)\n",
    "            print(f\"Downloaded: {summary_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Download error: {e}\")\n",
    "    elif choice == '3':\n",
    "        try:\n",
    "            files.download(report_filename)\n",
    "            print(f\"Downloaded: {report_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Download error: {e}\")\n",
    "    elif choice == '4':\n",
    "        try:\n",
    "            files.download(json_filename)\n",
    "            print(f\"Downloaded: {json_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Download error: {e}\")\n",
    "    else:\n",
    "        print(\"No download selected\")\n",
    "    \n",
    "    return {\n",
    "        'package': zip_filename,\n",
    "        'summary': summary_filename,\n",
    "        'report': report_filename,\n",
    "        'data': json_filename\n",
    "    }\n",
    "\n",
    "def generate_clinical_report(batch_results, analysis_summary, filename, timestamp):\n",
    "    \"\"\"\n",
    "    Generate a clinical-style report\n",
    "    \"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(\"CLINICAL AI ANALYSIS REPORT\\n\")\n",
    "        f.write(\"Custom Dataset Analysis with TorchXRayVision\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Report ID: {timestamp}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Executive summary\n",
    "        f.write(\"EXECUTIVE SUMMARY\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        main_model = list(batch_results.keys())[0]\n",
    "        main_results = batch_results[main_model]\n",
    "        total_images = len(main_results)\n",
    "        \n",
    "        images_with_findings = sum(1 for result in main_results if result['total_detections'] > 0)\n",
    "        normal_images = total_images - images_with_findings\n",
    "        \n",
    "        f.write(f\"Total Images Analyzed: {total_images}\\n\")\n",
    "        f.write(f\"Normal Images: {normal_images} ({normal_images/total_images*100:.1f}%)\\n\")\n",
    "        f.write(f\"Images with Findings: {images_with_findings} ({images_with_findings/total_images*100:.1f}%)\\n\")\n",
    "        f.write(f\"AI Models Used: {', '.join(batch_results.keys())}\\n\")\n",
    "        \n",
    "        # Detailed findings\n",
    "        f.write(\"\\n\\nDETAILED FINDINGS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        for summary in analysis_summary:\n",
    "            f.write(f\"\\nModel: {summary['model']}\\n\")\n",
    "            f.write(f\"  - Images analyzed: {summary['images_analyzed']}\\n\")\n",
    "            f.write(f\"  - Total detections: {summary['total_detections']}\\n\")\n",
    "            f.write(f\"  - Average detections per image: {summary['avg_detections_per_image']:.2f}\\n\")\n",
    "            f.write(f\"  - Images with findings: {summary['images_with_findings']} ({summary['percentage_with_findings']:.1f}%)\\n\")\n",
    "        \n",
    "        # Priority cases\n",
    "        high_severity = [r for r in main_results if r['total_detections'] > 5]\n",
    "        if high_severity:\n",
    "            f.write(f\"\\n\\nPRIORITY CASES (6+ findings)\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for case in high_severity:\n",
    "                f.write(f\"  - {case['filename']}: {case['total_detections']} findings\\n\")\n",
    "        \n",
    "        # Recommendations\n",
    "        f.write(f\"\\n\\nRECOMMENDATIONS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        if high_severity:\n",
    "            f.write(f\"1. Priority review recommended for {len(high_severity)} case(s) with multiple findings\\n\")\n",
    "        f.write(f\"2. Clinical correlation recommended for all positive findings\\n\")\n",
    "        f.write(f\"3. AI analysis serves as screening tool - final diagnosis requires radiologist review\\n\")\n",
    "        f.write(f\"4. Consider follow-up imaging for unclear or borderline cases\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "        f.write(\"End of Report\\n\")\n",
    "        f.write(\"Note: This AI analysis is for screening purposes only. \\n\")\n",
    "        f.write(\"Clinical correlation and radiologist review are essential.\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Export results if available\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    export_info = export_analysis_results(batch_results, dataset_filenames, batch_summary)\n",
    "    print(\"\\nExport completed successfully!\")\n",
    "    print(\"\\nGenerated files:\")\n",
    "    for key, filename in export_info.items():\n",
    "        print(f\"   {key}: {filename}\")\n",
    "else:\n",
    "    print(\"No results available for export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial-summary"
   },
   "source": [
    "## Tutorial Summary\n",
    "\n",
    "### What You Have Accomplished:\n",
    "\n",
    "**Data Management:**\n",
    "- Loaded custom medical images efficiently\n",
    "- Processed datasets in batch for optimal performance\n",
    "- Validated data quality and consistency\n",
    "\n",
    "**AI Analysis:**\n",
    "- Applied state-of-the-art TorchXRayVision models\n",
    "- Performed multi-model comparison analysis\n",
    "- Generated comprehensive pathology assessments\n",
    "\n",
    "**Clinical Integration:**\n",
    "- Created professional clinical reports\n",
    "- Exported results in multiple formats\n",
    "- Established workflows for research and practice\n",
    "\n",
    "### Skills Acquired:\n",
    "\n",
    "- **Dataset Integration**: Efficient loading and organization of custom medical datasets\n",
    "- **Batch Processing**: Automated analysis of multiple images simultaneously\n",
    "- **Model Application**: Practical use of multiple AI models for comprehensive analysis\n",
    "- **Results Interpretation**: Understanding and visualizing AI predictions\n",
    "- **Clinical Reporting**: Generating professional reports for medical use\n",
    "- **Data Export**: Preparing results for integration with clinical workflows\n",
    "\n",
    "### Practical Applications:\n",
    "\n",
    "**Medical Research:**\n",
    "- Analyze research cohorts and clinical studies\n",
    "- Validate AI models on local populations\n",
    "- Generate data for publication and presentation\n",
    "\n",
    "**Clinical Practice:**\n",
    "- Screen large volumes of radiological images\n",
    "- Assist in diagnostic workflow optimization\n",
    "- Support quality assurance programs\n",
    "\n",
    "**Educational Use:**\n",
    "- Create teaching datasets for medical education\n",
    "- Demonstrate AI capabilities to students\n",
    "- Support research projects and theses\n",
    "\n",
    "### Important Reminders:\n",
    "\n",
    "- **Data Privacy**: Always ensure patient confidentiality and data security\n",
    "- **Clinical Validation**: AI results require expert medical review\n",
    "- **Limitations**: Understand model constraints and appropriate use cases\n",
    "- **Documentation**: Maintain detailed records of methods and findings\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Practice**: Test the workflow with different types of medical images\n",
    "2. **Integrate**: Incorporate into your research or clinical practice\n",
    "3. **Collaborate**: Work with radiologists and clinicians for validation\n",
    "4. **Advance**: Explore additional AI models and techniques\n",
    "\n",
    "You now have the practical skills to effectively integrate custom datasets with state-of-the-art medical AI models for both research and clinical applications."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}